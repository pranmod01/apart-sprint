{
  "all": {
    "code_generation": {
      "name": "Code Generation",
      "category": "coding",
      "x": 0.65,
      "y": 0.5,
      "description": "Generate functional code from natural language descriptions",
      "benchmarks": [
        "aider_polyglot",
        "swe_bench_verified",
        "live_bench"
      ],
      "heights": {
        "2024": 0.465,
        "2025": 0.575,
        "2019": 0.36,
        "2020": 0.379,
        "2021": 0.399,
        "2022": 0.42,
        "2023": 0.442
      },
      "top_models": {
        "2024": [
          {
            "model": "o1-2024-12-17_high",
            "org": "OpenAI",
            "benchmark": "live_bench",
            "score": 75.67,
            "normalized_score": 0.7567,
            "date": "2024-12-17"
          },
          {
            "model": "o1-2024-12-17_high",
            "org": "OpenAI",
            "benchmark": "aider_polyglot",
            "score": 61.7,
            "normalized_score": 0.617,
            "date": "2024-12-17"
          },
          {
            "model": "claude-3-5-sonnet-20241022",
            "org": "Anthropic",
            "benchmark": "swe_bench_verified",
            "score": 0.0219839620900864,
            "normalized_score": 0.0219839620900864,
            "date": "2024-10-22"
          }
        ],
        "2025": [
          {
            "model": "gpt-5-2025-08-07_high",
            "org": "OpenAI",
            "benchmark": "aider_polyglot",
            "score": 88.0,
            "normalized_score": 0.88,
            "date": "2025-08-07"
          },
          {
            "model": "gemini-2.5-pro-exp-03-25",
            "org": "Google DeepMind",
            "benchmark": "live_bench",
            "score": 82.35,
            "normalized_score": 0.8234999999999999,
            "date": "2025-03-25"
          },
          {
            "model": "DeepSeek-V3.1",
            "org": "DeepSeek",
            "benchmark": "swe_bench_verified",
            "score": 0.0223856859876182,
            "normalized_score": 0.0223856859876182,
            "date": "2025-08-21"
          }
        ]
      }
    },
    "physical_intuition": {
      "name": "Physical Intuition",
      "category": "reasoning",
      "x": 0.5,
      "y": 0.5,
      "description": "Apply understanding of physical laws and object behavior",
      "benchmarks": [
        "piqa"
      ],
      "heights": {
        "2019": 0.705,
        "2021": 0.818,
        "2022": 0.832,
        "2023": 0.849,
        "2024": 0.887,
        "2020": 0.761,
        "2025": 0.914
      },
      "top_models": {
        "2019": [
          {
            "model": "gpt2-xl",
            "org": "OpenAI",
            "benchmark": "piqa",
            "score": 0.705,
            "normalized_score": 0.705,
            "date": "2019-11-05"
          }
        ],
        "2021": [
          {
            "model": "Gopher (280B)",
            "org": "DeepMind",
            "benchmark": "piqa",
            "score": 0.818,
            "normalized_score": 0.818,
            "date": "2021-12-08"
          }
        ],
        "2022": [
          {
            "model": "Megatron-Turing NLG 530B",
            "org": "Microsoft,NVIDIA",
            "benchmark": "piqa",
            "score": 0.8319,
            "normalized_score": 0.8319,
            "date": "2022-01-28"
          }
        ],
        "2023": [
          {
            "model": "falcon-180B",
            "org": "Technology Innovation Institute",
            "benchmark": "piqa",
            "score": 0.849,
            "normalized_score": 0.849,
            "date": "2023-09-06"
          }
        ],
        "2024": [
          {
            "model": "gpt-4o-mini-2024-07-18",
            "org": "OpenAI",
            "benchmark": "piqa",
            "score": 0.887,
            "normalized_score": 0.887,
            "date": "2024-07-18"
          }
        ]
      }
    },
    "scientific_reasoning": {
      "name": "Scientific Reasoning",
      "category": "knowledge",
      "x": 0.3,
      "y": 0.55,
      "description": "Apply scientific methods and domain knowledge to problems",
      "benchmarks": [
        "science_qa"
      ],
      "heights": {
        "2022": 0.74,
        "2023": 0.742,
        "2024": 0.913,
        "2019": 0.634,
        "2020": 0.668,
        "2021": 0.703,
        "2025": 0.94
      },
      "top_models": {
        "2022": [
          {
            "model": "text-davinci-001",
            "org": "OpenAI",
            "benchmark": "science_qa",
            "score": 0.7404,
            "normalized_score": 0.7404,
            "date": "2022-01-27"
          }
        ],
        "2023": [
          {
            "model": "blip2-opt-2.7b",
            "org": "Salesforce Research",
            "benchmark": "science_qa",
            "score": 0.7417,
            "normalized_score": 0.7417,
            "date": "2023-02-06"
          }
        ],
        "2024": [
          {
            "model": "Phi-3.5-vision-instruct",
            "org": null,
            "benchmark": "science_qa",
            "score": 0.913,
            "normalized_score": 0.913,
            "date": "2024-08-16"
          }
        ]
      }
    },
    "game_strategy": {
      "name": "Game Strategy",
      "category": "games",
      "x": 0.6,
      "y": 0.2,
      "description": "Develop winning approaches in strategic games",
      "benchmarks": [
        "factorio_learning_environment"
      ],
      "heights": {
        "2024": 2932.06,
        "2025": 1157.82,
        "2019": 2268.772,
        "2020": 2388.181,
        "2021": 2513.875,
        "2022": 2646.184,
        "2023": 2785.457
      },
      "top_models": {
        "2024": [
          {
            "model": "claude-3-5-sonnet-20240620",
            "org": "Anthropic",
            "benchmark": "factorio_learning_environment",
            "score": 293206.0,
            "normalized_score": 2932.06,
            "date": "2024-06-20"
          }
        ],
        "2025": [
          {
            "model": "gemini-2.0-flash-02-05",
            "org": "Google DeepMind,Google",
            "benchmark": "factorio_learning_environment",
            "score": 115782.0,
            "normalized_score": 1157.82,
            "date": "2025-02-05"
          }
        ]
      }
    },
    "commonsense_reasoning": {
      "name": "Commonsense Reasoning",
      "category": "reasoning",
      "x": 0.45,
      "y": 0.55,
      "description": "Apply everyday knowledge and intuitive logic",
      "benchmarks": [
        "common_sense_qa_2",
        "wino_grande",
        "arc_ai2",
        "hella_swag"
      ],
      "heights": {
        "2019": 0.411,
        "2021": 0.649,
        "2022": 0.772,
        "2023": 0.818,
        "2024": 0.912,
        "2020": 0.53,
        "2025": 0.939
      },
      "top_models": {
        "2019": [
          {
            "model": "gpt2-xl",
            "org": "OpenAI",
            "benchmark": "wino_grande",
            "score": 0.583,
            "normalized_score": 0.583,
            "date": "2019-11-05"
          },
          {
            "model": "gpt2-xl",
            "org": "OpenAI",
            "benchmark": "hella_swag",
            "score": 0.4,
            "normalized_score": 0.4,
            "date": "2019-11-05"
          },
          {
            "model": "gpt2-xl",
            "org": "OpenAI",
            "benchmark": "arc_ai2",
            "score": 0.25,
            "normalized_score": 0.25,
            "date": "2019-11-05"
          }
        ],
        "2021": [
          {
            "model": "GLaM (MoE)",
            "org": "Google",
            "benchmark": "wino_grande",
            "score": 0.792,
            "normalized_score": 0.792,
            "date": "2021-12-13"
          },
          {
            "model": "Gopher (280B)",
            "org": "DeepMind",
            "benchmark": "hella_swag",
            "score": 0.792,
            "normalized_score": 0.792,
            "date": "2021-12-08"
          },
          {
            "model": "gpt-j-6b",
            "org": "EleutherAI,LAION",
            "benchmark": "arc_ai2",
            "score": 0.363,
            "normalized_score": 0.363,
            "date": "2021-08-05"
          }
        ],
        "2022": [
          {
            "model": "text-davinci-003",
            "org": "OpenAI",
            "benchmark": "hella_swag",
            "score": 0.855,
            "normalized_score": 0.855,
            "date": "2022-11-28"
          },
          {
            "model": "text-davinci-002",
            "org": "OpenAI",
            "benchmark": "arc_ai2",
            "score": 0.852,
            "normalized_score": 0.852,
            "date": "2022-03-15"
          },
          {
            "model": "PaLM 540B",
            "org": "Google Research",
            "benchmark": "arc_ai2",
            "score": 0.852,
            "normalized_score": 0.852,
            "date": "2022-04-04"
          },
          {
            "model": "PaLM 540B",
            "org": "Google Research",
            "benchmark": "wino_grande",
            "score": 0.851,
            "normalized_score": 0.851,
            "date": "2022-04-04"
          },
          {
            "model": "text-davinci-001",
            "org": "OpenAI",
            "benchmark": "common_sense_qa_2",
            "score": 0.529,
            "normalized_score": 0.529,
            "date": "2022-01-27"
          }
        ],
        "2023": [
          {
            "model": "gpt-4-0314",
            "org": "OpenAI",
            "benchmark": "hella_swag",
            "score": 0.953,
            "normalized_score": 0.953,
            "date": "2023-03-14"
          },
          {
            "model": "gpt-4-32k-0314",
            "org": "OpenAI",
            "benchmark": "hella_swag",
            "score": 0.953,
            "normalized_score": 0.953,
            "date": "2023-03-14"
          },
          {
            "model": "gpt-4-0314",
            "org": "OpenAI",
            "benchmark": "wino_grande",
            "score": 0.875,
            "normalized_score": 0.875,
            "date": "2023-03-14"
          },
          {
            "model": "gpt-4-32k-0314",
            "org": "OpenAI",
            "benchmark": "wino_grande",
            "score": 0.875,
            "normalized_score": 0.875,
            "date": "2023-03-14"
          },
          {
            "model": "gpt-3.5-turbo-1106",
            "org": "OpenAI",
            "benchmark": "arc_ai2",
            "score": 0.874,
            "normalized_score": 0.874,
            "date": "2023-11-06"
          },
          {
            "model": "gpt-3.5-turbo-0613",
            "org": "OpenAI",
            "benchmark": "common_sense_qa_2",
            "score": 0.57,
            "normalized_score": 0.57,
            "date": "2023-06-13"
          }
        ],
        "2024": [
          {
            "model": "Llama-3.1-405B",
            "org": "Meta AI",
            "benchmark": "arc_ai2",
            "score": 0.953,
            "normalized_score": 0.953,
            "date": "2024-07-23"
          },
          {
            "model": "DeepSeek-V3",
            "org": "DeepSeek",
            "benchmark": "arc_ai2",
            "score": 0.953,
            "normalized_score": 0.953,
            "date": "2024-12-26"
          },
          {
            "model": "Llama-3.1-405B",
            "org": "Meta AI",
            "benchmark": "wino_grande",
            "score": 0.892,
            "normalized_score": 0.892,
            "date": "2024-07-23"
          },
          {
            "model": "Llama-3.1-405B",
            "org": "Meta AI",
            "benchmark": "hella_swag",
            "score": 0.892,
            "normalized_score": 0.892,
            "date": "2024-07-23"
          }
        ]
      }
    },
    "reading_comprehension": {
      "name": "Reading Comprehension",
      "category": "language",
      "x": 0.35,
      "y": 0.65,
      "description": "Extract meaning and answer questions from written passages",
      "benchmarks": [
        "open_book_qa"
      ],
      "heights": {
        "2019": 0.224,
        "2021": 0.63,
        "2022": 0.68,
        "2023": 0.86,
        "2024": 0.88,
        "2020": 0.427,
        "2025": 0.906
      },
      "top_models": {
        "2019": [
          {
            "model": "gpt2-xl",
            "org": "OpenAI",
            "benchmark": "open_book_qa",
            "score": 0.224,
            "normalized_score": 0.224,
            "date": "2019-11-05"
          }
        ],
        "2021": [
          {
            "model": "GLaM (MoE)",
            "org": "Google",
            "benchmark": "open_book_qa",
            "score": 0.63,
            "normalized_score": 0.63,
            "date": "2021-12-13"
          }
        ],
        "2022": [
          {
            "model": "PaLM 540B",
            "org": "Google Research",
            "benchmark": "open_book_qa",
            "score": 0.68,
            "normalized_score": 0.68,
            "date": "2022-04-04"
          }
        ],
        "2023": [
          {
            "model": "gpt-3.5-turbo-1106",
            "org": "OpenAI",
            "benchmark": "open_book_qa",
            "score": 0.86,
            "normalized_score": 0.86,
            "date": "2023-11-06"
          }
        ],
        "2024": [
          {
            "model": "Phi-3-mini-4k-instruct",
            "org": "Microsoft",
            "benchmark": "open_book_qa",
            "score": 0.88,
            "normalized_score": 0.88,
            "date": "2024-04-23"
          },
          {
            "model": "Phi-3-small-8k-instruct",
            "org": "Microsoft",
            "benchmark": "open_book_qa",
            "score": 0.88,
            "normalized_score": 0.88,
            "date": "2024-04-23"
          }
        ]
      }
    },
    "game_playing": {
      "name": "Game Playing",
      "category": "games",
      "x": 0.65,
      "y": 0.25,
      "description": "Learn and execute strategies in game environments",
      "benchmarks": [
        "balrog"
      ],
      "heights": {
        "2024": 0.326,
        "2025": 0.436,
        "2019": 0.252,
        "2020": 0.266,
        "2021": 0.28,
        "2022": 0.294,
        "2023": 0.31
      },
      "top_models": {
        "2024": [
          {
            "model": "claude-3-5-sonnet-20241022",
            "org": "Anthropic",
            "benchmark": "balrog",
            "score": 0.326,
            "normalized_score": 0.326,
            "date": "2024-10-22"
          }
        ],
        "2025": [
          {
            "model": "grok-4-0709",
            "org": "xAI",
            "benchmark": "balrog",
            "score": 0.436,
            "normalized_score": 0.436,
            "date": "2025-07-09"
          }
        ]
      }
    },
    "creative_writing": {
      "name": "Creative Writing",
      "category": "language",
      "x": 0.2,
      "y": 0.3,
      "description": "Generate original, engaging narrative and expressive text",
      "benchmarks": [
        "fictionlivebench"
      ],
      "heights": {
        "2024": 0.531,
        "2025": 1.0,
        "2019": 0.411,
        "2020": 0.433,
        "2021": 0.455,
        "2022": 0.479,
        "2023": 0.504
      },
      "top_models": {
        "2024": [
          {
            "model": "o1-2024-12-17_medium",
            "org": "OpenAI",
            "benchmark": "fictionlivebench",
            "score": 0.531,
            "normalized_score": 0.531,
            "date": "2024-12-17"
          }
        ],
        "2025": [
          {
            "model": "o3-2025-04-16_medium",
            "org": "OpenAI",
            "benchmark": "fictionlivebench",
            "score": 1.0,
            "normalized_score": 1.0,
            "date": "2025-04-16"
          }
        ]
      }
    },
    "competition_math": {
      "name": "Competition Math",
      "category": "mathematics",
      "x": 0.85,
      "y": 0.45,
      "description": "Solve competition-level mathematics problems (AMC, AIME, IMO)",
      "benchmarks": [
        "otis_mock_aime_2024_2025"
      ],
      "heights": {
        "2023": 0.015,
        "2024": 0.07,
        "2025": 0.075,
        "2019": 0.012,
        "2020": 0.013,
        "2021": 0.014,
        "2022": 0.014
      },
      "top_models": {
        "2023": [
          {
            "model": "claude-2.0",
            "org": "Anthropic",
            "benchmark": "otis_mock_aime_2024_2025",
            "score": 0.0151798976587226,
            "normalized_score": 0.0151798976587226,
            "date": "2023-07-11"
          }
        ],
        "2024": [
          {
            "model": "o1-preview-2024-09-12",
            "org": "OpenAI",
            "benchmark": "otis_mock_aime_2024_2025",
            "score": 0.0697920592732311,
            "normalized_score": 0.0697920592732311,
            "date": "2024-09-12"
          }
        ],
        "2025": [
          {
            "model": "claude-sonnet-4-20250514_16K",
            "org": "Anthropic",
            "benchmark": "otis_mock_aime_2024_2025",
            "score": 0.0752101433090354,
            "normalized_score": 0.0752101433090354,
            "date": "2025-05-22"
          },
          {
            "model": "claude-3-7-sonnet-20250219_32K",
            "org": "Anthropic",
            "benchmark": "otis_mock_aime_2024_2025",
            "score": 0.0752101433090354,
            "normalized_score": 0.0752101433090354,
            "date": "2025-02-24"
          },
          {
            "model": "claude-3-7-sonnet-20250219_16K",
            "org": "Anthropic",
            "benchmark": "otis_mock_aime_2024_2025",
            "score": 0.0752101433090354,
            "normalized_score": 0.0752101433090354,
            "date": "2025-02-24"
          },
          {
            "model": "DeepSeek-R1",
            "org": "DeepSeek",
            "benchmark": "otis_mock_aime_2024_2025",
            "score": 0.0752101433090354,
            "normalized_score": 0.0752101433090354,
            "date": "2025-01-20"
          }
        ]
      }
    },
    "advanced_reasoning": {
      "name": "Advanced Reasoning",
      "category": "reasoning",
      "x": 0.7,
      "y": 0.4,
      "description": "Handle complex multi-step reasoning across diverse domains",
      "benchmarks": [
        "gpqa_diamond"
      ],
      "heights": {
        "2023": 0.025,
        "2024": 0.033,
        "2025": 0.035,
        "2019": 0.02,
        "2020": 0.021,
        "2021": 0.023,
        "2022": 0.024
      },
      "top_models": {
        "2023": [
          {
            "model": "claude-2.0",
            "org": "Anthropic",
            "benchmark": "gpqa_diamond",
            "score": 0.0250762559835514,
            "normalized_score": 0.0250762559835514,
            "date": "2023-07-11"
          }
        ],
        "2024": [
          {
            "model": "dbrx-instruct",
            "org": "Databricks",
            "benchmark": "gpqa_diamond",
            "score": 0.0325694433356493,
            "normalized_score": 0.0325694433356493,
            "date": "2024-03-27"
          }
        ],
        "2025": [
          {
            "model": "gemini-2.0-flash-thinking-exp-01-21",
            "org": "Google DeepMind,Google",
            "benchmark": "gpqa_diamond",
            "score": 0.0352655272460119,
            "normalized_score": 0.0352655272460119,
            "date": "2025-01-21"
          }
        ]
      }
    },
    "mathematical_reasoning": {
      "name": "Mathematical Reasoning",
      "category": "mathematics",
      "x": 0.75,
      "y": 0.45,
      "description": "Solve math problems with step-by-step logical reasoning",
      "benchmarks": [
        "math_level_5",
        "gsm8k"
      ],
      "heights": {
        "2022": 0.782,
        "2023": 0.465,
        "2024": 0.479,
        "2025": 0.012,
        "2019": 0.67,
        "2020": 0.706,
        "2021": 0.743
      },
      "top_models": {
        "2022": [
          {
            "model": "text-davinci-003",
            "org": "OpenAI",
            "benchmark": "gsm8k",
            "score": 0.782,
            "normalized_score": 0.782,
            "date": "2022-11-28"
          }
        ],
        "2023": [
          {
            "model": "gpt-4-0314",
            "org": "OpenAI",
            "benchmark": "gsm8k",
            "score": 0.92,
            "normalized_score": 0.92,
            "date": "2023-03-14"
          },
          {
            "model": "gpt-4-1106-preview",
            "org": "OpenAI",
            "benchmark": "math_level_5",
            "score": 0.0105387946323973,
            "normalized_score": 0.0105387946323973,
            "date": "2023-11-06"
          }
        ],
        "2024": [
          {
            "model": "DeepSeek-Coder-V2-Instruct",
            "org": "DeepSeek",
            "benchmark": "gsm8k",
            "score": 0.945,
            "normalized_score": 0.945,
            "date": "2024-06-17"
          },
          {
            "model": "grok-2-1212",
            "org": "xAI",
            "benchmark": "math_level_5",
            "score": 0.0132343816959083,
            "normalized_score": 0.0132343816959083,
            "date": "2024-12-12"
          }
        ],
        "2025": [
          {
            "model": "Llama-4-Scout-17B-16E-Instruct",
            "org": "Meta AI",
            "benchmark": "math_level_5",
            "score": 0.0120224058737839,
            "normalized_score": 0.0120224058737839,
            "date": "2025-04-05"
          }
        ]
      }
    },
    "long_horizon_planning": {
      "name": "Long Horizon Planning",
      "category": "reasoning",
      "x": 0.55,
      "y": 0.75,
      "description": "Plan and reason about extended sequences of actions",
      "benchmarks": [
        "metr_time_horizons"
      ],
      "heights": {
        "2019": 0.101,
        "2023": 0.404,
        "2024": 0.559,
        "2025": 0.696,
        "2020": 0.177,
        "2021": 0.253,
        "2022": 0.328
      },
      "top_models": {
        "2019": [
          {
            "model": "gpt2-xl",
            "org": "OpenAI",
            "benchmark": "metr_time_horizons",
            "score": 0.101046,
            "normalized_score": 0.101046,
            "date": "2019-11-05"
          }
        ],
        "2023": [
          {
            "model": "gpt-4-1106-preview",
            "org": "OpenAI",
            "benchmark": "metr_time_horizons",
            "score": 0.404329,
            "normalized_score": 0.404329,
            "date": "2023-11-06"
          }
        ],
        "2024": [
          {
            "model": "o1-2024-12-17_medium",
            "org": "OpenAI",
            "benchmark": "metr_time_horizons",
            "score": 0.55932,
            "normalized_score": 0.55932,
            "date": "2024-12-17"
          }
        ],
        "2025": [
          {
            "model": "gpt-5-2025-08-07_medium",
            "org": "OpenAI",
            "benchmark": "metr_time_horizons",
            "score": 0.696053,
            "normalized_score": 0.696053,
            "date": "2025-08-07"
          }
        ]
      }
    },
    "writing_quality": {
      "name": "Writing Quality",
      "category": "language",
      "x": 0.25,
      "y": 0.35,
      "description": "Produce well-structured, grammatically correct, compelling text",
      "benchmarks": [
        "lech_mazur_writing"
      ],
      "heights": {
        "2024": 0.082,
        "2025": 0.084,
        "2019": 0.063,
        "2020": 0.067,
        "2021": 0.07,
        "2022": 0.074,
        "2023": 0.078
      },
      "top_models": {
        "2024": [
          {
            "model": "gpt-4o-2024-11-20",
            "org": "OpenAI",
            "benchmark": "lech_mazur_writing",
            "score": 8.18,
            "normalized_score": 0.0818,
            "date": "2024-11-20"
          }
        ],
        "2025": [
          {
            "model": "o3-2025-04-16_medium",
            "org": "OpenAI",
            "benchmark": "lech_mazur_writing",
            "score": 8.39,
            "normalized_score": 0.0839,
            "date": "2025-04-16"
          }
        ]
      }
    },
    "cad_design": {
      "name": "Cad Design",
      "category": "reasoning",
      "x": 0.75,
      "y": 0.25,
      "description": "Create and manipulate computer-aided design models",
      "benchmarks": [
        "cad_eval"
      ],
      "heights": {
        "2024": 0.56,
        "2025": 0.74,
        "2019": 0.433,
        "2020": 0.456,
        "2021": 0.48,
        "2022": 0.505,
        "2023": 0.532
      },
      "top_models": {
        "2024": [
          {
            "model": "o1-2024-12-17_medium",
            "org": "OpenAI",
            "benchmark": "cad_eval",
            "score": 0.56,
            "normalized_score": 0.56,
            "date": "2024-12-17"
          }
        ],
        "2025": [
          {
            "model": "o3-2025-04-16_medium",
            "org": "OpenAI",
            "benchmark": "cad_eval",
            "score": 0.74,
            "normalized_score": 0.74,
            "date": "2025-04-16"
          }
        ]
      }
    },
    "advanced_mathematics": {
      "name": "Advanced Mathematics",
      "category": "mathematics",
      "x": 0.8,
      "y": 0.4,
      "description": "Solve graduate-level and research mathematics problems",
      "benchmarks": [
        "frontiermath",
        "frontiermath_tier_4"
      ],
      "heights": {
        "2024": 0.009,
        "2025": 0.038,
        "2019": 0.007,
        "2020": 0.007,
        "2021": 0.008,
        "2022": 0.008,
        "2023": 0.009
      },
      "top_models": {
        "2024": [
          {
            "model": "o1-2024-12-17_high",
            "org": "OpenAI",
            "benchmark": "frontiermath",
            "score": 0.0170927852801478,
            "normalized_score": 0.0170927852801478,
            "date": "2024-12-17"
          },
          {
            "model": "claude-3-5-sonnet-20240620",
            "org": "Anthropic",
            "benchmark": "frontiermath_tier_4",
            "score": 0.0,
            "normalized_score": 0.0,
            "date": "2024-06-20"
          },
          {
            "model": "claude-3-5-sonnet-20241022",
            "org": "Anthropic",
            "benchmark": "frontiermath_tier_4",
            "score": 0.0,
            "normalized_score": 0.0,
            "date": "2024-10-22"
          }
        ],
        "2025": [
          {
            "model": "gpt-5-2025-08-07_high",
            "org": "OpenAI",
            "benchmark": "frontiermath_tier_4",
            "score": 0.0482403115617474,
            "normalized_score": 0.0482403115617474,
            "date": "2025-08-07"
          },
          {
            "model": "gemini-2.5-deep-think-2025-08-01-webapp",
            "org": "Google,Google DeepMind",
            "benchmark": "frontiermath",
            "score": 0.027,
            "normalized_score": 0.027,
            "date": "2025-08-01"
          }
        ]
      }
    },
    "abstract_reasoning": {
      "name": "Abstract Reasoning",
      "category": "reasoning",
      "x": 0.75,
      "y": 0.35,
      "description": "Recognize patterns and solve problems requiring high-level conceptual thinking",
      "benchmarks": [
        "arc_agi"
      ],
      "heights": {
        "2024": 0.307,
        "2025": 0.608,
        "2019": 0.238,
        "2020": 0.25,
        "2021": 0.263,
        "2022": 0.277,
        "2023": 0.292
      },
      "top_models": {
        "2024": [
          {
            "model": "o1-2024-12-17_medium",
            "org": "OpenAI",
            "benchmark": "arc_agi",
            "score": 0.307,
            "normalized_score": 0.307,
            "date": "2024-12-17"
          }
        ],
        "2025": [
          {
            "model": "o3-2025-04-16_high",
            "org": "OpenAI",
            "benchmark": "arc_agi",
            "score": 0.608,
            "normalized_score": 0.608,
            "date": "2025-04-16"
          }
        ]
      }
    },
    "basic_tasks": {
      "name": "Basic Tasks",
      "category": "reasoning",
      "x": 0.4,
      "y": 0.4,
      "description": "Perform fundamental operations and simple problem-solving",
      "benchmarks": [
        "simplebench"
      ],
      "heights": {
        "2024": 0.417,
        "2025": 0.624,
        "2019": 0.323,
        "2020": 0.34,
        "2021": 0.358,
        "2022": 0.376,
        "2023": 0.396
      },
      "top_models": {
        "2024": [
          {
            "model": "o1-preview-2024-09-12",
            "org": "OpenAI",
            "benchmark": "simplebench",
            "score": 0.417,
            "normalized_score": 0.417,
            "date": "2024-09-12"
          }
        ],
        "2025": [
          {
            "model": "gemini-2.5-pro-preview-06-05",
            "org": "Google DeepMind",
            "benchmark": "simplebench",
            "score": 0.624,
            "normalized_score": 0.624,
            "date": "2025-06-05"
          }
        ]
      }
    },
    "general_knowledge": {
      "name": "General Knowledge",
      "category": "knowledge",
      "x": 0.25,
      "y": 0.6,
      "description": "Answer questions across diverse academic and cultural domains",
      "benchmarks": [
        "mmlu"
      ],
      "heights": {
        "2021": 0.6,
        "2022": 0.7,
        "2023": 0.864,
        "2024": 0.881,
        "2025": 0.799,
        "2019": 0.541,
        "2020": 0.57
      },
      "top_models": {
        "2021": [
          {
            "model": "Gopher (280B)",
            "org": "DeepMind",
            "benchmark": "mmlu",
            "score": 0.6,
            "normalized_score": 0.6,
            "date": "2021-12-08"
          }
        ],
        "2022": [
          {
            "model": "text-davinci-002",
            "org": "OpenAI",
            "benchmark": "mmlu",
            "score": 0.7,
            "normalized_score": 0.7,
            "date": "2022-03-15"
          }
        ],
        "2023": [
          {
            "model": "gpt-4-0314",
            "org": "OpenAI",
            "benchmark": "mmlu",
            "score": 0.864,
            "normalized_score": 0.864,
            "date": "2023-03-14"
          }
        ],
        "2024": [
          {
            "model": "gpt-4o-2024-11-20",
            "org": "OpenAI",
            "benchmark": "mmlu",
            "score": 0.881,
            "normalized_score": 0.881,
            "date": "2024-11-20"
          }
        ],
        "2025": [
          {
            "model": "qwen2.5-14b-instruct",
            "org": "Alibaba",
            "benchmark": "mmlu",
            "score": 0.799,
            "normalized_score": 0.799,
            "date": "2025-02-26"
          }
        ]
      }
    },
    "os_interaction": {
      "name": "Os Interaction",
      "category": "agents",
      "x": 0.6,
      "y": 0.8,
      "description": "Navigate and manipulate operating system interfaces",
      "benchmarks": [
        "os_universe"
      ],
      "heights": {
        "2024": 0.284,
        "2025": 0.478,
        "2019": 0.22,
        "2020": 0.231,
        "2021": 0.243,
        "2022": 0.256,
        "2023": 0.27
      },
      "top_models": {
        "2024": [
          {
            "model": "claude-3-5-sonnet-20241022",
            "org": "Anthropic",
            "benchmark": "os_universe",
            "score": 0.2836,
            "normalized_score": 0.2836,
            "date": "2024-10-22"
          }
        ],
        "2025": [
          {
            "model": "computer-use-preview-2025-03-11",
            "org": null,
            "benchmark": "os_universe",
            "score": 0.478,
            "normalized_score": 0.478,
            "date": "2025-03-11"
          }
        ]
      }
    },
    "factual_knowledge": {
      "name": "Factual Knowledge",
      "category": "knowledge",
      "x": 0.2,
      "y": 0.55,
      "description": "Retrieve and apply specific facts across domains",
      "benchmarks": [
        "trivia_qa"
      ],
      "heights": {
        "2021": 0.758,
        "2022": 0.814,
        "2023": 0.876,
        "2024": 0.829,
        "2019": 0.684,
        "2020": 0.72,
        "2025": 0.854
      },
      "top_models": {
        "2021": [
          {
            "model": "GLaM (MoE)",
            "org": "Google",
            "benchmark": "trivia_qa",
            "score": 0.758,
            "normalized_score": 0.758,
            "date": "2021-12-13"
          }
        ],
        "2022": [
          {
            "model": "PaLM 540B",
            "org": "Google Research",
            "benchmark": "trivia_qa",
            "score": 0.814,
            "normalized_score": 0.814,
            "date": "2022-04-04"
          }
        ],
        "2023": [
          {
            "model": "Llama-2-70b-hf ",
            "org": "Meta AI",
            "benchmark": "trivia_qa",
            "score": 0.876,
            "normalized_score": 0.876,
            "date": "2023-07-18"
          }
        ],
        "2024": [
          {
            "model": "DeepSeek-V3",
            "org": "DeepSeek",
            "benchmark": "trivia_qa",
            "score": 0.829,
            "normalized_score": 0.829,
            "date": "2024-12-26"
          }
        ]
      }
    },
    "unusual_tasks": {
      "name": "Unusual Tasks",
      "category": "reasoning",
      "x": 0.5,
      "y": 0.3,
      "description": "Handle novel or atypical challenges outside standard benchmarks",
      "benchmarks": [
        "weirdml"
      ],
      "heights": {
        "2024": 0.595,
        "2025": 0.611,
        "2019": 0.46,
        "2020": 0.485,
        "2021": 0.51,
        "2022": 0.537,
        "2023": 0.565
      },
      "top_models": {
        "2024": [
          {
            "model": "o1-2024-12-17_high",
            "org": "OpenAI",
            "benchmark": "weirdml",
            "score": 0.5947,
            "normalized_score": 0.5947,
            "date": "2024-12-17"
          }
        ],
        "2025": [
          {
            "model": "gemini-2.5-pro-exp-03-25",
            "org": "Google DeepMind",
            "benchmark": "weirdml",
            "score": 0.6105,
            "normalized_score": 0.6105,
            "date": "2025-03-25"
          }
        ]
      }
    },
    "geographic_knowledge": {
      "name": "Geographic Knowledge",
      "category": "knowledge",
      "x": 0.25,
      "y": 0.5,
      "description": "Understand spatial relationships, locations, and geographic data",
      "benchmarks": [
        "geobench"
      ],
      "heights": {
        "2024": 39.34,
        "2025": 40.93,
        "2019": 30.441,
        "2020": 32.043,
        "2021": 33.729,
        "2022": 35.504,
        "2023": 37.373
      },
      "top_models": {
        "2024": [
          {
            "model": "gemini-1.5-flash-002",
            "org": "Google DeepMind",
            "benchmark": "geobench",
            "score": 3934.0,
            "normalized_score": 39.34,
            "date": "2024-09-24"
          }
        ],
        "2025": [
          {
            "model": "gemini-2.5-pro-exp-03-25",
            "org": "Google DeepMind",
            "benchmark": "geobench",
            "score": 4093.0,
            "normalized_score": 40.93,
            "date": "2025-03-25"
          }
        ]
      }
    },
    "complex_reasoning": {
      "name": "Complex Reasoning",
      "category": "reasoning",
      "x": 0.65,
      "y": 0.45,
      "description": "Navigate multi-layered logical problems requiring synthesis",
      "benchmarks": [
        "bbh"
      ],
      "heights": {
        "2023": 0.751,
        "2024": 0.875,
        "2019": 0.612,
        "2020": 0.644,
        "2021": 0.678,
        "2022": 0.713,
        "2025": 0.901
      },
      "top_models": {
        "2023": [
          {
            "model": "gpt-4-0613",
            "org": "OpenAI",
            "benchmark": "bbh",
            "score": 0.7512,
            "normalized_score": 0.7512,
            "date": "2023-06-13"
          }
        ],
        "2024": [
          {
            "model": "DeepSeek-V3",
            "org": "DeepSeek",
            "benchmark": "bbh",
            "score": 0.875,
            "normalized_score": 0.875,
            "date": "2024-12-26"
          }
        ]
      }
    },
    "spatial_reasoning": {
      "name": "Spatial Reasoning",
      "category": "games",
      "x": 0.55,
      "y": 0.25,
      "description": "Understand and manipulate objects in 2D and 3D space",
      "benchmarks": [
        "gso"
      ],
      "heights": {
        "2024": 0.046,
        "2025": 0.088,
        "2019": 0.036,
        "2020": 0.037,
        "2021": 0.039,
        "2022": 0.042,
        "2023": 0.044
      },
      "top_models": {
        "2024": [
          {
            "model": "claude-3-5-sonnet-20241022",
            "org": "Anthropic",
            "benchmark": "gso",
            "score": 0.046,
            "normalized_score": 0.046,
            "date": "2024-10-22"
          }
        ],
        "2025": [
          {
            "model": "o3-2025-04-16_high",
            "org": "OpenAI",
            "benchmark": "gso",
            "score": 0.088,
            "normalized_score": 0.088,
            "date": "2025-04-16"
          }
        ]
      }
    },
    "cybersecurity": {
      "name": "Cybersecurity",
      "category": "reasoning",
      "x": 0.7,
      "y": 0.2,
      "description": "Identify vulnerabilities and solve security-related challenges",
      "benchmarks": [
        "cybench"
      ],
      "heights": {
        "2024": 0.175,
        "2025": 0.225,
        "2019": 0.135,
        "2020": 0.143,
        "2021": 0.15,
        "2022": 0.158,
        "2023": 0.166
      },
      "top_models": {
        "2024": [
          {
            "model": "claude-3-5-sonnet-20240620",
            "org": "Anthropic",
            "benchmark": "cybench",
            "score": 0.175,
            "normalized_score": 0.175,
            "date": "2024-06-20"
          }
        ],
        "2025": [
          {
            "model": "o3-mini-2025-01-31_medium",
            "org": "OpenAI",
            "benchmark": "cybench",
            "score": 0.225,
            "normalized_score": 0.225,
            "date": "2025-01-31"
          }
        ]
      }
    },
    "language_understanding": {
      "name": "Language Understanding",
      "category": "language",
      "x": 0.4,
      "y": 0.65,
      "description": "Comprehend meaning, context, and nuance in text",
      "benchmarks": [
        "superglue"
      ],
      "heights": {
        "2022": 0.718,
        "2019": 0.616,
        "2020": 0.648,
        "2021": 0.682,
        "2023": 0.74,
        "2024": 0.762,
        "2025": 0.785
      },
      "top_models": {
        "2022": [
          {
            "model": "text-davinci-001",
            "org": "OpenAI",
            "benchmark": "superglue",
            "score": 0.718,
            "normalized_score": 0.718,
            "date": "2022-01-27"
          }
        ]
      }
    },
    "os_navigation": {
      "name": "Os Navigation",
      "category": "agents",
      "x": 0.55,
      "y": 0.85,
      "description": "Find and access files and programs within operating systems",
      "benchmarks": [
        "os_world"
      ],
      "heights": {
        "2023": 0.077,
        "2024": 0.22,
        "2025": 0.381,
        "2019": 0.063,
        "2020": 0.066,
        "2021": 0.069,
        "2022": 0.073
      },
      "top_models": {
        "2023": [
          {
            "model": "gpt-4-1106-vision-preview",
            "org": "OpenAI",
            "benchmark": "os_world",
            "score": 7.69,
            "normalized_score": 0.07690000000000001,
            "date": "2023-11-06"
          }
        ],
        "2024": [
          {
            "model": "claude-3-5-sonnet-20240620",
            "org": "Anthropic",
            "benchmark": "os_world",
            "score": 22.0,
            "normalized_score": 0.22,
            "date": "2024-06-20"
          }
        ],
        "2025": [
          {
            "model": "CUA",
            "org": "OpenAI",
            "benchmark": "os_world",
            "score": 38.1,
            "normalized_score": 0.381,
            "date": "2025-01-23"
          }
        ]
      }
    },
    "natural_language_inference": {
      "name": "Natural Language Inference",
      "category": "language",
      "x": 0.35,
      "y": 0.6,
      "description": "Determine logical relationships between text passages",
      "benchmarks": [
        "adversarial_nli"
      ],
      "heights": {
        "2022": 0.397,
        "2023": 0.581,
        "2024": 0.581,
        "2019": 0.34,
        "2020": 0.358,
        "2021": 0.377,
        "2025": 0.598
      },
      "top_models": {
        "2022": [
          {
            "model": "Megatron-Turing NLG 530B",
            "org": "Microsoft,NVIDIA",
            "benchmark": "adversarial_nli",
            "score": 0.397,
            "normalized_score": 0.397,
            "date": "2022-01-28"
          }
        ],
        "2023": [
          {
            "model": "gpt-3.5-turbo-1106",
            "org": "OpenAI",
            "benchmark": "adversarial_nli",
            "score": 0.581,
            "normalized_score": 0.581,
            "date": "2023-11-06"
          }
        ],
        "2024": [
          {
            "model": "Phi-3-small-8k-instruct",
            "org": "Microsoft",
            "benchmark": "adversarial_nli",
            "score": 0.581,
            "normalized_score": 0.581,
            "date": "2024-04-23"
          }
        ]
      }
    },
    "agent_reasoning": {
      "name": "Agent Reasoning",
      "category": "agents",
      "x": 0.5,
      "y": 0.8,
      "description": "Plan and execute multi-step tasks autonomously",
      "benchmarks": [
        "the_agent_company"
      ],
      "heights": {
        "2024": 0.344,
        "2025": 0.19,
        "2019": 0.266,
        "2020": 0.28,
        "2021": 0.295,
        "2022": 0.31,
        "2023": 0.327
      },
      "top_models": {
        "2024": [
          {
            "model": "claude-3-5-sonnet-20241022",
            "org": "Anthropic",
            "benchmark": "the_agent_company",
            "score": 0.344,
            "normalized_score": 0.344,
            "date": "2024-10-22"
          }
        ],
        "2025": [
          {
            "model": "gemini-2.0-flash-001",
            "org": "Google DeepMind,Google",
            "benchmark": "the_agent_company",
            "score": 0.19,
            "normalized_score": 0.19,
            "date": "2025-02-05"
          }
        ]
      }
    },
    "boolean_reasoning": {
      "name": "Boolean Reasoning",
      "category": "reasoning",
      "x": 0.4,
      "y": 0.5,
      "description": "Answer yes/no questions requiring logical deduction",
      "benchmarks": [
        "bool_q"
      ],
      "heights": {
        "2019": 0.618,
        "2021": 0.794,
        "2022": 0.887,
        "2023": 0.909,
        "2024": 0.887,
        "2020": 0.706,
        "2025": 0.914
      },
      "top_models": {
        "2019": [
          {
            "model": "gpt2-xl",
            "org": "OpenAI",
            "benchmark": "bool_q",
            "score": 0.618,
            "normalized_score": 0.618,
            "date": "2019-11-05"
          }
        ],
        "2021": [
          {
            "model": "Gopher (280B)",
            "org": "DeepMind",
            "benchmark": "bool_q",
            "score": 0.794,
            "normalized_score": 0.794,
            "date": "2021-12-08"
          }
        ],
        "2022": [
          {
            "model": "PaLM 540B",
            "org": "Google Research",
            "benchmark": "bool_q",
            "score": 0.887,
            "normalized_score": 0.887,
            "date": "2022-04-04"
          }
        ],
        "2023": [
          {
            "model": "PaLM 2-L",
            "org": null,
            "benchmark": "bool_q",
            "score": 0.909,
            "normalized_score": 0.909,
            "date": "2023-05-17"
          }
        ],
        "2024": [
          {
            "model": "gpt-4o-mini-2024-07-18",
            "org": "OpenAI",
            "benchmark": "bool_q",
            "score": 0.887,
            "normalized_score": 0.887,
            "date": "2024-07-18"
          }
        ]
      }
    },
    "language_modeling": {
      "name": "Language Modeling",
      "category": "language",
      "x": 0.3,
      "y": 0.7,
      "description": "Predict and generate coherent natural language sequences",
      "benchmarks": [
        "lambada"
      ],
      "heights": {
        "2021": 0.745,
        "2022": 0.872,
        "2023": 0.798,
        "2019": 0.672,
        "2020": 0.708,
        "2024": 0.822,
        "2025": 0.847
      },
      "top_models": {
        "2021": [
          {
            "model": "Gopher (280B)",
            "org": "DeepMind",
            "benchmark": "lambada",
            "score": 0.745,
            "normalized_score": 0.745,
            "date": "2021-12-08"
          }
        ],
        "2022": [
          {
            "model": "Megatron-Turing NLG 530B",
            "org": "Microsoft,NVIDIA",
            "benchmark": "lambada",
            "score": 0.8715,
            "normalized_score": 0.8715,
            "date": "2022-01-28"
          }
        ],
        "2023": [
          {
            "model": "falcon-180B",
            "org": "Technology Innovation Institute",
            "benchmark": "lambada",
            "score": 0.798,
            "normalized_score": 0.798,
            "date": "2023-09-06"
          }
        ]
      }
    },
    "terminal_usage": {
      "name": "Terminal Usage",
      "category": "agents",
      "x": 0.45,
      "y": 0.85,
      "description": "Execute commands and navigate command-line interfaces",
      "benchmarks": [
        "terminalbench"
      ],
      "heights": {
        "2025": 0.603,
        "2019": 0.443,
        "2020": 0.467,
        "2021": 0.491,
        "2022": 0.517,
        "2023": 0.544,
        "2024": 0.573
      },
      "top_models": {
        "2025": [
          {
            "model": "claude-sonnet-4-5-20250929",
            "org": "Anthropic",
            "benchmark": "terminalbench",
            "score": 0.603,
            "normalized_score": 0.603,
            "date": "2025-09-29"
          }
        ]
      }
    }
  },
  "openai": {
    "code_generation": {
      "name": "Code Generation",
      "category": "coding",
      "x": 0.65,
      "y": 0.5,
      "description": "Generate functional code from natural language descriptions",
      "benchmarks": [
        "aider_polyglot",
        "swe_bench_verified",
        "live_bench"
      ],
      "heights": {
        "2024": 0.464,
        "2025": 0.554,
        "2019": 0.359,
        "2020": 0.378,
        "2021": 0.398,
        "2022": 0.419,
        "2023": 0.441
      },
      "top_models": {
        "2024": [
          {
            "model": "o1-2024-12-17_high",
            "org": "OpenAI",
            "benchmark": "live_bench",
            "score": 75.67,
            "normalized_score": 0.7567,
            "date": "2024-12-17"
          },
          {
            "model": "o1-2024-12-17_high",
            "org": "OpenAI",
            "benchmark": "aider_polyglot",
            "score": 61.7,
            "normalized_score": 0.617,
            "date": "2024-12-17"
          },
          {
            "model": "gpt-4o-2024-11-20",
            "org": "OpenAI",
            "benchmark": "swe_bench_verified",
            "score": 0.0194865968016434,
            "normalized_score": 0.0194865968016434,
            "date": "2024-11-20"
          }
        ],
        "2025": [
          {
            "model": "gpt-5-2025-08-07_high",
            "org": "OpenAI",
            "benchmark": "aider_polyglot",
            "score": 88.0,
            "normalized_score": 0.88,
            "date": "2025-08-07"
          },
          {
            "model": "o3-mini-2025-01-31_high",
            "org": "OpenAI",
            "benchmark": "live_bench",
            "score": 75.88,
            "normalized_score": 0.7587999999999999,
            "date": "2025-01-31"
          },
          {
            "model": "o3-2025-04-16_medium",
            "org": "OpenAI",
            "benchmark": "swe_bench_verified",
            "score": 0.0222262497331002,
            "normalized_score": 0.0222262497331002,
            "date": "2025-04-16"
          }
        ]
      }
    },
    "physical_intuition": {
      "name": "Physical Intuition",
      "category": "reasoning",
      "x": 0.5,
      "y": 0.5,
      "description": "Apply understanding of physical laws and object behavior",
      "benchmarks": [
        "piqa"
      ],
      "heights": {
        "2019": 0.705,
        "2022": 0.823,
        "2024": 0.887,
        "2020": 0.744,
        "2021": 0.784,
        "2023": 0.855,
        "2025": 0.914
      },
      "top_models": {
        "2019": [
          {
            "model": "gpt2-xl",
            "org": "OpenAI",
            "benchmark": "piqa",
            "score": 0.705,
            "normalized_score": 0.705,
            "date": "2019-11-05"
          }
        ],
        "2022": [
          {
            "model": "text-davinci-001",
            "org": "OpenAI",
            "benchmark": "piqa",
            "score": 0.823,
            "normalized_score": 0.823,
            "date": "2022-01-27"
          }
        ],
        "2024": [
          {
            "model": "gpt-4o-mini-2024-07-18",
            "org": "OpenAI",
            "benchmark": "piqa",
            "score": 0.887,
            "normalized_score": 0.887,
            "date": "2024-07-18"
          }
        ]
      }
    },
    "scientific_reasoning": {
      "name": "Scientific Reasoning",
      "category": "knowledge",
      "x": 0.3,
      "y": 0.55,
      "description": "Apply scientific methods and domain knowledge to problems",
      "benchmarks": [
        "science_qa"
      ],
      "heights": {
        "2022": 0.74,
        "2024": 0.885,
        "2023": 0.812,
        "2019": 0.634,
        "2020": 0.668,
        "2021": 0.703,
        "2025": 0.912
      },
      "top_models": {
        "2022": [
          {
            "model": "text-davinci-001",
            "org": "OpenAI",
            "benchmark": "science_qa",
            "score": 0.7404,
            "normalized_score": 0.7404,
            "date": "2022-01-27"
          }
        ],
        "2024": [
          {
            "model": "gpt-4o-2024-05-13",
            "org": "OpenAI",
            "benchmark": "science_qa",
            "score": 0.885,
            "normalized_score": 0.885,
            "date": "2024-05-13"
          }
        ]
      }
    },
    "game_strategy": {
      "name": "Game Strategy",
      "category": "games",
      "x": 0.6,
      "y": 0.2,
      "description": "Develop winning approaches in strategic games",
      "benchmarks": [
        "factorio_learning_environment"
      ],
      "heights": {
        "2024": 875.99,
        "2019": 677.824,
        "2020": 713.499,
        "2021": 751.052,
        "2022": 790.581,
        "2023": 832.19,
        "2025": 1.0
      },
      "top_models": {
        "2024": [
          {
            "model": "gpt-4o-2024-11-20",
            "org": "OpenAI",
            "benchmark": "factorio_learning_environment",
            "score": 87599.0,
            "normalized_score": 875.99,
            "date": "2024-11-20"
          }
        ]
      }
    },
    "commonsense_reasoning": {
      "name": "Commonsense Reasoning",
      "category": "reasoning",
      "x": 0.45,
      "y": 0.55,
      "description": "Apply everyday knowledge and intuitive logic",
      "benchmarks": [
        "common_sense_qa_2",
        "wino_grande",
        "arc_ai2",
        "hella_swag"
      ],
      "heights": {
        "2019": 0.411,
        "2022": 0.763,
        "2023": 0.818,
        "2020": 0.528,
        "2021": 0.646,
        "2024": 0.843,
        "2025": 0.868
      },
      "top_models": {
        "2019": [
          {
            "model": "gpt2-xl",
            "org": "OpenAI",
            "benchmark": "wino_grande",
            "score": 0.583,
            "normalized_score": 0.583,
            "date": "2019-11-05"
          },
          {
            "model": "gpt2-xl",
            "org": "OpenAI",
            "benchmark": "hella_swag",
            "score": 0.4,
            "normalized_score": 0.4,
            "date": "2019-11-05"
          },
          {
            "model": "gpt2-xl",
            "org": "OpenAI",
            "benchmark": "arc_ai2",
            "score": 0.25,
            "normalized_score": 0.25,
            "date": "2019-11-05"
          }
        ],
        "2022": [
          {
            "model": "text-davinci-003",
            "org": "OpenAI",
            "benchmark": "hella_swag",
            "score": 0.855,
            "normalized_score": 0.855,
            "date": "2022-11-28"
          },
          {
            "model": "text-davinci-002",
            "org": "OpenAI",
            "benchmark": "arc_ai2",
            "score": 0.852,
            "normalized_score": 0.852,
            "date": "2022-03-15"
          },
          {
            "model": "text-davinci-002",
            "org": "OpenAI",
            "benchmark": "wino_grande",
            "score": 0.816,
            "normalized_score": 0.816,
            "date": "2022-03-15"
          },
          {
            "model": "text-davinci-001",
            "org": "OpenAI",
            "benchmark": "common_sense_qa_2",
            "score": 0.529,
            "normalized_score": 0.529,
            "date": "2022-01-27"
          }
        ],
        "2023": [
          {
            "model": "gpt-4-0314",
            "org": "OpenAI",
            "benchmark": "hella_swag",
            "score": 0.953,
            "normalized_score": 0.953,
            "date": "2023-03-14"
          },
          {
            "model": "gpt-4-32k-0314",
            "org": "OpenAI",
            "benchmark": "hella_swag",
            "score": 0.953,
            "normalized_score": 0.953,
            "date": "2023-03-14"
          },
          {
            "model": "gpt-4-0314",
            "org": "OpenAI",
            "benchmark": "wino_grande",
            "score": 0.875,
            "normalized_score": 0.875,
            "date": "2023-03-14"
          },
          {
            "model": "gpt-4-32k-0314",
            "org": "OpenAI",
            "benchmark": "wino_grande",
            "score": 0.875,
            "normalized_score": 0.875,
            "date": "2023-03-14"
          },
          {
            "model": "gpt-3.5-turbo-1106",
            "org": "OpenAI",
            "benchmark": "arc_ai2",
            "score": 0.874,
            "normalized_score": 0.874,
            "date": "2023-11-06"
          },
          {
            "model": "gpt-3.5-turbo-0613",
            "org": "OpenAI",
            "benchmark": "common_sense_qa_2",
            "score": 0.57,
            "normalized_score": 0.57,
            "date": "2023-06-13"
          }
        ]
      }
    },
    "reading_comprehension": {
      "name": "Reading Comprehension",
      "category": "language",
      "x": 0.35,
      "y": 0.65,
      "description": "Extract meaning and answer questions from written passages",
      "benchmarks": [
        "open_book_qa"
      ],
      "heights": {
        "2019": 0.224,
        "2022": 0.654,
        "2023": 0.86,
        "2020": 0.367,
        "2021": 0.511,
        "2024": 0.886,
        "2025": 0.912
      },
      "top_models": {
        "2019": [
          {
            "model": "gpt2-xl",
            "org": "OpenAI",
            "benchmark": "open_book_qa",
            "score": 0.224,
            "normalized_score": 0.224,
            "date": "2019-11-05"
          }
        ],
        "2022": [
          {
            "model": "text-davinci-001",
            "org": "OpenAI",
            "benchmark": "open_book_qa",
            "score": 0.654,
            "normalized_score": 0.654,
            "date": "2022-01-27"
          }
        ],
        "2023": [
          {
            "model": "gpt-3.5-turbo-1106",
            "org": "OpenAI",
            "benchmark": "open_book_qa",
            "score": 0.86,
            "normalized_score": 0.86,
            "date": "2023-11-06"
          }
        ]
      }
    },
    "game_playing": {
      "name": "Game Playing",
      "category": "games",
      "x": 0.65,
      "y": 0.25,
      "description": "Learn and execute strategies in game environments",
      "benchmarks": [
        "balrog"
      ],
      "heights": {
        "2024": 0.323,
        "2025": 0.328,
        "2019": 0.25,
        "2020": 0.263,
        "2021": 0.277,
        "2022": 0.292,
        "2023": 0.307
      },
      "top_models": {
        "2024": [
          {
            "model": "gpt-4o-2024-05-13",
            "org": "OpenAI",
            "benchmark": "balrog",
            "score": 0.323,
            "normalized_score": 0.323,
            "date": "2024-05-13"
          }
        ],
        "2025": [
          {
            "model": "gpt-5-2025-08-07_minimal",
            "org": "OpenAI",
            "benchmark": "balrog",
            "score": 0.328,
            "normalized_score": 0.328,
            "date": "2025-08-07"
          }
        ]
      }
    },
    "creative_writing": {
      "name": "Creative Writing",
      "category": "language",
      "x": 0.2,
      "y": 0.3,
      "description": "Generate original, engaging narrative and expressive text",
      "benchmarks": [
        "fictionlivebench"
      ],
      "heights": {
        "2024": 0.531,
        "2025": 1.0,
        "2019": 0.411,
        "2020": 0.433,
        "2021": 0.455,
        "2022": 0.479,
        "2023": 0.504
      },
      "top_models": {
        "2024": [
          {
            "model": "o1-2024-12-17_medium",
            "org": "OpenAI",
            "benchmark": "fictionlivebench",
            "score": 0.531,
            "normalized_score": 0.531,
            "date": "2024-12-17"
          }
        ],
        "2025": [
          {
            "model": "o3-2025-04-16_medium",
            "org": "OpenAI",
            "benchmark": "fictionlivebench",
            "score": 1.0,
            "normalized_score": 1.0,
            "date": "2025-04-16"
          }
        ]
      }
    },
    "competition_math": {
      "name": "Competition Math",
      "category": "mathematics",
      "x": 0.85,
      "y": 0.45,
      "description": "Solve competition-level mathematics problems (AMC, AIME, IMO)",
      "benchmarks": [
        "otis_mock_aime_2024_2025"
      ],
      "heights": {
        "2023": 0.005,
        "2024": 0.07,
        "2025": 0.073,
        "2019": 0.004,
        "2020": 0.004,
        "2021": 0.005,
        "2022": 0.005
      },
      "top_models": {
        "2023": [
          {
            "model": "gpt-4-0613",
            "org": "OpenAI",
            "benchmark": "otis_mock_aime_2024_2025",
            "score": 0.0053628183286856,
            "normalized_score": 0.0053628183286856,
            "date": "2023-06-13"
          }
        ],
        "2024": [
          {
            "model": "o1-preview-2024-09-12",
            "org": "OpenAI",
            "benchmark": "otis_mock_aime_2024_2025",
            "score": 0.0697920592732311,
            "normalized_score": 0.0697920592732311,
            "date": "2024-09-12"
          }
        ],
        "2025": [
          {
            "model": "gpt-4.5-preview-2025-02-27",
            "org": "OpenAI",
            "benchmark": "otis_mock_aime_2024_2025",
            "score": 0.0730911212732345,
            "normalized_score": 0.0730911212732345,
            "date": "2025-02-27"
          }
        ]
      }
    },
    "advanced_reasoning": {
      "name": "Advanced Reasoning",
      "category": "reasoning",
      "x": 0.7,
      "y": 0.4,
      "description": "Handle complex multi-step reasoning across diverse domains",
      "benchmarks": [
        "gpqa_diamond"
      ],
      "heights": {
        "2023": 0.024,
        "2024": 0.031,
        "2025": 0.033,
        "2019": 0.02,
        "2020": 0.021,
        "2021": 0.022,
        "2022": 0.023
      },
      "top_models": {
        "2023": [
          {
            "model": "gpt-4-1106-preview",
            "org": "OpenAI",
            "benchmark": "gpqa_diamond",
            "score": 0.0240761426183016,
            "normalized_score": 0.0240761426183016,
            "date": "2023-11-06"
          }
        ],
        "2024": [
          {
            "model": "o1-2024-12-17_medium",
            "org": "OpenAI",
            "benchmark": "gpqa_diamond",
            "score": 0.030532892233932,
            "normalized_score": 0.030532892233932,
            "date": "2024-12-17"
          }
        ],
        "2025": [
          {
            "model": "gpt-4.5-preview-2025-02-27",
            "org": "OpenAI",
            "benchmark": "gpqa_diamond",
            "score": 0.0330420508781365,
            "normalized_score": 0.0330420508781365,
            "date": "2025-02-27"
          }
        ]
      }
    },
    "mathematical_reasoning": {
      "name": "Mathematical Reasoning",
      "category": "mathematics",
      "x": 0.75,
      "y": 0.45,
      "description": "Solve math problems with step-by-step logical reasoning",
      "benchmarks": [
        "math_level_5",
        "gsm8k"
      ],
      "heights": {
        "2022": 0.782,
        "2023": 0.465,
        "2024": 0.462,
        "2025": 0.011,
        "2019": 0.67,
        "2020": 0.706,
        "2021": 0.743
      },
      "top_models": {
        "2022": [
          {
            "model": "text-davinci-003",
            "org": "OpenAI",
            "benchmark": "gsm8k",
            "score": 0.782,
            "normalized_score": 0.782,
            "date": "2022-11-28"
          }
        ],
        "2023": [
          {
            "model": "gpt-4-0314",
            "org": "OpenAI",
            "benchmark": "gsm8k",
            "score": 0.92,
            "normalized_score": 0.92,
            "date": "2023-03-14"
          },
          {
            "model": "gpt-4-1106-preview",
            "org": "OpenAI",
            "benchmark": "math_level_5",
            "score": 0.0105387946323973,
            "normalized_score": 0.0105387946323973,
            "date": "2023-11-06"
          }
        ],
        "2024": [
          {
            "model": "gpt-4o-mini-2024-07-18",
            "org": "OpenAI",
            "benchmark": "gsm8k",
            "score": 0.913,
            "normalized_score": 0.913,
            "date": "2024-07-18"
          },
          {
            "model": "gpt-4-turbo-2024-04-09",
            "org": "OpenAI",
            "benchmark": "math_level_5",
            "score": 0.0114282589303959,
            "normalized_score": 0.0114282589303959,
            "date": "2024-04-09"
          }
        ],
        "2025": [
          {
            "model": "gpt-4.5-preview-2025-02-27",
            "org": "OpenAI",
            "benchmark": "math_level_5",
            "score": 0.0112706944281362,
            "normalized_score": 0.0112706944281362,
            "date": "2025-02-27"
          }
        ]
      }
    },
    "long_horizon_planning": {
      "name": "Long Horizon Planning",
      "category": "reasoning",
      "x": 0.55,
      "y": 0.75,
      "description": "Plan and reason about extended sequences of actions",
      "benchmarks": [
        "metr_time_horizons"
      ],
      "heights": {
        "2019": 0.101,
        "2023": 0.404,
        "2024": 0.559,
        "2025": 0.696,
        "2020": 0.177,
        "2021": 0.253,
        "2022": 0.328
      },
      "top_models": {
        "2019": [
          {
            "model": "gpt2-xl",
            "org": "OpenAI",
            "benchmark": "metr_time_horizons",
            "score": 0.101046,
            "normalized_score": 0.101046,
            "date": "2019-11-05"
          }
        ],
        "2023": [
          {
            "model": "gpt-4-1106-preview",
            "org": "OpenAI",
            "benchmark": "metr_time_horizons",
            "score": 0.404329,
            "normalized_score": 0.404329,
            "date": "2023-11-06"
          }
        ],
        "2024": [
          {
            "model": "o1-2024-12-17_medium",
            "org": "OpenAI",
            "benchmark": "metr_time_horizons",
            "score": 0.55932,
            "normalized_score": 0.55932,
            "date": "2024-12-17"
          }
        ],
        "2025": [
          {
            "model": "gpt-5-2025-08-07_medium",
            "org": "OpenAI",
            "benchmark": "metr_time_horizons",
            "score": 0.696053,
            "normalized_score": 0.696053,
            "date": "2025-08-07"
          }
        ]
      }
    },
    "writing_quality": {
      "name": "Writing Quality",
      "category": "language",
      "x": 0.25,
      "y": 0.35,
      "description": "Produce well-structured, grammatically correct, compelling text",
      "benchmarks": [
        "lech_mazur_writing"
      ],
      "heights": {
        "2024": 0.082,
        "2025": 0.084,
        "2019": 0.063,
        "2020": 0.067,
        "2021": 0.07,
        "2022": 0.074,
        "2023": 0.078
      },
      "top_models": {
        "2024": [
          {
            "model": "gpt-4o-2024-11-20",
            "org": "OpenAI",
            "benchmark": "lech_mazur_writing",
            "score": 8.18,
            "normalized_score": 0.0818,
            "date": "2024-11-20"
          }
        ],
        "2025": [
          {
            "model": "o3-2025-04-16_medium",
            "org": "OpenAI",
            "benchmark": "lech_mazur_writing",
            "score": 8.39,
            "normalized_score": 0.0839,
            "date": "2025-04-16"
          }
        ]
      }
    },
    "cad_design": {
      "name": "Cad Design",
      "category": "reasoning",
      "x": 0.75,
      "y": 0.25,
      "description": "Create and manipulate computer-aided design models",
      "benchmarks": [
        "cad_eval"
      ],
      "heights": {
        "2024": 0.56,
        "2025": 0.74,
        "2019": 0.433,
        "2020": 0.456,
        "2021": 0.48,
        "2022": 0.505,
        "2023": 0.532
      },
      "top_models": {
        "2024": [
          {
            "model": "o1-2024-12-17_medium",
            "org": "OpenAI",
            "benchmark": "cad_eval",
            "score": 0.56,
            "normalized_score": 0.56,
            "date": "2024-12-17"
          }
        ],
        "2025": [
          {
            "model": "o3-2025-04-16_medium",
            "org": "OpenAI",
            "benchmark": "cad_eval",
            "score": 0.74,
            "normalized_score": 0.74,
            "date": "2025-04-16"
          }
        ]
      }
    },
    "advanced_mathematics": {
      "name": "Advanced Mathematics",
      "category": "mathematics",
      "x": 0.8,
      "y": 0.4,
      "description": "Solve graduate-level and research mathematics problems",
      "benchmarks": [
        "frontiermath",
        "frontiermath_tier_4"
      ],
      "heights": {
        "2024": 0.017,
        "2025": 0.037,
        "2019": 0.013,
        "2020": 0.014,
        "2021": 0.015,
        "2022": 0.015,
        "2023": 0.016
      },
      "top_models": {
        "2024": [
          {
            "model": "o1-2024-12-17_high",
            "org": "OpenAI",
            "benchmark": "frontiermath",
            "score": 0.0170927852801478,
            "normalized_score": 0.0170927852801478,
            "date": "2024-12-17"
          }
        ],
        "2025": [
          {
            "model": "gpt-5-2025-08-07_high",
            "org": "OpenAI",
            "benchmark": "frontiermath_tier_4",
            "score": 0.0482403115617474,
            "normalized_score": 0.0482403115617474,
            "date": "2025-08-07"
          },
          {
            "model": "gpt-5-2025-08-07_high",
            "org": "OpenAI",
            "benchmark": "frontiermath",
            "score": 0.0259769551791457,
            "normalized_score": 0.0259769551791457,
            "date": "2025-08-07"
          }
        ]
      }
    },
    "abstract_reasoning": {
      "name": "Abstract Reasoning",
      "category": "reasoning",
      "x": 0.75,
      "y": 0.35,
      "description": "Recognize patterns and solve problems requiring high-level conceptual thinking",
      "benchmarks": [
        "arc_agi"
      ],
      "heights": {
        "2024": 0.307,
        "2025": 0.608,
        "2019": 0.238,
        "2020": 0.25,
        "2021": 0.263,
        "2022": 0.277,
        "2023": 0.292
      },
      "top_models": {
        "2024": [
          {
            "model": "o1-2024-12-17_medium",
            "org": "OpenAI",
            "benchmark": "arc_agi",
            "score": 0.307,
            "normalized_score": 0.307,
            "date": "2024-12-17"
          }
        ],
        "2025": [
          {
            "model": "o3-2025-04-16_high",
            "org": "OpenAI",
            "benchmark": "arc_agi",
            "score": 0.608,
            "normalized_score": 0.608,
            "date": "2025-04-16"
          }
        ]
      }
    },
    "basic_tasks": {
      "name": "Basic Tasks",
      "category": "reasoning",
      "x": 0.4,
      "y": 0.4,
      "description": "Perform fundamental operations and simple problem-solving",
      "benchmarks": [
        "simplebench"
      ],
      "heights": {
        "2024": 0.417,
        "2025": 0.611,
        "2019": 0.323,
        "2020": 0.34,
        "2021": 0.358,
        "2022": 0.376,
        "2023": 0.396
      },
      "top_models": {
        "2024": [
          {
            "model": "o1-preview-2024-09-12",
            "org": "OpenAI",
            "benchmark": "simplebench",
            "score": 0.417,
            "normalized_score": 0.417,
            "date": "2024-09-12"
          }
        ],
        "2025": [
          {
            "model": "gpt-5-pro-2025-10-06_high",
            "org": "OpenAI",
            "benchmark": "simplebench",
            "score": 0.611,
            "normalized_score": 0.611,
            "date": "2025-10-07"
          }
        ]
      }
    },
    "general_knowledge": {
      "name": "General Knowledge",
      "category": "knowledge",
      "x": 0.25,
      "y": 0.6,
      "description": "Answer questions across diverse academic and cultural domains",
      "benchmarks": [
        "mmlu"
      ],
      "heights": {
        "2022": 0.7,
        "2023": 0.864,
        "2024": 0.881,
        "2019": 0.6,
        "2020": 0.632,
        "2021": 0.665,
        "2025": 0.907
      },
      "top_models": {
        "2022": [
          {
            "model": "text-davinci-002",
            "org": "OpenAI",
            "benchmark": "mmlu",
            "score": 0.7,
            "normalized_score": 0.7,
            "date": "2022-03-15"
          }
        ],
        "2023": [
          {
            "model": "gpt-4-0314",
            "org": "OpenAI",
            "benchmark": "mmlu",
            "score": 0.864,
            "normalized_score": 0.864,
            "date": "2023-03-14"
          }
        ],
        "2024": [
          {
            "model": "gpt-4o-2024-11-20",
            "org": "OpenAI",
            "benchmark": "mmlu",
            "score": 0.881,
            "normalized_score": 0.881,
            "date": "2024-11-20"
          }
        ]
      }
    },
    "os_interaction": {
      "name": "Os Interaction",
      "category": "agents",
      "x": 0.6,
      "y": 0.8,
      "description": "Navigate and manipulate operating system interfaces",
      "benchmarks": [
        "os_universe"
      ],
      "heights": {
        "2024": 0.068,
        "2019": 0.053,
        "2020": 0.055,
        "2021": 0.058,
        "2022": 0.061,
        "2023": 0.065,
        "2025": 0.07
      },
      "top_models": {
        "2024": [
          {
            "model": "gpt-4o-2024-11-20",
            "org": "OpenAI",
            "benchmark": "os_universe",
            "score": 0.0679,
            "normalized_score": 0.0679,
            "date": "2024-11-20"
          }
        ]
      }
    },
    "factual_knowledge": {
      "name": "Factual Knowledge",
      "category": "knowledge",
      "x": 0.2,
      "y": 0.55,
      "description": "Retrieve and apply specific facts across domains",
      "benchmarks": [
        "trivia_qa"
      ],
      "heights": {
        "2022": 0.712,
        "2023": 0.858,
        "2019": 0.61,
        "2020": 0.643,
        "2021": 0.676,
        "2024": 0.884,
        "2025": 0.91
      },
      "top_models": {
        "2022": [
          {
            "model": "text-davinci-001",
            "org": "OpenAI",
            "benchmark": "trivia_qa",
            "score": 0.712,
            "normalized_score": 0.712,
            "date": "2022-01-27"
          }
        ],
        "2023": [
          {
            "model": "gpt-3.5-turbo-1106",
            "org": "OpenAI",
            "benchmark": "trivia_qa",
            "score": 0.858,
            "normalized_score": 0.858,
            "date": "2023-11-06"
          }
        ]
      }
    },
    "unusual_tasks": {
      "name": "Unusual Tasks",
      "category": "reasoning",
      "x": 0.5,
      "y": 0.3,
      "description": "Handle novel or atypical challenges outside standard benchmarks",
      "benchmarks": [
        "weirdml"
      ],
      "heights": {
        "2024": 0.595,
        "2025": 0.603,
        "2019": 0.46,
        "2020": 0.485,
        "2021": 0.51,
        "2022": 0.537,
        "2023": 0.565
      },
      "top_models": {
        "2024": [
          {
            "model": "o1-2024-12-17_high",
            "org": "OpenAI",
            "benchmark": "weirdml",
            "score": 0.5947,
            "normalized_score": 0.5947,
            "date": "2024-12-17"
          }
        ],
        "2025": [
          {
            "model": "gpt-4.5-preview-2025-02-27",
            "org": "OpenAI",
            "benchmark": "weirdml",
            "score": 0.6026,
            "normalized_score": 0.6026,
            "date": "2025-02-27"
          }
        ]
      }
    },
    "geographic_knowledge": {
      "name": "Geographic Knowledge",
      "category": "knowledge",
      "x": 0.25,
      "y": 0.5,
      "description": "Understand spatial relationships, locations, and geographic data",
      "benchmarks": [
        "geobench"
      ],
      "heights": {
        "2024": 39.25,
        "2025": 39.37,
        "2019": 30.371,
        "2020": 31.969,
        "2021": 33.652,
        "2022": 35.423,
        "2023": 37.288
      },
      "top_models": {
        "2024": [
          {
            "model": "o1-2024-12-17_medium",
            "org": "OpenAI",
            "benchmark": "geobench",
            "score": 3925.0,
            "normalized_score": 39.25,
            "date": "2024-12-17"
          }
        ],
        "2025": [
          {
            "model": "gpt-5-2025-08-07_medium",
            "org": "OpenAI",
            "benchmark": "geobench",
            "score": 3937.0,
            "normalized_score": 39.37,
            "date": "2025-08-07"
          }
        ]
      }
    },
    "complex_reasoning": {
      "name": "Complex Reasoning",
      "category": "reasoning",
      "x": 0.65,
      "y": 0.45,
      "description": "Navigate multi-layered logical problems requiring synthesis",
      "benchmarks": [
        "bbh"
      ],
      "heights": {
        "2023": 0.751,
        "2019": 0.612,
        "2020": 0.644,
        "2021": 0.678,
        "2022": 0.713,
        "2024": 0.774,
        "2025": 0.797
      },
      "top_models": {
        "2023": [
          {
            "model": "gpt-4-0613",
            "org": "OpenAI",
            "benchmark": "bbh",
            "score": 0.7512,
            "normalized_score": 0.7512,
            "date": "2023-06-13"
          }
        ]
      }
    },
    "spatial_reasoning": {
      "name": "Spatial Reasoning",
      "category": "games",
      "x": 0.55,
      "y": 0.25,
      "description": "Understand and manipulate objects in 2D and 3D space",
      "benchmarks": [
        "gso"
      ],
      "heights": {
        "2024": 0.0,
        "2025": 0.088,
        "2019": 0.0,
        "2020": 0.0,
        "2021": 0.0,
        "2022": 0.0,
        "2023": 0.0
      },
      "top_models": {
        "2024": [
          {
            "model": "gpt-4o-2024-11-20",
            "org": "OpenAI",
            "benchmark": "gso",
            "score": 0.0,
            "normalized_score": 0.0,
            "date": "2024-11-20"
          }
        ],
        "2025": [
          {
            "model": "o3-2025-04-16_high",
            "org": "OpenAI",
            "benchmark": "gso",
            "score": 0.088,
            "normalized_score": 0.088,
            "date": "2025-04-16"
          }
        ]
      }
    },
    "cybersecurity": {
      "name": "Cybersecurity",
      "category": "reasoning",
      "x": 0.7,
      "y": 0.2,
      "description": "Identify vulnerabilities and solve security-related challenges",
      "benchmarks": [
        "cybench"
      ],
      "heights": {
        "2024": 0.125,
        "2025": 0.225,
        "2019": 0.097,
        "2020": 0.102,
        "2021": 0.107,
        "2022": 0.113,
        "2023": 0.119
      },
      "top_models": {
        "2024": [
          {
            "model": "gpt-4o-2024-11-20",
            "org": "OpenAI",
            "benchmark": "cybench",
            "score": 0.125,
            "normalized_score": 0.125,
            "date": "2024-11-20"
          }
        ],
        "2025": [
          {
            "model": "o3-mini-2025-01-31_medium",
            "org": "OpenAI",
            "benchmark": "cybench",
            "score": 0.225,
            "normalized_score": 0.225,
            "date": "2025-01-31"
          }
        ]
      }
    },
    "language_understanding": {
      "name": "Language Understanding",
      "category": "language",
      "x": 0.4,
      "y": 0.65,
      "description": "Comprehend meaning, context, and nuance in text",
      "benchmarks": [
        "superglue"
      ],
      "heights": {
        "2022": 0.718,
        "2019": 0.616,
        "2020": 0.648,
        "2021": 0.682,
        "2023": 0.74,
        "2024": 0.762,
        "2025": 0.785
      },
      "top_models": {
        "2022": [
          {
            "model": "text-davinci-001",
            "org": "OpenAI",
            "benchmark": "superglue",
            "score": 0.718,
            "normalized_score": 0.718,
            "date": "2022-01-27"
          }
        ]
      }
    },
    "os_navigation": {
      "name": "Os Navigation",
      "category": "agents",
      "x": 0.55,
      "y": 0.85,
      "description": "Find and access files and programs within operating systems",
      "benchmarks": [
        "os_world"
      ],
      "heights": {
        "2023": 0.077,
        "2024": 0.054,
        "2025": 0.381,
        "2019": 0.063,
        "2020": 0.066,
        "2021": 0.069,
        "2022": 0.073
      },
      "top_models": {
        "2023": [
          {
            "model": "gpt-4-1106-vision-preview",
            "org": "OpenAI",
            "benchmark": "os_world",
            "score": 7.69,
            "normalized_score": 0.07690000000000001,
            "date": "2023-11-06"
          }
        ],
        "2024": [
          {
            "model": "gpt-4-turbo-2024-04-09",
            "org": "OpenAI",
            "benchmark": "os_world",
            "score": 5.4,
            "normalized_score": 0.054000000000000006,
            "date": "2024-04-09"
          }
        ],
        "2025": [
          {
            "model": "CUA",
            "org": "OpenAI",
            "benchmark": "os_world",
            "score": 38.1,
            "normalized_score": 0.381,
            "date": "2025-01-23"
          }
        ]
      }
    },
    "natural_language_inference": {
      "name": "Natural Language Inference",
      "category": "language",
      "x": 0.35,
      "y": 0.6,
      "description": "Determine logical relationships between text passages",
      "benchmarks": [
        "adversarial_nli"
      ],
      "heights": {
        "2022": 0.354,
        "2023": 0.581,
        "2019": 0.304,
        "2020": 0.319,
        "2021": 0.336,
        "2024": 0.598,
        "2025": 0.616
      },
      "top_models": {
        "2022": [
          {
            "model": "text-davinci-001",
            "org": "OpenAI",
            "benchmark": "adversarial_nli",
            "score": 0.354,
            "normalized_score": 0.354,
            "date": "2022-01-27"
          }
        ],
        "2023": [
          {
            "model": "gpt-3.5-turbo-1106",
            "org": "OpenAI",
            "benchmark": "adversarial_nli",
            "score": 0.581,
            "normalized_score": 0.581,
            "date": "2023-11-06"
          }
        ]
      }
    },
    "agent_reasoning": {
      "name": "Agent Reasoning",
      "category": "agents",
      "x": 0.5,
      "y": 0.8,
      "description": "Plan and execute multi-step tasks autonomously",
      "benchmarks": [
        "the_agent_company"
      ],
      "heights": {
        "2024": 0.167,
        "2019": 0.129,
        "2020": 0.136,
        "2021": 0.143,
        "2022": 0.151,
        "2023": 0.159,
        "2025": 0.172
      },
      "top_models": {
        "2024": [
          {
            "model": "gpt-4o-2024-11-20",
            "org": "OpenAI",
            "benchmark": "the_agent_company",
            "score": 0.167,
            "normalized_score": 0.167,
            "date": "2024-11-20"
          }
        ]
      }
    },
    "boolean_reasoning": {
      "name": "Boolean Reasoning",
      "category": "reasoning",
      "x": 0.4,
      "y": 0.5,
      "description": "Answer yes/no questions requiring logical deduction",
      "benchmarks": [
        "bool_q"
      ],
      "heights": {
        "2019": 0.618,
        "2022": 0.881,
        "2023": 0.87,
        "2024": 0.887,
        "2020": 0.706,
        "2021": 0.793,
        "2025": 0.914
      },
      "top_models": {
        "2019": [
          {
            "model": "gpt2-xl",
            "org": "OpenAI",
            "benchmark": "bool_q",
            "score": 0.618,
            "normalized_score": 0.618,
            "date": "2019-11-05"
          }
        ],
        "2022": [
          {
            "model": "text-davinci-003",
            "org": "OpenAI",
            "benchmark": "bool_q",
            "score": 0.881,
            "normalized_score": 0.881,
            "date": "2022-11-28"
          }
        ],
        "2023": [
          {
            "model": "gpt-3.5-turbo-0613",
            "org": "OpenAI",
            "benchmark": "bool_q",
            "score": 0.87,
            "normalized_score": 0.87,
            "date": "2023-06-13"
          }
        ],
        "2024": [
          {
            "model": "gpt-4o-mini-2024-07-18",
            "org": "OpenAI",
            "benchmark": "bool_q",
            "score": 0.887,
            "normalized_score": 0.887,
            "date": "2024-07-18"
          }
        ]
      }
    },
    "language_modeling": {
      "name": "Language Modeling",
      "category": "language",
      "x": 0.3,
      "y": 0.7,
      "description": "Predict and generate coherent natural language sequences",
      "benchmarks": [
        "lambada"
      ],
      "heights": {
        "2022": 0.864,
        "2019": 0.741,
        "2020": 0.78,
        "2021": 0.821,
        "2023": 0.89,
        "2024": 0.917,
        "2025": 0.944
      },
      "top_models": {
        "2022": [
          {
            "model": "text-davinci-001",
            "org": "OpenAI",
            "benchmark": "lambada",
            "score": 0.864,
            "normalized_score": 0.864,
            "date": "2022-01-27"
          }
        ]
      }
    },
    "terminal_usage": {
      "name": "Terminal Usage",
      "category": "agents",
      "x": 0.45,
      "y": 0.85,
      "description": "Execute commands and navigate command-line interfaces",
      "benchmarks": [
        "terminalbench"
      ],
      "heights": {
        "2025": 0.525,
        "2019": 0.386,
        "2020": 0.406,
        "2021": 0.428,
        "2022": 0.45,
        "2023": 0.474,
        "2024": 0.499
      },
      "top_models": {
        "2025": [
          {
            "model": "gpt-5-2025-08-07_medium",
            "org": "OpenAI",
            "benchmark": "terminalbench",
            "score": 0.525,
            "normalized_score": 0.525,
            "date": "2025-08-07"
          }
        ]
      }
    }
  },
  "anthropic": {
    "code_generation": {
      "name": "Code Generation",
      "category": "coding",
      "x": 0.65,
      "y": 0.5,
      "description": "Generate functional code from natural language descriptions",
      "benchmarks": [
        "aider_polyglot",
        "swe_bench_verified",
        "live_bench"
      ],
      "heights": {
        "2024": 0.376,
        "2025": 0.501,
        "2019": 0.291,
        "2020": 0.306,
        "2021": 0.322,
        "2022": 0.339,
        "2023": 0.357
      },
      "top_models": {
        "2024": [
          {
            "model": "claude-3-5-sonnet-20241022",
            "org": "Anthropic",
            "benchmark": "live_bench",
            "score": 59.03,
            "normalized_score": 0.5903,
            "date": "2024-10-22"
          },
          {
            "model": "claude-3-5-sonnet-20241022",
            "org": "Anthropic",
            "benchmark": "aider_polyglot",
            "score": 51.6,
            "normalized_score": 0.516,
            "date": "2024-10-22"
          },
          {
            "model": "claude-3-5-sonnet-20241022",
            "org": "Anthropic",
            "benchmark": "swe_bench_verified",
            "score": 0.0219839620900864,
            "normalized_score": 0.0219839620900864,
            "date": "2024-10-22"
          }
        ],
        "2025": [
          {
            "model": "claude-3-7-sonnet-20250219",
            "org": "Anthropic",
            "benchmark": "live_bench",
            "score": 76.1,
            "normalized_score": 0.7609999999999999,
            "date": "2025-02-24"
          },
          {
            "model": "claude-opus-4-20250514_32K",
            "org": "Anthropic",
            "benchmark": "aider_polyglot",
            "score": 72.0,
            "normalized_score": 0.72,
            "date": "2025-05-22"
          },
          {
            "model": "claude-3-7-sonnet-20250219",
            "org": "Anthropic",
            "benchmark": "swe_bench_verified",
            "score": 0.0223613967392078,
            "normalized_score": 0.0223613967392078,
            "date": "2025-02-24"
          }
        ]
      }
    },
    "physical_intuition": {
      "name": "Physical Intuition",
      "category": "reasoning",
      "x": 0.5,
      "y": 0.5,
      "description": "Apply understanding of physical laws and object behavior",
      "benchmarks": [
        "piqa"
      ],
      "heights": {},
      "top_models": {}
    },
    "scientific_reasoning": {
      "name": "Scientific Reasoning",
      "category": "knowledge",
      "x": 0.3,
      "y": 0.55,
      "description": "Apply scientific methods and domain knowledge to problems",
      "benchmarks": [
        "science_qa"
      ],
      "heights": {
        "2024": 0.72,
        "2019": 0.557,
        "2020": 0.586,
        "2021": 0.617,
        "2022": 0.65,
        "2023": 0.684,
        "2025": 0.742
      },
      "top_models": {
        "2024": [
          {
            "model": "claude-3-haiku-20240307",
            "org": "Anthropic",
            "benchmark": "science_qa",
            "score": 0.72,
            "normalized_score": 0.72,
            "date": "2024-03-07"
          }
        ]
      }
    },
    "game_strategy": {
      "name": "Game Strategy",
      "category": "games",
      "x": 0.6,
      "y": 0.2,
      "description": "Develop winning approaches in strategic games",
      "benchmarks": [
        "factorio_learning_environment"
      ],
      "heights": {
        "2024": 2932.06,
        "2019": 2268.772,
        "2020": 2388.181,
        "2021": 2513.875,
        "2022": 2646.184,
        "2023": 2785.457,
        "2025": 1.0
      },
      "top_models": {
        "2024": [
          {
            "model": "claude-3-5-sonnet-20240620",
            "org": "Anthropic",
            "benchmark": "factorio_learning_environment",
            "score": 293206.0,
            "normalized_score": 2932.06,
            "date": "2024-06-20"
          }
        ]
      }
    },
    "commonsense_reasoning": {
      "name": "Commonsense Reasoning",
      "category": "reasoning",
      "x": 0.45,
      "y": 0.55,
      "description": "Apply everyday knowledge and intuitive logic",
      "benchmarks": [
        "common_sense_qa_2",
        "wino_grande",
        "arc_ai2",
        "hella_swag"
      ],
      "heights": {
        "2023": 0.863,
        "2024": 0.885,
        "2019": 0.703,
        "2020": 0.74,
        "2021": 0.779,
        "2022": 0.82,
        "2025": 0.912
      },
      "top_models": {
        "2023": [
          {
            "model": "claude-instant-1.2",
            "org": "Anthropic",
            "benchmark": "arc_ai2",
            "score": 0.863,
            "normalized_score": 0.863,
            "date": "2023-08-09"
          }
        ],
        "2024": [
          {
            "model": "claude-3-opus-20240229",
            "org": "Anthropic",
            "benchmark": "wino_grande",
            "score": 0.885,
            "normalized_score": 0.885,
            "date": "2024-02-29"
          }
        ]
      }
    },
    "reading_comprehension": {
      "name": "Reading Comprehension",
      "category": "language",
      "x": 0.35,
      "y": 0.65,
      "description": "Extract meaning and answer questions from written passages",
      "benchmarks": [
        "open_book_qa"
      ],
      "heights": {},
      "top_models": {}
    },
    "game_playing": {
      "name": "Game Playing",
      "category": "games",
      "x": 0.65,
      "y": 0.25,
      "description": "Learn and execute strategies in game environments",
      "benchmarks": [
        "balrog"
      ],
      "heights": {
        "2024": 0.326,
        "2019": 0.252,
        "2020": 0.266,
        "2021": 0.28,
        "2022": 0.294,
        "2023": 0.31,
        "2025": 0.336
      },
      "top_models": {
        "2024": [
          {
            "model": "claude-3-5-sonnet-20241022",
            "org": "Anthropic",
            "benchmark": "balrog",
            "score": 0.326,
            "normalized_score": 0.326,
            "date": "2024-10-22"
          }
        ]
      }
    },
    "creative_writing": {
      "name": "Creative Writing",
      "category": "language",
      "x": 0.2,
      "y": 0.3,
      "description": "Generate original, engaging narrative and expressive text",
      "benchmarks": [
        "fictionlivebench"
      ],
      "heights": {
        "2025": 0.531,
        "2019": 0.39,
        "2020": 0.411,
        "2021": 0.433,
        "2022": 0.455,
        "2023": 0.479,
        "2024": 0.504
      },
      "top_models": {
        "2025": [
          {
            "model": "claude-3-7-sonnet-20250219_8K",
            "org": "Anthropic",
            "benchmark": "fictionlivebench",
            "score": 0.531,
            "normalized_score": 0.531,
            "date": "2025-02-24"
          }
        ]
      }
    },
    "competition_math": {
      "name": "Competition Math",
      "category": "mathematics",
      "x": 0.85,
      "y": 0.45,
      "description": "Solve competition-level mathematics problems (AMC, AIME, IMO)",
      "benchmarks": [
        "otis_mock_aime_2024_2025"
      ],
      "heights": {
        "2023": 0.015,
        "2024": 0.026,
        "2025": 0.075,
        "2019": 0.012,
        "2020": 0.013,
        "2021": 0.014,
        "2022": 0.014
      },
      "top_models": {
        "2023": [
          {
            "model": "claude-2.0",
            "org": "Anthropic",
            "benchmark": "otis_mock_aime_2024_2025",
            "score": 0.0151798976587226,
            "normalized_score": 0.0151798976587226,
            "date": "2023-07-11"
          }
        ],
        "2024": [
          {
            "model": "claude-3-5-sonnet-20241022",
            "org": "Anthropic",
            "benchmark": "otis_mock_aime_2024_2025",
            "score": 0.0263639568559024,
            "normalized_score": 0.0263639568559024,
            "date": "2024-10-22"
          }
        ],
        "2025": [
          {
            "model": "claude-sonnet-4-20250514_16K",
            "org": "Anthropic",
            "benchmark": "otis_mock_aime_2024_2025",
            "score": 0.0752101433090354,
            "normalized_score": 0.0752101433090354,
            "date": "2025-05-22"
          },
          {
            "model": "claude-3-7-sonnet-20250219_32K",
            "org": "Anthropic",
            "benchmark": "otis_mock_aime_2024_2025",
            "score": 0.0752101433090354,
            "normalized_score": 0.0752101433090354,
            "date": "2025-02-24"
          },
          {
            "model": "claude-3-7-sonnet-20250219_16K",
            "org": "Anthropic",
            "benchmark": "otis_mock_aime_2024_2025",
            "score": 0.0752101433090354,
            "normalized_score": 0.0752101433090354,
            "date": "2025-02-24"
          }
        ]
      }
    },
    "advanced_reasoning": {
      "name": "Advanced Reasoning",
      "category": "reasoning",
      "x": 0.7,
      "y": 0.4,
      "description": "Handle complex multi-step reasoning across diverse domains",
      "benchmarks": [
        "gpqa_diamond"
      ],
      "heights": {
        "2023": 0.025,
        "2024": 0.028,
        "2025": 0.034,
        "2019": 0.02,
        "2020": 0.021,
        "2021": 0.023,
        "2022": 0.024
      },
      "top_models": {
        "2023": [
          {
            "model": "claude-2.0",
            "org": "Anthropic",
            "benchmark": "gpqa_diamond",
            "score": 0.0250762559835514,
            "normalized_score": 0.0250762559835514,
            "date": "2023-07-11"
          }
        ],
        "2024": [
          {
            "model": "claude-3-5-sonnet-20241022",
            "org": "Anthropic",
            "benchmark": "gpqa_diamond",
            "score": 0.0282080901470788,
            "normalized_score": 0.0282080901470788,
            "date": "2024-10-22"
          }
        ],
        "2025": [
          {
            "model": "claude-sonnet-4-20250514",
            "org": "Anthropic",
            "benchmark": "gpqa_diamond",
            "score": 0.0335861814573252,
            "normalized_score": 0.0335861814573252,
            "date": "2025-05-22"
          }
        ]
      }
    },
    "mathematical_reasoning": {
      "name": "Mathematical Reasoning",
      "category": "mathematics",
      "x": 0.75,
      "y": 0.45,
      "description": "Solve math problems with step-by-step logical reasoning",
      "benchmarks": [
        "math_level_5",
        "gsm8k"
      ],
      "heights": {
        "2023": 0.437,
        "2024": 0.012,
        "2025": 0.011,
        "2019": 0.356,
        "2020": 0.375,
        "2021": 0.394,
        "2022": 0.415
      },
      "top_models": {
        "2023": [
          {
            "model": "claude-instant-1.2",
            "org": "Anthropic",
            "benchmark": "gsm8k",
            "score": 0.867,
            "normalized_score": 0.867,
            "date": "2023-08-09"
          },
          {
            "model": "claude-2.0",
            "org": "Anthropic",
            "benchmark": "math_level_5",
            "score": 0.0065956709139699,
            "normalized_score": 0.0065956709139699,
            "date": "2023-07-11"
          }
        ],
        "2024": [
          {
            "model": "claude-3-5-sonnet-20240620",
            "org": "Anthropic",
            "benchmark": "math_level_5",
            "score": 0.0116250120233614,
            "normalized_score": 0.0116250120233614,
            "date": "2024-06-20"
          }
        ],
        "2025": [
          {
            "model": "claude-3-7-sonnet-20250219",
            "org": "Anthropic",
            "benchmark": "math_level_5",
            "score": 0.0106696518619303,
            "normalized_score": 0.0106696518619303,
            "date": "2025-02-24"
          }
        ]
      }
    },
    "long_horizon_planning": {
      "name": "Long Horizon Planning",
      "category": "reasoning",
      "x": 0.55,
      "y": 0.75,
      "description": "Plan and reason about extended sequences of actions",
      "benchmarks": [
        "metr_time_horizons"
      ],
      "heights": {
        "2024": 0.527,
        "2025": 0.674,
        "2019": 0.408,
        "2020": 0.429,
        "2021": 0.452,
        "2022": 0.476,
        "2023": 0.501
      },
      "top_models": {
        "2024": [
          {
            "model": "claude-3-5-sonnet-20241022",
            "org": "Anthropic",
            "benchmark": "metr_time_horizons",
            "score": 0.52701,
            "normalized_score": 0.52701,
            "date": "2024-10-22"
          }
        ],
        "2025": [
          {
            "model": "claude-sonnet-4-5-20250929",
            "org": "Anthropic",
            "benchmark": "metr_time_horizons",
            "score": 0.673842,
            "normalized_score": 0.673842,
            "date": "2025-09-29"
          }
        ]
      }
    },
    "writing_quality": {
      "name": "Writing Quality",
      "category": "language",
      "x": 0.25,
      "y": 0.35,
      "description": "Produce well-structured, grammatically correct, compelling text",
      "benchmarks": [
        "lech_mazur_writing"
      ],
      "heights": {
        "2024": 0.08,
        "2025": 0.081,
        "2019": 0.062,
        "2020": 0.065,
        "2021": 0.069,
        "2022": 0.072,
        "2023": 0.076
      },
      "top_models": {
        "2024": [
          {
            "model": "claude-3-5-sonnet-20241022",
            "org": "Anthropic",
            "benchmark": "lech_mazur_writing",
            "score": 8.03,
            "normalized_score": 0.0803,
            "date": "2024-10-22"
          }
        ],
        "2025": [
          {
            "model": "claude-3-7-sonnet-20250219_16K",
            "org": "Anthropic",
            "benchmark": "lech_mazur_writing",
            "score": 8.11,
            "normalized_score": 0.08109999999999999,
            "date": "2025-02-24"
          }
        ]
      }
    },
    "cad_design": {
      "name": "Cad Design",
      "category": "reasoning",
      "x": 0.75,
      "y": 0.25,
      "description": "Create and manipulate computer-aided design models",
      "benchmarks": [
        "cad_eval"
      ],
      "heights": {
        "2024": 0.48,
        "2025": 0.54,
        "2019": 0.371,
        "2020": 0.391,
        "2021": 0.412,
        "2022": 0.433,
        "2023": 0.456
      },
      "top_models": {
        "2024": [
          {
            "model": "claude-3-5-sonnet-20241022",
            "org": "Anthropic",
            "benchmark": "cad_eval",
            "score": 0.48,
            "normalized_score": 0.48,
            "date": "2024-10-22"
          }
        ],
        "2025": [
          {
            "model": "claude-3-7-sonnet-20250219",
            "org": "Anthropic",
            "benchmark": "cad_eval",
            "score": 0.54,
            "normalized_score": 0.54,
            "date": "2025-02-24"
          }
        ]
      }
    },
    "advanced_mathematics": {
      "name": "Advanced Mathematics",
      "category": "mathematics",
      "x": 0.8,
      "y": 0.4,
      "description": "Solve graduate-level and research mathematics problems",
      "benchmarks": [
        "frontiermath",
        "frontiermath_tier_4"
      ],
      "heights": {
        "2024": 0.004,
        "2025": 0.024,
        "2019": 0.003,
        "2020": 0.003,
        "2021": 0.003,
        "2022": 0.004,
        "2023": 0.004
      },
      "top_models": {
        "2024": [
          {
            "model": "claude-3-5-sonnet-20241022",
            "org": "Anthropic",
            "benchmark": "frontiermath",
            "score": 0.0083731308075254,
            "normalized_score": 0.0083731308075254,
            "date": "2024-10-22"
          },
          {
            "model": "claude-3-5-sonnet-20240620",
            "org": "Anthropic",
            "benchmark": "frontiermath_tier_4",
            "score": 0.0,
            "normalized_score": 0.0,
            "date": "2024-06-20"
          },
          {
            "model": "claude-3-5-sonnet-20241022",
            "org": "Anthropic",
            "benchmark": "frontiermath_tier_4",
            "score": 0.0,
            "normalized_score": 0.0,
            "date": "2024-10-22"
          }
        ],
        "2025": [
          {
            "model": "claude-sonnet-4-5-20250929_32K",
            "org": "Anthropic",
            "benchmark": "frontiermath_tier_4",
            "score": 0.029147663515556,
            "normalized_score": 0.029147663515556,
            "date": "2025-09-29"
          },
          {
            "model": "claude-opus-4-1-20250805_27K",
            "org": "Anthropic",
            "benchmark": "frontiermath_tier_4",
            "score": 0.029147663515556,
            "normalized_score": 0.029147663515556,
            "date": "2025-08-05"
          },
          {
            "model": "claude-opus-4-20250514_27K",
            "org": "Anthropic",
            "benchmark": "frontiermath_tier_4",
            "score": 0.029147663515556,
            "normalized_score": 0.029147663515556,
            "date": "2025-05-22"
          },
          {
            "model": "claude-sonnet-4-5-20250929_32K",
            "org": "Anthropic",
            "benchmark": "frontiermath",
            "score": 0.0179143222440727,
            "normalized_score": 0.0179143222440727,
            "date": "2025-09-29"
          }
        ]
      }
    },
    "abstract_reasoning": {
      "name": "Abstract Reasoning",
      "category": "reasoning",
      "x": 0.75,
      "y": 0.35,
      "description": "Recognize patterns and solve problems requiring high-level conceptual thinking",
      "benchmarks": [
        "arc_agi"
      ],
      "heights": {
        "2025": 0.4,
        "2019": 0.294,
        "2020": 0.31,
        "2021": 0.326,
        "2022": 0.343,
        "2023": 0.361,
        "2024": 0.38
      },
      "top_models": {
        "2025": [
          {
            "model": "claude-sonnet-4-20250514_16K",
            "org": "Anthropic",
            "benchmark": "arc_agi",
            "score": 0.4,
            "normalized_score": 0.4,
            "date": "2025-05-22"
          }
        ]
      }
    },
    "basic_tasks": {
      "name": "Basic Tasks",
      "category": "reasoning",
      "x": 0.4,
      "y": 0.4,
      "description": "Perform fundamental operations and simple problem-solving",
      "benchmarks": [
        "simplebench"
      ],
      "heights": {
        "2024": 0.414,
        "2025": 0.6,
        "2019": 0.32,
        "2020": 0.337,
        "2021": 0.355,
        "2022": 0.374,
        "2023": 0.393
      },
      "top_models": {
        "2024": [
          {
            "model": "claude-3-5-sonnet-20241022",
            "org": "Anthropic",
            "benchmark": "simplebench",
            "score": 0.414,
            "normalized_score": 0.414,
            "date": "2024-10-22"
          }
        ],
        "2025": [
          {
            "model": "claude-opus-4-1-20250805",
            "org": "Anthropic",
            "benchmark": "simplebench",
            "score": 0.6,
            "normalized_score": 0.6,
            "date": "2025-08-05"
          }
        ]
      }
    },
    "general_knowledge": {
      "name": "General Knowledge",
      "category": "knowledge",
      "x": 0.25,
      "y": 0.6,
      "description": "Answer questions across diverse academic and cultural domains",
      "benchmarks": [
        "mmlu"
      ],
      "heights": {
        "2023": 0.785,
        "2024": 0.873,
        "2019": 0.639,
        "2020": 0.673,
        "2021": 0.708,
        "2022": 0.746,
        "2025": 0.899
      },
      "top_models": {
        "2023": [
          {
            "model": "claude-2.0",
            "org": "Anthropic",
            "benchmark": "mmlu",
            "score": 0.785,
            "normalized_score": 0.785,
            "date": "2023-07-11"
          }
        ],
        "2024": [
          {
            "model": "claude-3-5-sonnet-20241022",
            "org": "Anthropic",
            "benchmark": "mmlu",
            "score": 0.873,
            "normalized_score": 0.873,
            "date": "2024-10-22"
          }
        ]
      }
    },
    "os_interaction": {
      "name": "Os Interaction",
      "category": "agents",
      "x": 0.6,
      "y": 0.8,
      "description": "Navigate and manipulate operating system interfaces",
      "benchmarks": [
        "os_universe"
      ],
      "heights": {
        "2024": 0.284,
        "2019": 0.22,
        "2020": 0.231,
        "2021": 0.243,
        "2022": 0.256,
        "2023": 0.27,
        "2025": 0.293
      },
      "top_models": {
        "2024": [
          {
            "model": "claude-3-5-sonnet-20241022",
            "org": "Anthropic",
            "benchmark": "os_universe",
            "score": 0.2836,
            "normalized_score": 0.2836,
            "date": "2024-10-22"
          }
        ]
      }
    },
    "factual_knowledge": {
      "name": "Factual Knowledge",
      "category": "knowledge",
      "x": 0.2,
      "y": 0.55,
      "description": "Retrieve and apply specific facts across domains",
      "benchmarks": [
        "trivia_qa"
      ],
      "heights": {
        "2023": 0.875,
        "2019": 0.713,
        "2020": 0.75,
        "2021": 0.79,
        "2022": 0.831,
        "2024": 0.901,
        "2025": 0.928
      },
      "top_models": {
        "2023": [
          {
            "model": "claude-2.0",
            "org": "Anthropic",
            "benchmark": "trivia_qa",
            "score": 0.875,
            "normalized_score": 0.875,
            "date": "2023-07-11"
          }
        ]
      }
    },
    "unusual_tasks": {
      "name": "Unusual Tasks",
      "category": "reasoning",
      "x": 0.5,
      "y": 0.3,
      "description": "Handle novel or atypical challenges outside standard benchmarks",
      "benchmarks": [
        "weirdml"
      ],
      "heights": {
        "2024": 0.509,
        "2025": 0.557,
        "2019": 0.394,
        "2020": 0.415,
        "2021": 0.436,
        "2022": 0.459,
        "2023": 0.484
      },
      "top_models": {
        "2024": [
          {
            "model": "claude-3-5-sonnet-20241022",
            "org": "Anthropic",
            "benchmark": "weirdml",
            "score": 0.5094,
            "normalized_score": 0.5094,
            "date": "2024-10-22"
          }
        ],
        "2025": [
          {
            "model": "claude-3-7-sonnet-20250219_8K",
            "org": "Anthropic",
            "benchmark": "weirdml",
            "score": 0.5569,
            "normalized_score": 0.5569,
            "date": "2025-02-24"
          }
        ]
      }
    },
    "geographic_knowledge": {
      "name": "Geographic Knowledge",
      "category": "knowledge",
      "x": 0.25,
      "y": 0.5,
      "description": "Understand spatial relationships, locations, and geographic data",
      "benchmarks": [
        "geobench"
      ],
      "heights": {
        "2024": 33.27,
        "2025": 38.44,
        "2019": 25.744,
        "2020": 27.099,
        "2021": 28.525,
        "2022": 30.026,
        "2023": 31.607
      },
      "top_models": {
        "2024": [
          {
            "model": "claude-3-5-sonnet-20241022",
            "org": "Anthropic",
            "benchmark": "geobench",
            "score": 3327.0,
            "normalized_score": 33.27,
            "date": "2024-10-22"
          }
        ],
        "2025": [
          {
            "model": "claude-3-7-sonnet-20250219_15K",
            "org": "Anthropic",
            "benchmark": "geobench",
            "score": 3844.0,
            "normalized_score": 38.44,
            "date": "2025-02-24"
          }
        ]
      }
    },
    "complex_reasoning": {
      "name": "Complex Reasoning",
      "category": "reasoning",
      "x": 0.65,
      "y": 0.45,
      "description": "Navigate multi-layered logical problems requiring synthesis",
      "benchmarks": [
        "bbh"
      ],
      "heights": {},
      "top_models": {}
    },
    "spatial_reasoning": {
      "name": "Spatial Reasoning",
      "category": "games",
      "x": 0.55,
      "y": 0.25,
      "description": "Understand and manipulate objects in 2D and 3D space",
      "benchmarks": [
        "gso"
      ],
      "heights": {
        "2024": 0.046,
        "2025": 0.069,
        "2019": 0.036,
        "2020": 0.037,
        "2021": 0.039,
        "2022": 0.042,
        "2023": 0.044
      },
      "top_models": {
        "2024": [
          {
            "model": "claude-3-5-sonnet-20241022",
            "org": "Anthropic",
            "benchmark": "gso",
            "score": 0.046,
            "normalized_score": 0.046,
            "date": "2024-10-22"
          }
        ],
        "2025": [
          {
            "model": "claude-opus-4-20250514",
            "org": "Anthropic",
            "benchmark": "gso",
            "score": 0.069,
            "normalized_score": 0.069,
            "date": "2025-05-22"
          }
        ]
      }
    },
    "cybersecurity": {
      "name": "Cybersecurity",
      "category": "reasoning",
      "x": 0.7,
      "y": 0.2,
      "description": "Identify vulnerabilities and solve security-related challenges",
      "benchmarks": [
        "cybench"
      ],
      "heights": {
        "2024": 0.175,
        "2025": 0.2,
        "2019": 0.135,
        "2020": 0.143,
        "2021": 0.15,
        "2022": 0.158,
        "2023": 0.166
      },
      "top_models": {
        "2024": [
          {
            "model": "claude-3-5-sonnet-20240620",
            "org": "Anthropic",
            "benchmark": "cybench",
            "score": 0.175,
            "normalized_score": 0.175,
            "date": "2024-06-20"
          }
        ],
        "2025": [
          {
            "model": "claude-3-7-sonnet-20250219",
            "org": "Anthropic",
            "benchmark": "cybench",
            "score": 0.2,
            "normalized_score": 0.2,
            "date": "2025-02-24"
          }
        ]
      }
    },
    "language_understanding": {
      "name": "Language Understanding",
      "category": "language",
      "x": 0.4,
      "y": 0.65,
      "description": "Comprehend meaning, context, and nuance in text",
      "benchmarks": [
        "superglue"
      ],
      "heights": {},
      "top_models": {}
    },
    "os_navigation": {
      "name": "Os Navigation",
      "category": "agents",
      "x": 0.55,
      "y": 0.85,
      "description": "Find and access files and programs within operating systems",
      "benchmarks": [
        "os_world"
      ],
      "heights": {
        "2024": 0.22,
        "2025": 0.28,
        "2019": 0.17,
        "2020": 0.179,
        "2021": 0.189,
        "2022": 0.199,
        "2023": 0.209
      },
      "top_models": {
        "2024": [
          {
            "model": "claude-3-5-sonnet-20240620",
            "org": "Anthropic",
            "benchmark": "os_world",
            "score": 22.0,
            "normalized_score": 0.22,
            "date": "2024-06-20"
          }
        ],
        "2025": [
          {
            "model": "claude-3-7-sonnet-20250219",
            "org": "Anthropic",
            "benchmark": "os_world",
            "score": 28.0,
            "normalized_score": 0.28,
            "date": "2025-02-24"
          }
        ]
      }
    },
    "natural_language_inference": {
      "name": "Natural Language Inference",
      "category": "language",
      "x": 0.35,
      "y": 0.6,
      "description": "Determine logical relationships between text passages",
      "benchmarks": [
        "adversarial_nli"
      ],
      "heights": {},
      "top_models": {}
    },
    "agent_reasoning": {
      "name": "Agent Reasoning",
      "category": "agents",
      "x": 0.5,
      "y": 0.8,
      "description": "Plan and execute multi-step tasks autonomously",
      "benchmarks": [
        "the_agent_company"
      ],
      "heights": {
        "2024": 0.344,
        "2019": 0.266,
        "2020": 0.28,
        "2021": 0.295,
        "2022": 0.31,
        "2023": 0.327,
        "2025": 0.354
      },
      "top_models": {
        "2024": [
          {
            "model": "claude-3-5-sonnet-20241022",
            "org": "Anthropic",
            "benchmark": "the_agent_company",
            "score": 0.344,
            "normalized_score": 0.344,
            "date": "2024-10-22"
          }
        ]
      }
    },
    "boolean_reasoning": {
      "name": "Boolean Reasoning",
      "category": "reasoning",
      "x": 0.4,
      "y": 0.5,
      "description": "Answer yes/no questions requiring logical deduction",
      "benchmarks": [
        "bool_q"
      ],
      "heights": {},
      "top_models": {}
    },
    "language_modeling": {
      "name": "Language Modeling",
      "category": "language",
      "x": 0.3,
      "y": 0.7,
      "description": "Predict and generate coherent natural language sequences",
      "benchmarks": [
        "lambada"
      ],
      "heights": {},
      "top_models": {}
    },
    "terminal_usage": {
      "name": "Terminal Usage",
      "category": "agents",
      "x": 0.45,
      "y": 0.85,
      "description": "Execute commands and navigate command-line interfaces",
      "benchmarks": [
        "terminalbench"
      ],
      "heights": {
        "2025": 0.603,
        "2019": 0.443,
        "2020": 0.467,
        "2021": 0.491,
        "2022": 0.517,
        "2023": 0.544,
        "2024": 0.573
      },
      "top_models": {
        "2025": [
          {
            "model": "claude-sonnet-4-5-20250929",
            "org": "Anthropic",
            "benchmark": "terminalbench",
            "score": 0.603,
            "normalized_score": 0.603,
            "date": "2025-09-29"
          }
        ]
      }
    }
  },
  "google": {
    "code_generation": {
      "name": "Code Generation",
      "category": "coding",
      "x": 0.65,
      "y": 0.5,
      "description": "Generate functional code from natural language descriptions",
      "benchmarks": [
        "aider_polyglot",
        "swe_bench_verified",
        "live_bench"
      ],
      "heights": {
        "2024": 0.511,
        "2025": 0.544,
        "2019": 0.395,
        "2020": 0.416,
        "2021": 0.438,
        "2022": 0.461,
        "2023": 0.485
      },
      "top_models": {
        "2024": [
          {
            "model": "gemini-exp-1206",
            "org": "Google DeepMind,Google",
            "benchmark": "live_bench",
            "score": 64.09,
            "normalized_score": 0.6409,
            "date": "2024-12-06"
          },
          {
            "model": "gemini-exp-1206",
            "org": "Google DeepMind,Google",
            "benchmark": "aider_polyglot",
            "score": 38.2,
            "normalized_score": 0.382,
            "date": "2024-12-06"
          }
        ],
        "2025": [
          {
            "model": "gemini-2.5-pro-exp-03-25",
            "org": "Google DeepMind",
            "benchmark": "live_bench",
            "score": 82.35,
            "normalized_score": 0.8234999999999999,
            "date": "2025-03-25"
          },
          {
            "model": "gemini-2.5-pro-preview-06-05",
            "org": "Google DeepMind",
            "benchmark": "aider_polyglot",
            "score": 79.1,
            "normalized_score": 0.7909999999999999,
            "date": "2025-06-05"
          },
          {
            "model": "gemini-2.0-flash-001",
            "org": "Google DeepMind,Google",
            "benchmark": "swe_bench_verified",
            "score": 0.0185442113758202,
            "normalized_score": 0.0185442113758202,
            "date": "2025-02-05"
          }
        ]
      }
    },
    "physical_intuition": {
      "name": "Physical Intuition",
      "category": "reasoning",
      "x": 0.5,
      "y": 0.5,
      "description": "Apply understanding of physical laws and object behavior",
      "benchmarks": [
        "piqa"
      ],
      "heights": {
        "2021": 0.818,
        "2022": 0.823,
        "2024": 0.875,
        "2023": 0.849,
        "2019": 0.738,
        "2020": 0.777,
        "2025": 0.901
      },
      "top_models": {
        "2021": [
          {
            "model": "Gopher (280B)",
            "org": "DeepMind",
            "benchmark": "piqa",
            "score": 0.818,
            "normalized_score": 0.818,
            "date": "2021-12-08"
          }
        ],
        "2022": [
          {
            "model": "PaLM 540B",
            "org": "Google Research",
            "benchmark": "piqa",
            "score": 0.823,
            "normalized_score": 0.823,
            "date": "2022-04-04"
          }
        ],
        "2024": [
          {
            "model": "gemini-1.5-flash-002",
            "org": "Google DeepMind",
            "benchmark": "piqa",
            "score": 0.875,
            "normalized_score": 0.875,
            "date": "2024-09-24"
          }
        ]
      }
    },
    "scientific_reasoning": {
      "name": "Scientific Reasoning",
      "category": "knowledge",
      "x": 0.3,
      "y": 0.55,
      "description": "Apply scientific methods and domain knowledge to problems",
      "benchmarks": [
        "science_qa"
      ],
      "heights": {
        "2024": 0.797,
        "2019": 0.617,
        "2020": 0.649,
        "2021": 0.683,
        "2022": 0.719,
        "2023": 0.757,
        "2025": 0.821
      },
      "top_models": {
        "2024": [
          {
            "model": "gemini-1.0-pro-vision",
            "org": "Google DeepMind",
            "benchmark": "science_qa",
            "score": 0.797,
            "normalized_score": 0.797,
            "date": "2024-01-04"
          }
        ]
      }
    },
    "game_strategy": {
      "name": "Game Strategy",
      "category": "games",
      "x": 0.6,
      "y": 0.2,
      "description": "Develop winning approaches in strategic games",
      "benchmarks": [
        "factorio_learning_environment"
      ],
      "heights": {
        "2025": 1157.82,
        "2019": 851.104,
        "2020": 895.899,
        "2021": 943.052,
        "2022": 992.686,
        "2023": 1044.933,
        "2024": 1099.929
      },
      "top_models": {
        "2025": [
          {
            "model": "gemini-2.0-flash-02-05",
            "org": "Google DeepMind,Google",
            "benchmark": "factorio_learning_environment",
            "score": 115782.0,
            "normalized_score": 1157.82,
            "date": "2025-02-05"
          }
        ]
      }
    },
    "commonsense_reasoning": {
      "name": "Commonsense Reasoning",
      "category": "reasoning",
      "x": 0.45,
      "y": 0.55,
      "description": "Apply everyday knowledge and intuitive logic",
      "benchmarks": [
        "common_sense_qa_2",
        "wino_grande",
        "arc_ai2",
        "hella_swag"
      ],
      "heights": {
        "2021": 0.792,
        "2022": 0.847,
        "2024": 0.798,
        "2023": 0.823,
        "2019": 0.715,
        "2020": 0.752,
        "2025": 0.822
      },
      "top_models": {
        "2021": [
          {
            "model": "GLaM (MoE)",
            "org": "Google",
            "benchmark": "wino_grande",
            "score": 0.792,
            "normalized_score": 0.792,
            "date": "2021-12-13"
          },
          {
            "model": "Gopher (280B)",
            "org": "DeepMind",
            "benchmark": "hella_swag",
            "score": 0.792,
            "normalized_score": 0.792,
            "date": "2021-12-08"
          }
        ],
        "2022": [
          {
            "model": "PaLM 540B",
            "org": "Google Research",
            "benchmark": "arc_ai2",
            "score": 0.852,
            "normalized_score": 0.852,
            "date": "2022-04-04"
          },
          {
            "model": "PaLM 540B",
            "org": "Google Research",
            "benchmark": "wino_grande",
            "score": 0.851,
            "normalized_score": 0.851,
            "date": "2022-04-04"
          },
          {
            "model": "PaLM 540B",
            "org": "Google Research",
            "benchmark": "hella_swag",
            "score": 0.838,
            "normalized_score": 0.838,
            "date": "2022-04-04"
          }
        ],
        "2024": [
          {
            "model": "gemma-7b",
            "org": "Google DeepMind",
            "benchmark": "hella_swag",
            "score": 0.822,
            "normalized_score": 0.822,
            "date": "2024-02-21"
          },
          {
            "model": "gemma-7b",
            "org": "Google DeepMind",
            "benchmark": "wino_grande",
            "score": 0.79,
            "normalized_score": 0.79,
            "date": "2024-02-21"
          },
          {
            "model": "gemma-7b",
            "org": "Google DeepMind",
            "benchmark": "arc_ai2",
            "score": 0.783,
            "normalized_score": 0.783,
            "date": "2024-02-21"
          }
        ]
      }
    },
    "reading_comprehension": {
      "name": "Reading Comprehension",
      "category": "language",
      "x": 0.35,
      "y": 0.65,
      "description": "Extract meaning and answer questions from written passages",
      "benchmarks": [
        "open_book_qa"
      ],
      "heights": {
        "2021": 0.63,
        "2022": 0.68,
        "2024": 0.786,
        "2023": 0.733,
        "2019": 0.569,
        "2020": 0.598,
        "2025": 0.81
      },
      "top_models": {
        "2021": [
          {
            "model": "GLaM (MoE)",
            "org": "Google",
            "benchmark": "open_book_qa",
            "score": 0.63,
            "normalized_score": 0.63,
            "date": "2021-12-13"
          }
        ],
        "2022": [
          {
            "model": "PaLM 540B",
            "org": "Google Research",
            "benchmark": "open_book_qa",
            "score": 0.68,
            "normalized_score": 0.68,
            "date": "2022-04-04"
          }
        ],
        "2024": [
          {
            "model": "gemma-7b",
            "org": "Google DeepMind",
            "benchmark": "open_book_qa",
            "score": 0.786,
            "normalized_score": 0.786,
            "date": "2024-02-21"
          }
        ]
      }
    },
    "game_playing": {
      "name": "Game Playing",
      "category": "games",
      "x": 0.65,
      "y": 0.25,
      "description": "Learn and execute strategies in game environments",
      "benchmarks": [
        "balrog"
      ],
      "heights": {
        "2024": 0.21,
        "2025": 0.404,
        "2019": 0.162,
        "2020": 0.171,
        "2021": 0.18,
        "2022": 0.19,
        "2023": 0.199
      },
      "top_models": {
        "2024": [
          {
            "model": "gemini-1.5-pro-002",
            "org": "Google DeepMind",
            "benchmark": "balrog",
            "score": 0.21,
            "normalized_score": 0.21,
            "date": "2024-09-24"
          }
        ],
        "2025": [
          {
            "model": "gemini-2.5-pro-exp-03-25",
            "org": "Google DeepMind",
            "benchmark": "balrog",
            "score": 0.404,
            "normalized_score": 0.404,
            "date": "2025-03-25"
          }
        ]
      }
    },
    "creative_writing": {
      "name": "Creative Writing",
      "category": "language",
      "x": 0.2,
      "y": 0.3,
      "description": "Generate original, engaging narrative and expressive text",
      "benchmarks": [
        "fictionlivebench"
      ],
      "heights": {
        "2025": 0.906,
        "2019": 0.666,
        "2020": 0.701,
        "2021": 0.738,
        "2022": 0.777,
        "2023": 0.818,
        "2024": 0.861
      },
      "top_models": {
        "2025": [
          {
            "model": "gemini-2.5-pro-exp-03-25",
            "org": "Google DeepMind",
            "benchmark": "fictionlivebench",
            "score": 0.906,
            "normalized_score": 0.906,
            "date": "2025-03-25"
          }
        ]
      }
    },
    "competition_math": {
      "name": "Competition Math",
      "category": "mathematics",
      "x": 0.85,
      "y": 0.45,
      "description": "Solve competition-level mathematics problems (AMC, AIME, IMO)",
      "benchmarks": [
        "otis_mock_aime_2024_2025"
      ],
      "heights": {
        "2024": 0.052,
        "2025": 0.074,
        "2019": 0.04,
        "2020": 0.042,
        "2021": 0.045,
        "2022": 0.047,
        "2023": 0.049
      },
      "top_models": {
        "2024": [
          {
            "model": "gemini-1.5-pro-002",
            "org": "Google DeepMind",
            "benchmark": "otis_mock_aime_2024_2025",
            "score": 0.0518678201121603,
            "normalized_score": 0.0518678201121603,
            "date": "2024-09-24"
          }
        ],
        "2025": [
          {
            "model": "gemini-2.0-flash-thinking-exp-01-21",
            "org": "Google DeepMind,Google",
            "benchmark": "otis_mock_aime_2024_2025",
            "score": 0.074460272702958,
            "normalized_score": 0.074460272702958,
            "date": "2025-01-21"
          }
        ]
      }
    },
    "advanced_reasoning": {
      "name": "Advanced Reasoning",
      "category": "reasoning",
      "x": 0.7,
      "y": 0.4,
      "description": "Handle complex multi-step reasoning across diverse domains",
      "benchmarks": [
        "gpqa_diamond"
      ],
      "heights": {
        "2024": 0.028,
        "2025": 0.035,
        "2019": 0.022,
        "2020": 0.023,
        "2021": 0.024,
        "2022": 0.025,
        "2023": 0.027
      },
      "top_models": {
        "2024": [
          {
            "model": "gemini-1.5-pro-002",
            "org": "Google DeepMind",
            "benchmark": "gpqa_diamond",
            "score": 0.0279597096365042,
            "normalized_score": 0.0279597096365042,
            "date": "2024-09-24"
          }
        ],
        "2025": [
          {
            "model": "gemini-2.0-flash-thinking-exp-01-21",
            "org": "Google DeepMind,Google",
            "benchmark": "gpqa_diamond",
            "score": 0.0352655272460119,
            "normalized_score": 0.0352655272460119,
            "date": "2025-01-21"
          }
        ]
      }
    },
    "mathematical_reasoning": {
      "name": "Mathematical Reasoning",
      "category": "mathematics",
      "x": 0.75,
      "y": 0.45,
      "description": "Solve math problems with step-by-step logical reasoning",
      "benchmarks": [
        "math_level_5",
        "gsm8k"
      ],
      "heights": {
        "2022": 0.565,
        "2024": 0.418,
        "2025": 0.011,
        "2023": 0.491,
        "2019": 0.484,
        "2020": 0.51,
        "2021": 0.537
      },
      "top_models": {
        "2022": [
          {
            "model": "PaLM 540B",
            "org": "Google Research",
            "benchmark": "gsm8k",
            "score": 0.565,
            "normalized_score": 0.565,
            "date": "2022-04-04"
          }
        ],
        "2024": [
          {
            "model": "gemini-1.5-flash-001",
            "org": "Google DeepMind",
            "benchmark": "gsm8k",
            "score": 0.824,
            "normalized_score": 0.824,
            "date": "2024-05-23"
          },
          {
            "model": "gemini-1.5-flash-002",
            "org": "Google DeepMind",
            "benchmark": "math_level_5",
            "score": 0.0112012212758022,
            "normalized_score": 0.0112012212758022,
            "date": "2024-09-24"
          }
        ],
        "2025": [
          {
            "model": "gemma-3-27b-it",
            "org": "Google DeepMind",
            "benchmark": "math_level_5",
            "score": 0.0111958575257272,
            "normalized_score": 0.0111958575257272,
            "date": "2025-03-12"
          }
        ]
      }
    },
    "long_horizon_planning": {
      "name": "Long Horizon Planning",
      "category": "reasoning",
      "x": 0.55,
      "y": 0.75,
      "description": "Plan and reason about extended sequences of actions",
      "benchmarks": [
        "metr_time_horizons"
      ],
      "heights": {
        "2025": 0.554,
        "2019": 0.407,
        "2020": 0.429,
        "2021": 0.451,
        "2022": 0.475,
        "2023": 0.5,
        "2024": 0.526
      },
      "top_models": {
        "2025": [
          {
            "model": "gemini-2.5-pro-preview-06-05",
            "org": "Google DeepMind",
            "benchmark": "metr_time_horizons",
            "score": 0.5544,
            "normalized_score": 0.5544,
            "date": "2025-06-05"
          }
        ]
      }
    },
    "writing_quality": {
      "name": "Writing Quality",
      "category": "language",
      "x": 0.25,
      "y": 0.35,
      "description": "Produce well-structured, grammatically correct, compelling text",
      "benchmarks": [
        "lech_mazur_writing"
      ],
      "heights": {
        "2024": 0.072,
        "2025": 0.081,
        "2019": 0.056,
        "2020": 0.059,
        "2021": 0.062,
        "2022": 0.065,
        "2023": 0.068
      },
      "top_models": {
        "2024": [
          {
            "model": "gemini-2.0-flash-exp",
            "org": "Google DeepMind,Google",
            "benchmark": "lech_mazur_writing",
            "score": 7.15,
            "normalized_score": 0.07150000000000001,
            "date": "2024-12-11"
          }
        ],
        "2025": [
          {
            "model": "gemini-2.5-pro-exp-03-25",
            "org": "Google DeepMind",
            "benchmark": "lech_mazur_writing",
            "score": 8.05,
            "normalized_score": 0.0805,
            "date": "2025-03-25"
          }
        ]
      }
    },
    "cad_design": {
      "name": "Cad Design",
      "category": "reasoning",
      "x": 0.75,
      "y": 0.25,
      "description": "Create and manipulate computer-aided design models",
      "benchmarks": [
        "cad_eval"
      ],
      "heights": {
        "2024": 0.34,
        "2025": 0.64,
        "2019": 0.263,
        "2020": 0.277,
        "2021": 0.292,
        "2022": 0.307,
        "2023": 0.323
      },
      "top_models": {
        "2024": [
          {
            "model": "gemini-1.5-pro-002",
            "org": "Google DeepMind",
            "benchmark": "cad_eval",
            "score": 0.34,
            "normalized_score": 0.34,
            "date": "2024-09-24"
          }
        ],
        "2025": [
          {
            "model": "gemini-2.5-pro-preview-03-25",
            "org": "Google DeepMind",
            "benchmark": "cad_eval",
            "score": 0.64,
            "normalized_score": 0.64,
            "date": "2025-04-09"
          }
        ]
      }
    },
    "advanced_mathematics": {
      "name": "Advanced Mathematics",
      "category": "mathematics",
      "x": 0.8,
      "y": 0.4,
      "description": "Solve graduate-level and research mathematics problems",
      "benchmarks": [
        "frontiermath",
        "frontiermath_tier_4"
      ],
      "heights": {
        "2024": 0.0,
        "2025": 0.035,
        "2019": 0.0,
        "2020": 0.0,
        "2021": 0.0,
        "2022": 0.0,
        "2023": 0.0
      },
      "top_models": {
        "2024": [
          {
            "model": "gemini-1.5-flash-002",
            "org": "Google DeepMind",
            "benchmark": "frontiermath",
            "score": 0.0,
            "normalized_score": 0.0,
            "date": "2024-09-24"
          }
        ],
        "2025": [
          {
            "model": "gemini-2.5-deep-think-2025-08-01-webapp",
            "org": "Google,Google DeepMind",
            "benchmark": "frontiermath_tier_4",
            "score": 0.044,
            "normalized_score": 0.044,
            "date": "2025-08-01"
          },
          {
            "model": "gemini-2.5-deep-think-2025-08-01-webapp",
            "org": "Google,Google DeepMind",
            "benchmark": "frontiermath",
            "score": 0.027,
            "normalized_score": 0.027,
            "date": "2025-08-01"
          }
        ]
      }
    },
    "abstract_reasoning": {
      "name": "Abstract Reasoning",
      "category": "reasoning",
      "x": 0.75,
      "y": 0.35,
      "description": "Recognize patterns and solve problems requiring high-level conceptual thinking",
      "benchmarks": [
        "arc_agi"
      ],
      "heights": {
        "2025": 0.333,
        "2019": 0.245,
        "2020": 0.258,
        "2021": 0.271,
        "2022": 0.286,
        "2023": 0.301,
        "2024": 0.316
      },
      "top_models": {
        "2025": [
          {
            "model": "gemini-2.5-flash-preview-05-20_16K",
            "org": "Google DeepMind",
            "benchmark": "arc_agi",
            "score": 0.333,
            "normalized_score": 0.333,
            "date": "2025-05-20"
          },
          {
            "model": "gemini-2.5-flash-preview-05-20",
            "org": "Google DeepMind",
            "benchmark": "arc_agi",
            "score": 0.333,
            "normalized_score": 0.333,
            "date": "2025-05-20"
          }
        ]
      }
    },
    "basic_tasks": {
      "name": "Basic Tasks",
      "category": "reasoning",
      "x": 0.4,
      "y": 0.4,
      "description": "Perform fundamental operations and simple problem-solving",
      "benchmarks": [
        "simplebench"
      ],
      "heights": {
        "2024": 0.311,
        "2025": 0.624,
        "2019": 0.241,
        "2020": 0.253,
        "2021": 0.267,
        "2022": 0.281,
        "2023": 0.295
      },
      "top_models": {
        "2024": [
          {
            "model": "gemini-exp-1206",
            "org": "Google DeepMind,Google",
            "benchmark": "simplebench",
            "score": 0.311,
            "normalized_score": 0.311,
            "date": "2024-12-06"
          }
        ],
        "2025": [
          {
            "model": "gemini-2.5-pro-preview-06-05",
            "org": "Google DeepMind",
            "benchmark": "simplebench",
            "score": 0.624,
            "normalized_score": 0.624,
            "date": "2025-06-05"
          }
        ]
      }
    },
    "general_knowledge": {
      "name": "General Knowledge",
      "category": "knowledge",
      "x": 0.25,
      "y": 0.6,
      "description": "Answer questions across diverse academic and cultural domains",
      "benchmarks": [
        "mmlu"
      ],
      "heights": {
        "2021": 0.6,
        "2022": 0.693,
        "2024": 0.869,
        "2023": 0.781,
        "2019": 0.541,
        "2020": 0.57,
        "2025": 0.895
      },
      "top_models": {
        "2021": [
          {
            "model": "Gopher (280B)",
            "org": "DeepMind",
            "benchmark": "mmlu",
            "score": 0.6,
            "normalized_score": 0.6,
            "date": "2021-12-08"
          }
        ],
        "2022": [
          {
            "model": "PaLM 540B",
            "org": "Google Research",
            "benchmark": "mmlu",
            "score": 0.693,
            "normalized_score": 0.693,
            "date": "2022-04-04"
          }
        ],
        "2024": [
          {
            "model": "gemini-1.5-pro-002",
            "org": "Google DeepMind",
            "benchmark": "mmlu",
            "score": 0.869,
            "normalized_score": 0.869,
            "date": "2024-09-24"
          }
        ]
      }
    },
    "os_interaction": {
      "name": "Os Interaction",
      "category": "agents",
      "x": 0.6,
      "y": 0.8,
      "description": "Navigate and manipulate operating system interfaces",
      "benchmarks": [
        "os_universe"
      ],
      "heights": {
        "2024": 0.061,
        "2025": 0.096,
        "2019": 0.047,
        "2020": 0.05,
        "2021": 0.052,
        "2022": 0.055,
        "2023": 0.058
      },
      "top_models": {
        "2024": [
          {
            "model": "gemini-1.5-pro-002",
            "org": "Google DeepMind",
            "benchmark": "os_universe",
            "score": 0.0612,
            "normalized_score": 0.0612,
            "date": "2024-09-24"
          }
        ],
        "2025": [
          {
            "model": "gemini-2.5-pro-exp-03-25",
            "org": "Google DeepMind",
            "benchmark": "os_universe",
            "score": 0.0959,
            "normalized_score": 0.0959,
            "date": "2025-03-25"
          }
        ]
      }
    },
    "factual_knowledge": {
      "name": "Factual Knowledge",
      "category": "knowledge",
      "x": 0.2,
      "y": 0.55,
      "description": "Retrieve and apply specific facts across domains",
      "benchmarks": [
        "trivia_qa"
      ],
      "heights": {
        "2021": 0.758,
        "2022": 0.814,
        "2024": 0.723,
        "2023": 0.768,
        "2019": 0.684,
        "2020": 0.72,
        "2025": 0.745
      },
      "top_models": {
        "2021": [
          {
            "model": "GLaM (MoE)",
            "org": "Google",
            "benchmark": "trivia_qa",
            "score": 0.758,
            "normalized_score": 0.758,
            "date": "2021-12-13"
          }
        ],
        "2022": [
          {
            "model": "PaLM 540B",
            "org": "Google Research",
            "benchmark": "trivia_qa",
            "score": 0.814,
            "normalized_score": 0.814,
            "date": "2022-04-04"
          }
        ],
        "2024": [
          {
            "model": "gemma-7b",
            "org": "Google DeepMind",
            "benchmark": "trivia_qa",
            "score": 0.723,
            "normalized_score": 0.723,
            "date": "2024-02-21"
          }
        ]
      }
    },
    "unusual_tasks": {
      "name": "Unusual Tasks",
      "category": "reasoning",
      "x": 0.5,
      "y": 0.3,
      "description": "Handle novel or atypical challenges outside standard benchmarks",
      "benchmarks": [
        "weirdml"
      ],
      "heights": {
        "2024": 0.391,
        "2025": 0.611,
        "2019": 0.303,
        "2020": 0.318,
        "2021": 0.335,
        "2022": 0.353,
        "2023": 0.371
      },
      "top_models": {
        "2024": [
          {
            "model": "gemini-2.0-flash-exp",
            "org": "Google DeepMind,Google",
            "benchmark": "weirdml",
            "score": 0.3905,
            "normalized_score": 0.3905,
            "date": "2024-12-11"
          }
        ],
        "2025": [
          {
            "model": "gemini-2.5-pro-exp-03-25",
            "org": "Google DeepMind",
            "benchmark": "weirdml",
            "score": 0.6105,
            "normalized_score": 0.6105,
            "date": "2025-03-25"
          }
        ]
      }
    },
    "geographic_knowledge": {
      "name": "Geographic Knowledge",
      "category": "knowledge",
      "x": 0.25,
      "y": 0.5,
      "description": "Understand spatial relationships, locations, and geographic data",
      "benchmarks": [
        "geobench"
      ],
      "heights": {
        "2024": 39.34,
        "2025": 40.93,
        "2019": 30.441,
        "2020": 32.043,
        "2021": 33.729,
        "2022": 35.504,
        "2023": 37.373
      },
      "top_models": {
        "2024": [
          {
            "model": "gemini-1.5-flash-002",
            "org": "Google DeepMind",
            "benchmark": "geobench",
            "score": 3934.0,
            "normalized_score": 39.34,
            "date": "2024-09-24"
          }
        ],
        "2025": [
          {
            "model": "gemini-2.5-pro-exp-03-25",
            "org": "Google DeepMind",
            "benchmark": "geobench",
            "score": 4093.0,
            "normalized_score": 40.93,
            "date": "2025-03-25"
          }
        ]
      }
    },
    "complex_reasoning": {
      "name": "Complex Reasoning",
      "category": "reasoning",
      "x": 0.65,
      "y": 0.45,
      "description": "Navigate multi-layered logical problems requiring synthesis",
      "benchmarks": [
        "bbh"
      ],
      "heights": {
        "2024": 0.551,
        "2019": 0.426,
        "2020": 0.449,
        "2021": 0.472,
        "2022": 0.497,
        "2023": 0.523,
        "2025": 0.568
      },
      "top_models": {
        "2024": [
          {
            "model": "gemma-7b",
            "org": "Google DeepMind",
            "benchmark": "bbh",
            "score": 0.551,
            "normalized_score": 0.551,
            "date": "2024-02-21"
          }
        ]
      }
    },
    "spatial_reasoning": {
      "name": "Spatial Reasoning",
      "category": "games",
      "x": 0.55,
      "y": 0.25,
      "description": "Understand and manipulate objects in 2D and 3D space",
      "benchmarks": [
        "gso"
      ],
      "heights": {},
      "top_models": {}
    },
    "cybersecurity": {
      "name": "Cybersecurity",
      "category": "reasoning",
      "x": 0.7,
      "y": 0.2,
      "description": "Identify vulnerabilities and solve security-related challenges",
      "benchmarks": [
        "cybench"
      ],
      "heights": {
        "2024": 0.075,
        "2019": 0.058,
        "2020": 0.061,
        "2021": 0.064,
        "2022": 0.068,
        "2023": 0.071,
        "2025": 0.077
      },
      "top_models": {
        "2024": [
          {
            "model": "gemini-1.5-pro-001",
            "org": "Google DeepMind",
            "benchmark": "cybench",
            "score": 0.075,
            "normalized_score": 0.075,
            "date": "2024-05-24"
          }
        ]
      }
    },
    "language_understanding": {
      "name": "Language Understanding",
      "category": "language",
      "x": 0.4,
      "y": 0.65,
      "description": "Comprehend meaning, context, and nuance in text",
      "benchmarks": [
        "superglue"
      ],
      "heights": {},
      "top_models": {}
    },
    "os_navigation": {
      "name": "Os Navigation",
      "category": "agents",
      "x": 0.55,
      "y": 0.85,
      "description": "Find and access files and programs within operating systems",
      "benchmarks": [
        "os_world"
      ],
      "heights": {
        "2024": 0.054,
        "2019": 0.042,
        "2020": 0.044,
        "2021": 0.046,
        "2022": 0.049,
        "2023": 0.051,
        "2025": 0.056
      },
      "top_models": {
        "2024": [
          {
            "model": "gemini-1.5-pro-001",
            "org": "Google DeepMind",
            "benchmark": "os_world",
            "score": 5.4,
            "normalized_score": 0.054000000000000006,
            "date": "2024-05-24"
          }
        ]
      }
    },
    "natural_language_inference": {
      "name": "Natural Language Inference",
      "category": "language",
      "x": 0.35,
      "y": 0.6,
      "description": "Determine logical relationships between text passages",
      "benchmarks": [
        "adversarial_nli"
      ],
      "heights": {
        "2024": 0.487,
        "2019": 0.377,
        "2020": 0.397,
        "2021": 0.418,
        "2022": 0.44,
        "2023": 0.463,
        "2025": 0.502
      },
      "top_models": {
        "2024": [
          {
            "model": "gemma-7b",
            "org": "Google DeepMind",
            "benchmark": "adversarial_nli",
            "score": 0.487,
            "normalized_score": 0.487,
            "date": "2024-02-21"
          }
        ]
      }
    },
    "agent_reasoning": {
      "name": "Agent Reasoning",
      "category": "agents",
      "x": 0.5,
      "y": 0.8,
      "description": "Plan and execute multi-step tasks autonomously",
      "benchmarks": [
        "the_agent_company"
      ],
      "heights": {
        "2024": 0.08,
        "2025": 0.19,
        "2019": 0.062,
        "2020": 0.065,
        "2021": 0.069,
        "2022": 0.072,
        "2023": 0.076
      },
      "top_models": {
        "2024": [
          {
            "model": "gemini-1.5-pro-002",
            "org": "Google DeepMind",
            "benchmark": "the_agent_company",
            "score": 0.08,
            "normalized_score": 0.08,
            "date": "2024-09-24"
          }
        ],
        "2025": [
          {
            "model": "gemini-2.0-flash-001",
            "org": "Google DeepMind,Google",
            "benchmark": "the_agent_company",
            "score": 0.19,
            "normalized_score": 0.19,
            "date": "2025-02-05"
          }
        ]
      }
    },
    "boolean_reasoning": {
      "name": "Boolean Reasoning",
      "category": "reasoning",
      "x": 0.4,
      "y": 0.5,
      "description": "Answer yes/no questions requiring logical deduction",
      "benchmarks": [
        "bool_q"
      ],
      "heights": {
        "2021": 0.794,
        "2022": 0.887,
        "2024": 0.858,
        "2023": 0.873,
        "2019": 0.717,
        "2020": 0.754,
        "2025": 0.884
      },
      "top_models": {
        "2021": [
          {
            "model": "Gopher (280B)",
            "org": "DeepMind",
            "benchmark": "bool_q",
            "score": 0.794,
            "normalized_score": 0.794,
            "date": "2021-12-08"
          }
        ],
        "2022": [
          {
            "model": "PaLM 540B",
            "org": "Google Research",
            "benchmark": "bool_q",
            "score": 0.887,
            "normalized_score": 0.887,
            "date": "2022-04-04"
          }
        ],
        "2024": [
          {
            "model": "gemini-1.5-flash-001",
            "org": "Google DeepMind",
            "benchmark": "bool_q",
            "score": 0.858,
            "normalized_score": 0.858,
            "date": "2024-05-23"
          }
        ]
      }
    },
    "language_modeling": {
      "name": "Language Modeling",
      "category": "language",
      "x": 0.3,
      "y": 0.7,
      "description": "Predict and generate coherent natural language sequences",
      "benchmarks": [
        "lambada"
      ],
      "heights": {
        "2021": 0.745,
        "2022": 0.779,
        "2019": 0.672,
        "2020": 0.708,
        "2023": 0.802,
        "2024": 0.826,
        "2025": 0.851
      },
      "top_models": {
        "2021": [
          {
            "model": "Gopher (280B)",
            "org": "DeepMind",
            "benchmark": "lambada",
            "score": 0.745,
            "normalized_score": 0.745,
            "date": "2021-12-08"
          }
        ],
        "2022": [
          {
            "model": "PaLM 540B",
            "org": "Google Research",
            "benchmark": "lambada",
            "score": 0.779,
            "normalized_score": 0.779,
            "date": "2022-04-04"
          }
        ]
      }
    },
    "terminal_usage": {
      "name": "Terminal Usage",
      "category": "agents",
      "x": 0.45,
      "y": 0.85,
      "description": "Execute commands and navigate command-line interfaces",
      "benchmarks": [
        "terminalbench"
      ],
      "heights": {
        "2025": 0.253,
        "2019": 0.186,
        "2020": 0.196,
        "2021": 0.206,
        "2022": 0.217,
        "2023": 0.228,
        "2024": 0.24
      },
      "top_models": {
        "2025": [
          {
            "model": "gemini-2.5-pro-preview-05-06",
            "org": "Google DeepMind",
            "benchmark": "terminalbench",
            "score": 0.253,
            "normalized_score": 0.253,
            "date": "2025-05-06"
          }
        ]
      }
    }
  },
  "meta": {
    "code_generation": {
      "name": "Code Generation",
      "category": "coding",
      "x": 0.65,
      "y": 0.5,
      "description": "Generate functional code from natural language descriptions",
      "benchmarks": [
        "aider_polyglot",
        "swe_bench_verified",
        "live_bench"
      ],
      "heights": {
        "2024": 0.502,
        "2025": 0.156,
        "2019": 0.388,
        "2020": 0.409,
        "2021": 0.43,
        "2022": 0.453,
        "2023": 0.477
      },
      "top_models": {
        "2024": [
          {
            "model": "Llama-3.3-70B-Instruct",
            "org": "Meta AI",
            "benchmark": "live_bench",
            "score": 50.16,
            "normalized_score": 0.5015999999999999,
            "date": "2024-12-06"
          }
        ],
        "2025": [
          {
            "model": "Llama-4-Maverick-17B-128E-Instruct",
            "org": "Meta AI",
            "benchmark": "aider_polyglot",
            "score": 15.6,
            "normalized_score": 0.156,
            "date": "2025-04-05"
          }
        ]
      }
    },
    "physical_intuition": {
      "name": "Physical Intuition",
      "category": "reasoning",
      "x": 0.5,
      "y": 0.5,
      "description": "Apply understanding of physical laws and object behavior",
      "benchmarks": [
        "piqa"
      ],
      "heights": {
        "2022": 0.69,
        "2023": 0.828,
        "2024": 0.859,
        "2019": 0.592,
        "2020": 0.623,
        "2021": 0.655,
        "2025": 0.885
      },
      "top_models": {
        "2022": [
          {
            "model": "opt-1.3b",
            "org": "Meta AI",
            "benchmark": "piqa",
            "score": 0.69,
            "normalized_score": 0.69,
            "date": "2022-05-11"
          }
        ],
        "2023": [
          {
            "model": "LLaMA-65B",
            "org": "Meta AI",
            "benchmark": "piqa",
            "score": 0.828,
            "normalized_score": 0.828,
            "date": "2023-02-24"
          },
          {
            "model": "Llama-2-70b-hf ",
            "org": "Meta AI",
            "benchmark": "piqa",
            "score": 0.828,
            "normalized_score": 0.828,
            "date": "2023-07-18"
          }
        ],
        "2024": [
          {
            "model": "Llama-3.1-405B",
            "org": "Meta AI",
            "benchmark": "piqa",
            "score": 0.859,
            "normalized_score": 0.859,
            "date": "2024-07-23"
          }
        ]
      }
    },
    "scientific_reasoning": {
      "name": "Scientific Reasoning",
      "category": "knowledge",
      "x": 0.3,
      "y": 0.55,
      "description": "Apply scientific methods and domain knowledge to problems",
      "benchmarks": [
        "science_qa"
      ],
      "heights": {
        "2023": 0.558,
        "2019": 0.454,
        "2020": 0.478,
        "2021": 0.504,
        "2022": 0.53,
        "2024": 0.575,
        "2025": 0.592
      },
      "top_models": {
        "2023": [
          {
            "model": "Llama-2-13b",
            "org": "Meta AI",
            "benchmark": "science_qa",
            "score": 0.5578,
            "normalized_score": 0.5578,
            "date": "2023-07-18"
          }
        ]
      }
    },
    "game_strategy": {
      "name": "Game Strategy",
      "category": "games",
      "x": 0.6,
      "y": 0.2,
      "description": "Develop winning approaches in strategic games",
      "benchmarks": [
        "factorio_learning_environment"
      ],
      "heights": {
        "2024": 549.98,
        "2019": 425.564,
        "2020": 447.962,
        "2021": 471.539,
        "2022": 496.357,
        "2023": 522.481,
        "2025": 1.0
      },
      "top_models": {
        "2024": [
          {
            "model": "Llama-3.3-70B-Instruct",
            "org": "Meta AI",
            "benchmark": "factorio_learning_environment",
            "score": 54998.0,
            "normalized_score": 549.98,
            "date": "2024-12-06"
          }
        ]
      }
    },
    "commonsense_reasoning": {
      "name": "Commonsense Reasoning",
      "category": "reasoning",
      "x": 0.45,
      "y": 0.55,
      "description": "Apply everyday knowledge and intuitive logic",
      "benchmarks": [
        "common_sense_qa_2",
        "wino_grande",
        "arc_ai2",
        "hella_swag"
      ],
      "heights": {
        "2022": 0.544,
        "2023": 0.734,
        "2024": 0.912,
        "2019": 0.466,
        "2020": 0.491,
        "2021": 0.517,
        "2025": 0.939
      },
      "top_models": {
        "2022": [
          {
            "model": "opt-175b",
            "org": "Meta AI",
            "benchmark": "hella_swag",
            "score": 0.791,
            "normalized_score": 0.791,
            "date": "2022-05-02"
          },
          {
            "model": "opt-1.3b",
            "org": "Meta AI",
            "benchmark": "wino_grande",
            "score": 0.61,
            "normalized_score": 0.61,
            "date": "2022-05-11"
          },
          {
            "model": "opt-1.3b",
            "org": "Meta AI",
            "benchmark": "arc_ai2",
            "score": 0.232,
            "normalized_score": 0.232,
            "date": "2022-05-11"
          }
        ],
        "2023": [
          {
            "model": "Llama-2-70b-hf ",
            "org": "Meta AI",
            "benchmark": "hella_swag",
            "score": 0.853,
            "normalized_score": 0.853,
            "date": "2023-07-18"
          },
          {
            "model": "Llama-2-70b-hf ",
            "org": "Meta AI",
            "benchmark": "wino_grande",
            "score": 0.802,
            "normalized_score": 0.802,
            "date": "2023-07-18"
          },
          {
            "model": "Llama-2-70b-hf ",
            "org": "Meta AI",
            "benchmark": "arc_ai2",
            "score": 0.783,
            "normalized_score": 0.783,
            "date": "2023-07-18"
          },
          {
            "model": "Llama-2-70b-hf ",
            "org": "Meta AI",
            "benchmark": "common_sense_qa_2",
            "score": 0.5,
            "normalized_score": 0.5,
            "date": "2023-07-18"
          }
        ],
        "2024": [
          {
            "model": "Llama-3.1-405B",
            "org": "Meta AI",
            "benchmark": "arc_ai2",
            "score": 0.953,
            "normalized_score": 0.953,
            "date": "2024-07-23"
          },
          {
            "model": "Llama-3.1-405B",
            "org": "Meta AI",
            "benchmark": "wino_grande",
            "score": 0.892,
            "normalized_score": 0.892,
            "date": "2024-07-23"
          },
          {
            "model": "Llama-3.1-405B",
            "org": "Meta AI",
            "benchmark": "hella_swag",
            "score": 0.892,
            "normalized_score": 0.892,
            "date": "2024-07-23"
          }
        ]
      }
    },
    "reading_comprehension": {
      "name": "Reading Comprehension",
      "category": "language",
      "x": 0.35,
      "y": 0.65,
      "description": "Extract meaning and answer questions from written passages",
      "benchmarks": [
        "open_book_qa"
      ],
      "heights": {
        "2022": 0.24,
        "2023": 0.602,
        "2024": 0.826,
        "2019": 0.206,
        "2020": 0.217,
        "2021": 0.228,
        "2025": 0.851
      },
      "top_models": {
        "2022": [
          {
            "model": "opt-1.3b",
            "org": "Meta AI",
            "benchmark": "open_book_qa",
            "score": 0.24,
            "normalized_score": 0.24,
            "date": "2022-05-11"
          }
        ],
        "2023": [
          {
            "model": "LLaMA-65B",
            "org": "Meta AI",
            "benchmark": "open_book_qa",
            "score": 0.602,
            "normalized_score": 0.602,
            "date": "2023-02-24"
          },
          {
            "model": "Llama-2-70b-hf ",
            "org": "Meta AI",
            "benchmark": "open_book_qa",
            "score": 0.602,
            "normalized_score": 0.602,
            "date": "2023-07-18"
          }
        ],
        "2024": [
          {
            "model": "Meta-Llama-3-8B-Instruct",
            "org": "Meta AI",
            "benchmark": "open_book_qa",
            "score": 0.826,
            "normalized_score": 0.826,
            "date": "2024-04-18"
          }
        ]
      }
    },
    "game_playing": {
      "name": "Game Playing",
      "category": "games",
      "x": 0.65,
      "y": 0.25,
      "description": "Learn and execute strategies in game environments",
      "benchmarks": [
        "balrog"
      ],
      "heights": {
        "2024": 0.279,
        "2019": 0.216,
        "2020": 0.227,
        "2021": 0.239,
        "2022": 0.252,
        "2023": 0.265,
        "2025": 0.287
      },
      "top_models": {
        "2024": [
          {
            "model": "Llama-3.1-70B-Instruct",
            "org": "Meta AI",
            "benchmark": "balrog",
            "score": 0.279,
            "normalized_score": 0.279,
            "date": "2024-07-23"
          }
        ]
      }
    },
    "creative_writing": {
      "name": "Creative Writing",
      "category": "language",
      "x": 0.2,
      "y": 0.3,
      "description": "Generate original, engaging narrative and expressive text",
      "benchmarks": [
        "fictionlivebench"
      ],
      "heights": {
        "2025": 0.364,
        "2019": 0.268,
        "2020": 0.282,
        "2021": 0.296,
        "2022": 0.312,
        "2023": 0.329,
        "2024": 0.346
      },
      "top_models": {
        "2025": [
          {
            "model": "chutes/Llama-4-Maverick-17B-128E-Instruct",
            "org": "Meta AI",
            "benchmark": "fictionlivebench",
            "score": 0.364,
            "normalized_score": 0.364,
            "date": "2025-04-06"
          }
        ]
      }
    },
    "competition_math": {
      "name": "Competition Math",
      "category": "mathematics",
      "x": 0.85,
      "y": 0.45,
      "description": "Solve competition-level mathematics problems (AMC, AIME, IMO)",
      "benchmarks": [
        "otis_mock_aime_2024_2025"
      ],
      "heights": {
        "2023": 0.0,
        "2024": 0.032,
        "2025": 0.049,
        "2019": 0.0,
        "2020": 0.0,
        "2021": 0.0,
        "2022": 0.0
      },
      "top_models": {
        "2023": [
          {
            "model": "Llama-2-70b-chat-hf",
            "org": "Meta AI",
            "benchmark": "otis_mock_aime_2024_2025",
            "score": 0.0,
            "normalized_score": 0.0,
            "date": "2023-07-18"
          }
        ],
        "2024": [
          {
            "model": "Llama-3.1-405B-Instruct",
            "org": "Meta AI",
            "benchmark": "otis_mock_aime_2024_2025",
            "score": 0.0321864460916233,
            "normalized_score": 0.0321864460916233,
            "date": "2024-07-23"
          }
        ],
        "2025": [
          {
            "model": "Llama-4-Maverick-17B-128E-Instruct-FP8",
            "org": "Meta AI",
            "benchmark": "otis_mock_aime_2024_2025",
            "score": 0.0494852855954187,
            "normalized_score": 0.0494852855954187,
            "date": "2025-04-05"
          }
        ]
      }
    },
    "advanced_reasoning": {
      "name": "Advanced Reasoning",
      "category": "reasoning",
      "x": 0.7,
      "y": 0.4,
      "description": "Handle complex multi-step reasoning across diverse domains",
      "benchmarks": [
        "gpqa_diamond"
      ],
      "heights": {
        "2023": 0.02,
        "2024": 0.029,
        "2025": 0.032,
        "2019": 0.016,
        "2020": 0.017,
        "2021": 0.018,
        "2022": 0.019
      },
      "top_models": {
        "2023": [
          {
            "model": "Llama-2-70b-chat-hf",
            "org": "Meta AI",
            "benchmark": "gpqa_diamond",
            "score": 0.0199018085582841,
            "normalized_score": 0.0199018085582841,
            "date": "2023-07-18"
          }
        ],
        "2024": [
          {
            "model": "Llama-3.3-70B-Instruct",
            "org": "Meta AI",
            "benchmark": "gpqa_diamond",
            "score": 0.028523027562061,
            "normalized_score": 0.028523027562061,
            "date": "2024-12-06"
          }
        ],
        "2025": [
          {
            "model": "Llama-4-Scout-17B-16E-Instruct",
            "org": "Meta AI",
            "benchmark": "gpqa_diamond",
            "score": 0.0315490201249947,
            "normalized_score": 0.0315490201249947,
            "date": "2025-04-05"
          }
        ]
      }
    },
    "mathematical_reasoning": {
      "name": "Mathematical Reasoning",
      "category": "mathematics",
      "x": 0.75,
      "y": 0.45,
      "description": "Solve math problems with step-by-step logical reasoning",
      "benchmarks": [
        "math_level_5",
        "gsm8k"
      ],
      "heights": {
        "2022": 0.04,
        "2023": 0.349,
        "2024": 0.418,
        "2025": 0.012,
        "2019": 0.034,
        "2020": 0.036,
        "2021": 0.038
      },
      "top_models": {
        "2022": [
          {
            "model": "opt-175b",
            "org": "Meta AI",
            "benchmark": "gsm8k",
            "score": 0.04,
            "normalized_score": 0.04,
            "date": "2022-05-02"
          }
        ],
        "2023": [
          {
            "model": "Llama-2-70b-hf ",
            "org": "Meta AI",
            "benchmark": "gsm8k",
            "score": 0.696,
            "normalized_score": 0.696,
            "date": "2023-07-18"
          },
          {
            "model": "Llama-2-70b-chat-hf",
            "org": "Meta AI",
            "benchmark": "math_level_5",
            "score": 0.0025422297741566,
            "normalized_score": 0.0025422297741566,
            "date": "2023-07-18"
          }
        ],
        "2024": [
          {
            "model": "Llama-3.1-8B-Instruct",
            "org": "Meta AI",
            "benchmark": "gsm8k",
            "score": 0.824,
            "normalized_score": 0.824,
            "date": "2024-07-23"
          },
          {
            "model": "Llama-3.1-405B-Instruct",
            "org": "Meta AI",
            "benchmark": "math_level_5",
            "score": 0.0121852759365695,
            "normalized_score": 0.0121852759365695,
            "date": "2024-07-23"
          }
        ],
        "2025": [
          {
            "model": "Llama-4-Scout-17B-16E-Instruct",
            "org": "Meta AI",
            "benchmark": "math_level_5",
            "score": 0.0120224058737839,
            "normalized_score": 0.0120224058737839,
            "date": "2025-04-05"
          }
        ]
      }
    },
    "long_horizon_planning": {
      "name": "Long Horizon Planning",
      "category": "reasoning",
      "x": 0.55,
      "y": 0.75,
      "description": "Plan and reason about extended sequences of actions",
      "benchmarks": [
        "metr_time_horizons"
      ],
      "heights": {},
      "top_models": {}
    },
    "writing_quality": {
      "name": "Writing Quality",
      "category": "language",
      "x": 0.25,
      "y": 0.35,
      "description": "Produce well-structured, grammatically correct, compelling text",
      "benchmarks": [
        "lech_mazur_writing"
      ],
      "heights": {
        "2025": 0.062,
        "2019": 0.046,
        "2020": 0.048,
        "2021": 0.05,
        "2022": 0.053,
        "2023": 0.056,
        "2024": 0.059
      },
      "top_models": {
        "2025": [
          {
            "model": "Llama-4-Maverick-17B-128E-Instruct",
            "org": "Meta AI",
            "benchmark": "lech_mazur_writing",
            "score": 6.2,
            "normalized_score": 0.062,
            "date": "2025-04-05"
          }
        ]
      }
    },
    "cad_design": {
      "name": "Cad Design",
      "category": "reasoning",
      "x": 0.75,
      "y": 0.25,
      "description": "Create and manipulate computer-aided design models",
      "benchmarks": [
        "cad_eval"
      ],
      "heights": {},
      "top_models": {}
    },
    "advanced_mathematics": {
      "name": "Advanced Mathematics",
      "category": "mathematics",
      "x": 0.8,
      "y": 0.4,
      "description": "Solve graduate-level and research mathematics problems",
      "benchmarks": [
        "frontiermath",
        "frontiermath_tier_4"
      ],
      "heights": {
        "2025": 0.005,
        "2019": 0.004,
        "2020": 0.004,
        "2021": 0.004,
        "2022": 0.004,
        "2023": 0.005,
        "2024": 0.005
      },
      "top_models": {
        "2025": [
          {
            "model": "Llama-4-Maverick-17B-128E-Instruct-FP8",
            "org": "Meta AI",
            "benchmark": "frontiermath",
            "score": 0.004868154158215,
            "normalized_score": 0.004868154158215,
            "date": "2025-04-05"
          }
        ]
      }
    },
    "abstract_reasoning": {
      "name": "Abstract Reasoning",
      "category": "reasoning",
      "x": 0.75,
      "y": 0.35,
      "description": "Recognize patterns and solve problems requiring high-level conceptual thinking",
      "benchmarks": [
        "arc_agi"
      ],
      "heights": {
        "2025": 0.044,
        "2019": 0.032,
        "2020": 0.034,
        "2021": 0.036,
        "2022": 0.038,
        "2023": 0.04,
        "2024": 0.042
      },
      "top_models": {
        "2025": [
          {
            "model": "Llama-4-Maverick-17B-128E-Instruct",
            "org": "Meta AI",
            "benchmark": "arc_agi",
            "score": 0.044,
            "normalized_score": 0.044,
            "date": "2025-04-05"
          }
        ]
      }
    },
    "basic_tasks": {
      "name": "Basic Tasks",
      "category": "reasoning",
      "x": 0.4,
      "y": 0.4,
      "description": "Perform fundamental operations and simple problem-solving",
      "benchmarks": [
        "simplebench"
      ],
      "heights": {
        "2024": 0.23,
        "2025": 0.277,
        "2019": 0.178,
        "2020": 0.187,
        "2021": 0.197,
        "2022": 0.208,
        "2023": 0.218
      },
      "top_models": {
        "2024": [
          {
            "model": "Llama-3.1-405B-Instruct",
            "org": "Meta AI",
            "benchmark": "simplebench",
            "score": 0.23,
            "normalized_score": 0.23,
            "date": "2024-07-23"
          }
        ],
        "2025": [
          {
            "model": "Llama-4-Maverick-17B-128E-Instruct",
            "org": "Meta AI",
            "benchmark": "simplebench",
            "score": 0.277,
            "normalized_score": 0.277,
            "date": "2025-04-05"
          }
        ]
      }
    },
    "general_knowledge": {
      "name": "General Knowledge",
      "category": "knowledge",
      "x": 0.25,
      "y": 0.6,
      "description": "Answer questions across diverse academic and cultural domains",
      "benchmarks": [
        "mmlu"
      ],
      "heights": {
        "2023": 0.699,
        "2024": 0.863,
        "2019": 0.569,
        "2020": 0.599,
        "2021": 0.631,
        "2022": 0.664,
        "2025": 0.889
      },
      "top_models": {
        "2023": [
          {
            "model": "Llama-2-70b-hf ",
            "org": "Meta AI",
            "benchmark": "mmlu",
            "score": 0.699,
            "normalized_score": 0.699,
            "date": "2023-07-18"
          }
        ],
        "2024": [
          {
            "model": "Llama-3.3-70B-Instruct",
            "org": "Meta AI",
            "benchmark": "mmlu",
            "score": 0.863,
            "normalized_score": 0.863,
            "date": "2024-12-06"
          }
        ]
      }
    },
    "os_interaction": {
      "name": "Os Interaction",
      "category": "agents",
      "x": 0.6,
      "y": 0.8,
      "description": "Navigate and manipulate operating system interfaces",
      "benchmarks": [
        "os_universe"
      ],
      "heights": {},
      "top_models": {}
    },
    "factual_knowledge": {
      "name": "Factual Knowledge",
      "category": "knowledge",
      "x": 0.2,
      "y": 0.55,
      "description": "Retrieve and apply specific facts across domains",
      "benchmarks": [
        "trivia_qa"
      ],
      "heights": {
        "2023": 0.876,
        "2024": 0.827,
        "2019": 0.714,
        "2020": 0.751,
        "2021": 0.791,
        "2022": 0.832,
        "2025": 0.852
      },
      "top_models": {
        "2023": [
          {
            "model": "Llama-2-70b-hf ",
            "org": "Meta AI",
            "benchmark": "trivia_qa",
            "score": 0.876,
            "normalized_score": 0.876,
            "date": "2023-07-18"
          }
        ],
        "2024": [
          {
            "model": "Llama-3.1-405B",
            "org": "Meta AI",
            "benchmark": "trivia_qa",
            "score": 0.827,
            "normalized_score": 0.827,
            "date": "2024-07-23"
          }
        ]
      }
    },
    "unusual_tasks": {
      "name": "Unusual Tasks",
      "category": "reasoning",
      "x": 0.5,
      "y": 0.3,
      "description": "Handle novel or atypical challenges outside standard benchmarks",
      "benchmarks": [
        "weirdml"
      ],
      "heights": {
        "2024": 0.235,
        "2025": 0.442,
        "2019": 0.182,
        "2020": 0.191,
        "2021": 0.201,
        "2022": 0.212,
        "2023": 0.223
      },
      "top_models": {
        "2024": [
          {
            "model": "llama3.3:70b-instruct-q8_0",
            "org": "Meta AI",
            "benchmark": "weirdml",
            "score": 0.2348,
            "normalized_score": 0.2348,
            "date": "2024-12-06"
          }
        ],
        "2025": [
          {
            "model": "Llama-4-Maverick-17B-128E-Instruct",
            "org": "Meta AI",
            "benchmark": "weirdml",
            "score": 0.4424,
            "normalized_score": 0.4424,
            "date": "2025-04-05"
          }
        ]
      }
    },
    "geographic_knowledge": {
      "name": "Geographic Knowledge",
      "category": "knowledge",
      "x": 0.25,
      "y": 0.5,
      "description": "Understand spatial relationships, locations, and geographic data",
      "benchmarks": [
        "geobench"
      ],
      "heights": {
        "2024": 27.98,
        "2025": 30.69,
        "2019": 21.65,
        "2020": 22.79,
        "2021": 23.989,
        "2022": 25.252,
        "2023": 26.581
      },
      "top_models": {
        "2024": [
          {
            "model": "Llama-3.2-90B-Vision-Instruct",
            "org": "Meta AI",
            "benchmark": "geobench",
            "score": 2798.0,
            "normalized_score": 27.98,
            "date": "2024-09-24"
          }
        ],
        "2025": [
          {
            "model": "Llama-4-Maverick-17B-128E-Instruct",
            "org": "Meta AI",
            "benchmark": "geobench",
            "score": 3069.0,
            "normalized_score": 30.69,
            "date": "2025-04-05"
          }
        ]
      }
    },
    "complex_reasoning": {
      "name": "Complex Reasoning",
      "category": "reasoning",
      "x": 0.65,
      "y": 0.45,
      "description": "Navigate multi-layered logical problems requiring synthesis",
      "benchmarks": [
        "bbh"
      ],
      "heights": {
        "2023": 0.649,
        "2024": 0.829,
        "2019": 0.529,
        "2020": 0.556,
        "2021": 0.586,
        "2022": 0.617,
        "2025": 0.854
      },
      "top_models": {
        "2023": [
          {
            "model": "Llama-2-70b-hf ",
            "org": "Meta AI",
            "benchmark": "bbh",
            "score": 0.649,
            "normalized_score": 0.649,
            "date": "2023-07-18"
          }
        ],
        "2024": [
          {
            "model": "Llama-3.1-405B",
            "org": "Meta AI",
            "benchmark": "bbh",
            "score": 0.829,
            "normalized_score": 0.829,
            "date": "2024-07-23"
          }
        ]
      }
    },
    "spatial_reasoning": {
      "name": "Spatial Reasoning",
      "category": "games",
      "x": 0.55,
      "y": 0.25,
      "description": "Understand and manipulate objects in 2D and 3D space",
      "benchmarks": [
        "gso"
      ],
      "heights": {},
      "top_models": {}
    },
    "cybersecurity": {
      "name": "Cybersecurity",
      "category": "reasoning",
      "x": 0.7,
      "y": 0.2,
      "description": "Identify vulnerabilities and solve security-related challenges",
      "benchmarks": [
        "cybench"
      ],
      "heights": {
        "2024": 0.075,
        "2019": 0.058,
        "2020": 0.061,
        "2021": 0.064,
        "2022": 0.068,
        "2023": 0.071,
        "2025": 0.077
      },
      "top_models": {
        "2024": [
          {
            "model": "Llama-3.1-405B-Instruct",
            "org": "Meta AI",
            "benchmark": "cybench",
            "score": 0.075,
            "normalized_score": 0.075,
            "date": "2024-07-23"
          }
        ]
      }
    },
    "language_understanding": {
      "name": "Language Understanding",
      "category": "language",
      "x": 0.4,
      "y": 0.65,
      "description": "Comprehend meaning, context, and nuance in text",
      "benchmarks": [
        "superglue"
      ],
      "heights": {},
      "top_models": {}
    },
    "os_navigation": {
      "name": "Os Navigation",
      "category": "agents",
      "x": 0.55,
      "y": 0.85,
      "description": "Find and access files and programs within operating systems",
      "benchmarks": [
        "os_world"
      ],
      "heights": {},
      "top_models": {}
    },
    "natural_language_inference": {
      "name": "Natural Language Inference",
      "category": "language",
      "x": 0.35,
      "y": 0.6,
      "description": "Determine logical relationships between text passages",
      "benchmarks": [
        "adversarial_nli"
      ],
      "heights": {
        "2024": 0.573,
        "2019": 0.443,
        "2020": 0.467,
        "2021": 0.491,
        "2022": 0.517,
        "2023": 0.544,
        "2025": 0.59
      },
      "top_models": {
        "2024": [
          {
            "model": "Meta-Llama-3-8B-Instruct",
            "org": "Meta AI",
            "benchmark": "adversarial_nli",
            "score": 0.573,
            "normalized_score": 0.573,
            "date": "2024-04-18"
          }
        ]
      }
    },
    "agent_reasoning": {
      "name": "Agent Reasoning",
      "category": "agents",
      "x": 0.5,
      "y": 0.8,
      "description": "Plan and execute multi-step tasks autonomously",
      "benchmarks": [
        "the_agent_company"
      ],
      "heights": {
        "2024": 0.141,
        "2019": 0.109,
        "2020": 0.115,
        "2021": 0.121,
        "2022": 0.127,
        "2023": 0.134,
        "2025": 0.145
      },
      "top_models": {
        "2024": [
          {
            "model": "Llama-3.1-405B-Instruct",
            "org": "Meta AI",
            "benchmark": "the_agent_company",
            "score": 0.141,
            "normalized_score": 0.141,
            "date": "2024-07-23"
          }
        ]
      }
    },
    "boolean_reasoning": {
      "name": "Boolean Reasoning",
      "category": "reasoning",
      "x": 0.4,
      "y": 0.5,
      "description": "Answer yes/no questions requiring logical deduction",
      "benchmarks": [
        "bool_q"
      ],
      "heights": {
        "2022": 0.793,
        "2023": 0.886,
        "2024": 0.828,
        "2019": 0.68,
        "2020": 0.716,
        "2021": 0.753,
        "2025": 0.853
      },
      "top_models": {
        "2022": [
          {
            "model": "opt-175b",
            "org": "Meta AI",
            "benchmark": "bool_q",
            "score": 0.793,
            "normalized_score": 0.793,
            "date": "2022-05-02"
          }
        ],
        "2023": [
          {
            "model": "Llama-2-70b-hf ",
            "org": "Meta AI",
            "benchmark": "bool_q",
            "score": 0.886,
            "normalized_score": 0.886,
            "date": "2023-07-18"
          }
        ],
        "2024": [
          {
            "model": "Llama-3.1-8B-Instruct",
            "org": "Meta AI",
            "benchmark": "bool_q",
            "score": 0.828,
            "normalized_score": 0.828,
            "date": "2024-07-23"
          }
        ]
      }
    },
    "language_modeling": {
      "name": "Language Modeling",
      "category": "language",
      "x": 0.3,
      "y": 0.7,
      "description": "Predict and generate coherent natural language sequences",
      "benchmarks": [
        "lambada"
      ],
      "heights": {
        "2023": 0.789,
        "2019": 0.643,
        "2020": 0.676,
        "2021": 0.712,
        "2022": 0.75,
        "2024": 0.813,
        "2025": 0.837
      },
      "top_models": {
        "2023": [
          {
            "model": "Llama-2-70b-hf ",
            "org": "Meta AI",
            "benchmark": "lambada",
            "score": 0.789,
            "normalized_score": 0.789,
            "date": "2023-07-18"
          }
        ]
      }
    },
    "terminal_usage": {
      "name": "Terminal Usage",
      "category": "agents",
      "x": 0.45,
      "y": 0.85,
      "description": "Execute commands and navigate command-line interfaces",
      "benchmarks": [
        "terminalbench"
      ],
      "heights": {
        "2025": 0.155,
        "2019": 0.114,
        "2020": 0.12,
        "2021": 0.126,
        "2022": 0.133,
        "2023": 0.14,
        "2024": 0.147
      },
      "top_models": {
        "2025": [
          {
            "model": "Llama-4-Maverick-17B-128E-Instruct",
            "org": "Meta AI",
            "benchmark": "terminalbench",
            "score": 0.155,
            "normalized_score": 0.155,
            "date": "2025-04-05"
          }
        ]
      }
    }
  },
  "mistral_tii": {
    "code_generation": {
      "name": "Code Generation",
      "category": "coding",
      "x": 0.65,
      "y": 0.5,
      "description": "Generate functional code from natural language descriptions",
      "benchmarks": [
        "aider_polyglot",
        "swe_bench_verified",
        "live_bench"
      ],
      "heights": {
        "2024": 0.484,
        "2025": 0.275,
        "2019": 0.375,
        "2020": 0.394,
        "2021": 0.415,
        "2022": 0.437,
        "2023": 0.46
      },
      "top_models": {
        "2024": [
          {
            "model": "mistral-large-2411",
            "org": "Mistral AI",
            "benchmark": "live_bench",
            "score": 48.43,
            "normalized_score": 0.4843,
            "date": "2024-11-18"
          }
        ],
        "2025": [
          {
            "model": "mistral-small-2503",
            "org": "Mistral AI",
            "benchmark": "live_bench",
            "score": 43.96,
            "normalized_score": 0.4396,
            "date": "2025-03-17"
          },
          {
            "model": "codestral-2501",
            "org": "Mistral AI",
            "benchmark": "aider_polyglot",
            "score": 11.1,
            "normalized_score": 0.111,
            "date": "2025-01-13"
          }
        ]
      }
    },
    "physical_intuition": {
      "name": "Physical Intuition",
      "category": "reasoning",
      "x": 0.5,
      "y": 0.5,
      "description": "Apply understanding of physical laws and object behavior",
      "benchmarks": [
        "piqa"
      ],
      "heights": {
        "2023": 0.849,
        "2024": 0.835,
        "2019": 0.692,
        "2020": 0.728,
        "2021": 0.766,
        "2022": 0.807,
        "2025": 0.86
      },
      "top_models": {
        "2023": [
          {
            "model": "falcon-180B",
            "org": "Technology Innovation Institute",
            "benchmark": "piqa",
            "score": 0.849,
            "normalized_score": 0.849,
            "date": "2023-09-06"
          }
        ],
        "2024": [
          {
            "model": "Mistral-Nemo-Base-2407",
            "org": "Mistral AI",
            "benchmark": "piqa",
            "score": 0.835,
            "normalized_score": 0.835,
            "date": "2024-07-18"
          }
        ]
      }
    },
    "scientific_reasoning": {
      "name": "Scientific Reasoning",
      "category": "knowledge",
      "x": 0.3,
      "y": 0.55,
      "description": "Apply scientific methods and domain knowledge to problems",
      "benchmarks": [
        "science_qa"
      ],
      "heights": {},
      "top_models": {}
    },
    "game_strategy": {
      "name": "Game Strategy",
      "category": "games",
      "x": 0.6,
      "y": 0.2,
      "description": "Develop winning approaches in strategic games",
      "benchmarks": [
        "factorio_learning_environment"
      ],
      "heights": {},
      "top_models": {}
    },
    "commonsense_reasoning": {
      "name": "Commonsense Reasoning",
      "category": "reasoning",
      "x": 0.45,
      "y": 0.55,
      "description": "Apply everyday knowledge and intuitive logic",
      "benchmarks": [
        "common_sense_qa_2",
        "wino_grande",
        "arc_ai2",
        "hella_swag"
      ],
      "heights": {
        "2023": 0.878,
        "2024": 0.806,
        "2019": 0.715,
        "2020": 0.753,
        "2021": 0.792,
        "2022": 0.834,
        "2025": 0.83
      },
      "top_models": {
        "2023": [
          {
            "model": "falcon-180B",
            "org": "Technology Innovation Institute",
            "benchmark": "hella_swag",
            "score": 0.89,
            "normalized_score": 0.89,
            "date": "2023-09-06"
          },
          {
            "model": "Mixtral-8x7B-v0.1",
            "org": "Mistral AI",
            "benchmark": "arc_ai2",
            "score": 0.873,
            "normalized_score": 0.873,
            "date": "2023-12-11"
          },
          {
            "model": "falcon-180B",
            "org": "Technology Innovation Institute",
            "benchmark": "wino_grande",
            "score": 0.871,
            "normalized_score": 0.871,
            "date": "2023-09-06"
          }
        ],
        "2024": [
          {
            "model": "falcon-11b",
            "org": "Technology Innovation Institute",
            "benchmark": "hella_swag",
            "score": 0.8291,
            "normalized_score": 0.8291,
            "date": "2024-05-09"
          },
          {
            "model": "falcon-11b",
            "org": "Technology Innovation Institute",
            "benchmark": "wino_grande",
            "score": 0.783,
            "normalized_score": 0.783,
            "date": "2024-05-09"
          }
        ]
      }
    },
    "reading_comprehension": {
      "name": "Reading Comprehension",
      "category": "language",
      "x": 0.35,
      "y": 0.65,
      "description": "Extract meaning and answer questions from written passages",
      "benchmarks": [
        "open_book_qa"
      ],
      "heights": {
        "2023": 0.858,
        "2019": 0.699,
        "2020": 0.736,
        "2021": 0.774,
        "2022": 0.815,
        "2024": 0.884,
        "2025": 0.91
      },
      "top_models": {
        "2023": [
          {
            "model": "Mixtral-8x7B-v0.1",
            "org": "Mistral AI",
            "benchmark": "open_book_qa",
            "score": 0.858,
            "normalized_score": 0.858,
            "date": "2023-12-11"
          }
        ]
      }
    },
    "game_playing": {
      "name": "Game Playing",
      "category": "games",
      "x": 0.65,
      "y": 0.25,
      "description": "Learn and execute strategies in game environments",
      "benchmarks": [
        "balrog"
      ],
      "heights": {
        "2024": 0.176,
        "2019": 0.136,
        "2020": 0.143,
        "2021": 0.151,
        "2022": 0.159,
        "2023": 0.167,
        "2025": 0.181
      },
      "top_models": {
        "2024": [
          {
            "model": "Mistral-Nemo-Instruct-2407",
            "org": "Mistral AI",
            "benchmark": "balrog",
            "score": 0.176,
            "normalized_score": 0.176,
            "date": "2024-07-18"
          }
        ]
      }
    },
    "creative_writing": {
      "name": "Creative Writing",
      "category": "language",
      "x": 0.2,
      "y": 0.3,
      "description": "Generate original, engaging narrative and expressive text",
      "benchmarks": [
        "fictionlivebench"
      ],
      "heights": {},
      "top_models": {}
    },
    "competition_math": {
      "name": "Competition Math",
      "category": "mathematics",
      "x": 0.85,
      "y": 0.45,
      "description": "Solve competition-level mathematics problems (AMC, AIME, IMO)",
      "benchmarks": [
        "otis_mock_aime_2024_2025"
      ],
      "heights": {
        "2024": 0.025,
        "2025": 0.06,
        "2019": 0.019,
        "2020": 0.02,
        "2021": 0.021,
        "2022": 0.023,
        "2023": 0.024
      },
      "top_models": {
        "2024": [
          {
            "model": "mistral-large-2407",
            "org": "Mistral AI",
            "benchmark": "otis_mock_aime_2024_2025",
            "score": 0.0247426427977093,
            "normalized_score": 0.0247426427977093,
            "date": "2024-07-24"
          }
        ],
        "2025": [
          {
            "model": "mistral-medium-2505",
            "org": "Mistral AI",
            "benchmark": "otis_mock_aime_2024_2025",
            "score": 0.0596561179848226,
            "normalized_score": 0.0596561179848226,
            "date": "2025-05-07"
          }
        ]
      }
    },
    "advanced_reasoning": {
      "name": "Advanced Reasoning",
      "category": "reasoning",
      "x": 0.7,
      "y": 0.4,
      "description": "Handle complex multi-step reasoning across diverse domains",
      "benchmarks": [
        "gpqa_diamond"
      ],
      "heights": {
        "2023": 0.019,
        "2024": 0.027,
        "2025": 0.028,
        "2019": 0.015,
        "2020": 0.016,
        "2021": 0.017,
        "2022": 0.018
      },
      "top_models": {
        "2023": [
          {
            "model": "Mixtral-8x7B-Instruct-v0.1",
            "org": "Mistral AI",
            "benchmark": "gpqa_diamond",
            "score": 0.0193705960394135,
            "normalized_score": 0.0193705960394135,
            "date": "2023-12-11"
          }
        ],
        "2024": [
          {
            "model": "mistral-large-2411",
            "org": "Mistral AI",
            "benchmark": "gpqa_diamond",
            "score": 0.026887818295509,
            "normalized_score": 0.026887818295509,
            "date": "2024-11-18"
          }
        ],
        "2025": [
          {
            "model": "mistral-medium-2505",
            "org": "Mistral AI",
            "benchmark": "gpqa_diamond",
            "score": 0.0282469722965464,
            "normalized_score": 0.0282469722965464,
            "date": "2025-05-07"
          }
        ]
      }
    },
    "mathematical_reasoning": {
      "name": "Mathematical Reasoning",
      "category": "mathematics",
      "x": 0.75,
      "y": 0.45,
      "description": "Solve math problems with step-by-step logical reasoning",
      "benchmarks": [
        "math_level_5",
        "gsm8k"
      ],
      "heights": {
        "2023": 0.375,
        "2024": 0.427,
        "2025": 0.012,
        "2019": 0.305,
        "2020": 0.322,
        "2021": 0.338,
        "2022": 0.356
      },
      "top_models": {
        "2023": [
          {
            "model": "Mixtral-8x7B-v0.1",
            "org": "Mistral AI",
            "benchmark": "gsm8k",
            "score": 0.744,
            "normalized_score": 0.744,
            "date": "2023-12-11"
          },
          {
            "model": "open-mixtral-8x7b",
            "org": "Mistral AI",
            "benchmark": "math_level_5",
            "score": 0.0053032722455159,
            "normalized_score": 0.0053032722455159,
            "date": "2023-12-11"
          }
        ],
        "2024": [
          {
            "model": "Mistral-Nemo-Base-2407",
            "org": "Mistral AI",
            "benchmark": "gsm8k",
            "score": 0.842,
            "normalized_score": 0.842,
            "date": "2024-07-18"
          },
          {
            "model": "mistral-large-2411",
            "org": "Mistral AI",
            "benchmark": "math_level_5",
            "score": 0.0114694516234809,
            "normalized_score": 0.0114694516234809,
            "date": "2024-11-18"
          }
        ],
        "2025": [
          {
            "model": "mistral-small-2503",
            "org": "Mistral AI",
            "benchmark": "math_level_5",
            "score": 0.0119957003779657,
            "normalized_score": 0.0119957003779657,
            "date": "2025-03-17"
          }
        ]
      }
    },
    "long_horizon_planning": {
      "name": "Long Horizon Planning",
      "category": "reasoning",
      "x": 0.55,
      "y": 0.75,
      "description": "Plan and reason about extended sequences of actions",
      "benchmarks": [
        "metr_time_horizons"
      ],
      "heights": {},
      "top_models": {}
    },
    "writing_quality": {
      "name": "Writing Quality",
      "category": "language",
      "x": 0.25,
      "y": 0.35,
      "description": "Produce well-structured, grammatically correct, compelling text",
      "benchmarks": [
        "lech_mazur_writing"
      ],
      "heights": {
        "2024": 0.069,
        "2019": 0.053,
        "2020": 0.056,
        "2021": 0.059,
        "2022": 0.062,
        "2023": 0.066,
        "2025": 0.071
      },
      "top_models": {
        "2024": [
          {
            "model": "mistral-large-2407",
            "org": "Mistral AI",
            "benchmark": "lech_mazur_writing",
            "score": 6.9,
            "normalized_score": 0.069,
            "date": "2024-07-24"
          }
        ]
      }
    },
    "cad_design": {
      "name": "Cad Design",
      "category": "reasoning",
      "x": 0.75,
      "y": 0.25,
      "description": "Create and manipulate computer-aided design models",
      "benchmarks": [
        "cad_eval"
      ],
      "heights": {},
      "top_models": {}
    },
    "advanced_mathematics": {
      "name": "Advanced Mathematics",
      "category": "mathematics",
      "x": 0.8,
      "y": 0.4,
      "description": "Solve graduate-level and research mathematics problems",
      "benchmarks": [
        "frontiermath",
        "frontiermath_tier_4"
      ],
      "heights": {
        "2024": 0.003,
        "2025": 0.003,
        "2019": 0.002,
        "2020": 0.002,
        "2021": 0.003,
        "2022": 0.003,
        "2023": 0.003
      },
      "top_models": {
        "2024": [
          {
            "model": "mistral-large-2411",
            "org": "Mistral AI",
            "benchmark": "frontiermath",
            "score": 0.0034482758620689,
            "normalized_score": 0.0034482758620689,
            "date": "2024-11-18"
          }
        ],
        "2025": [
          {
            "model": "mistral-medium-2505",
            "org": "Mistral AI",
            "benchmark": "frontiermath",
            "score": 0.0034602076124567,
            "normalized_score": 0.0034602076124567,
            "date": "2025-05-07"
          }
        ]
      }
    },
    "abstract_reasoning": {
      "name": "Abstract Reasoning",
      "category": "reasoning",
      "x": 0.75,
      "y": 0.35,
      "description": "Recognize patterns and solve problems requiring high-level conceptual thinking",
      "benchmarks": [
        "arc_agi"
      ],
      "heights": {},
      "top_models": {}
    },
    "basic_tasks": {
      "name": "Basic Tasks",
      "category": "reasoning",
      "x": 0.4,
      "y": 0.4,
      "description": "Perform fundamental operations and simple problem-solving",
      "benchmarks": [
        "simplebench"
      ],
      "heights": {
        "2024": 0.225,
        "2019": 0.174,
        "2020": 0.183,
        "2021": 0.193,
        "2022": 0.203,
        "2023": 0.214,
        "2025": 0.232
      },
      "top_models": {
        "2024": [
          {
            "model": "mistral-large-2407",
            "org": "Mistral AI",
            "benchmark": "simplebench",
            "score": 0.225,
            "normalized_score": 0.225,
            "date": "2024-07-24"
          }
        ]
      }
    },
    "general_knowledge": {
      "name": "General Knowledge",
      "category": "knowledge",
      "x": 0.25,
      "y": 0.6,
      "description": "Answer questions across diverse academic and cultural domains",
      "benchmarks": [
        "mmlu"
      ],
      "heights": {
        "2023": 0.706,
        "2024": 0.8,
        "2019": 0.575,
        "2020": 0.605,
        "2021": 0.637,
        "2022": 0.671,
        "2025": 0.824
      },
      "top_models": {
        "2023": [
          {
            "model": "falcon-180B",
            "org": "Technology Innovation Institute",
            "benchmark": "mmlu",
            "score": 0.706,
            "normalized_score": 0.706,
            "date": "2023-09-06"
          },
          {
            "model": "Mixtral-8x7B-v0.1",
            "org": "Mistral AI",
            "benchmark": "mmlu",
            "score": 0.706,
            "normalized_score": 0.706,
            "date": "2023-12-11"
          }
        ],
        "2024": [
          {
            "model": "mistral-large-2407",
            "org": "Mistral AI",
            "benchmark": "mmlu",
            "score": 0.8,
            "normalized_score": 0.8,
            "date": "2024-07-24"
          }
        ]
      }
    },
    "os_interaction": {
      "name": "Os Interaction",
      "category": "agents",
      "x": 0.6,
      "y": 0.8,
      "description": "Navigate and manipulate operating system interfaces",
      "benchmarks": [
        "os_universe"
      ],
      "heights": {},
      "top_models": {}
    },
    "factual_knowledge": {
      "name": "Factual Knowledge",
      "category": "knowledge",
      "x": 0.2,
      "y": 0.55,
      "description": "Retrieve and apply specific facts across domains",
      "benchmarks": [
        "trivia_qa"
      ],
      "heights": {
        "2023": 0.822,
        "2019": 0.67,
        "2020": 0.705,
        "2021": 0.742,
        "2022": 0.781,
        "2024": 0.847,
        "2025": 0.872
      },
      "top_models": {
        "2023": [
          {
            "model": "Mixtral-8x7B-v0.1",
            "org": "Mistral AI",
            "benchmark": "trivia_qa",
            "score": 0.822,
            "normalized_score": 0.822,
            "date": "2023-12-11"
          }
        ]
      }
    },
    "unusual_tasks": {
      "name": "Unusual Tasks",
      "category": "reasoning",
      "x": 0.5,
      "y": 0.3,
      "description": "Handle novel or atypical challenges outside standard benchmarks",
      "benchmarks": [
        "weirdml"
      ],
      "heights": {
        "2025": 0.319,
        "2019": 0.234,
        "2020": 0.247,
        "2021": 0.26,
        "2022": 0.274,
        "2023": 0.288,
        "2024": 0.303
      },
      "top_models": {
        "2025": [
          {
            "model": "mistral-medium-2505",
            "org": "Mistral AI",
            "benchmark": "weirdml",
            "score": 0.3192,
            "normalized_score": 0.3192,
            "date": "2025-05-07"
          }
        ]
      }
    },
    "geographic_knowledge": {
      "name": "Geographic Knowledge",
      "category": "knowledge",
      "x": 0.25,
      "y": 0.5,
      "description": "Understand spatial relationships, locations, and geographic data",
      "benchmarks": [
        "geobench"
      ],
      "heights": {
        "2024": 21.31,
        "2019": 16.489,
        "2020": 17.357,
        "2021": 18.271,
        "2022": 19.232,
        "2023": 20.244,
        "2025": 1.0
      },
      "top_models": {
        "2024": [
          {
            "model": "Pixtral-12B-2409",
            "org": "Mistral AI",
            "benchmark": "geobench",
            "score": 2131.0,
            "normalized_score": 21.31,
            "date": "2024-09-17"
          }
        ]
      }
    },
    "complex_reasoning": {
      "name": "Complex Reasoning",
      "category": "reasoning",
      "x": 0.65,
      "y": 0.45,
      "description": "Navigate multi-layered logical problems requiring synthesis",
      "benchmarks": [
        "bbh"
      ],
      "heights": {
        "2023": 0.561,
        "2019": 0.457,
        "2020": 0.481,
        "2021": 0.506,
        "2022": 0.533,
        "2024": 0.578,
        "2025": 0.595
      },
      "top_models": {
        "2023": [
          {
            "model": "Mistral-7B-v0.1",
            "org": "Mistral AI",
            "benchmark": "bbh",
            "score": 0.561,
            "normalized_score": 0.561,
            "date": "2023-09-27"
          }
        ]
      }
    },
    "spatial_reasoning": {
      "name": "Spatial Reasoning",
      "category": "games",
      "x": 0.55,
      "y": 0.25,
      "description": "Understand and manipulate objects in 2D and 3D space",
      "benchmarks": [
        "gso"
      ],
      "heights": {},
      "top_models": {}
    },
    "cybersecurity": {
      "name": "Cybersecurity",
      "category": "reasoning",
      "x": 0.7,
      "y": 0.2,
      "description": "Identify vulnerabilities and solve security-related challenges",
      "benchmarks": [
        "cybench"
      ],
      "heights": {
        "2024": 0.075,
        "2019": 0.058,
        "2020": 0.061,
        "2021": 0.064,
        "2022": 0.068,
        "2023": 0.071,
        "2025": 0.077
      },
      "top_models": {
        "2024": [
          {
            "model": "Mixtral-8x22B-Instruct-v0.1",
            "org": "Mistral AI",
            "benchmark": "cybench",
            "score": 0.075,
            "normalized_score": 0.075,
            "date": "2024-04-17"
          }
        ]
      }
    },
    "language_understanding": {
      "name": "Language Understanding",
      "category": "language",
      "x": 0.4,
      "y": 0.65,
      "description": "Comprehend meaning, context, and nuance in text",
      "benchmarks": [
        "superglue"
      ],
      "heights": {},
      "top_models": {}
    },
    "os_navigation": {
      "name": "Os Navigation",
      "category": "agents",
      "x": 0.55,
      "y": 0.85,
      "description": "Find and access files and programs within operating systems",
      "benchmarks": [
        "os_world"
      ],
      "heights": {},
      "top_models": {}
    },
    "natural_language_inference": {
      "name": "Natural Language Inference",
      "category": "language",
      "x": 0.35,
      "y": 0.6,
      "description": "Determine logical relationships between text passages",
      "benchmarks": [
        "adversarial_nli"
      ],
      "heights": {
        "2023": 0.552,
        "2019": 0.45,
        "2020": 0.473,
        "2021": 0.498,
        "2022": 0.524,
        "2024": 0.569,
        "2025": 0.586
      },
      "top_models": {
        "2023": [
          {
            "model": "Mixtral-8x7B-v0.1",
            "org": "Mistral AI",
            "benchmark": "adversarial_nli",
            "score": 0.552,
            "normalized_score": 0.552,
            "date": "2023-12-11"
          }
        ]
      }
    },
    "agent_reasoning": {
      "name": "Agent Reasoning",
      "category": "agents",
      "x": 0.5,
      "y": 0.8,
      "description": "Plan and execute multi-step tasks autonomously",
      "benchmarks": [
        "the_agent_company"
      ],
      "heights": {},
      "top_models": {}
    },
    "boolean_reasoning": {
      "name": "Boolean Reasoning",
      "category": "reasoning",
      "x": 0.4,
      "y": 0.5,
      "description": "Answer yes/no questions requiring logical deduction",
      "benchmarks": [
        "bool_q"
      ],
      "heights": {
        "2023": 0.89,
        "2024": 0.825,
        "2019": 0.725,
        "2020": 0.763,
        "2021": 0.803,
        "2022": 0.845,
        "2025": 0.85
      },
      "top_models": {
        "2023": [
          {
            "model": "falcon-180B",
            "org": "Technology Innovation Institute",
            "benchmark": "bool_q",
            "score": 0.89,
            "normalized_score": 0.89,
            "date": "2023-09-06"
          }
        ],
        "2024": [
          {
            "model": "Mistral-Nemo-Base-2407",
            "org": "Mistral AI",
            "benchmark": "bool_q",
            "score": 0.825,
            "normalized_score": 0.825,
            "date": "2024-07-18"
          }
        ]
      }
    },
    "language_modeling": {
      "name": "Language Modeling",
      "category": "language",
      "x": 0.3,
      "y": 0.7,
      "description": "Predict and generate coherent natural language sequences",
      "benchmarks": [
        "lambada"
      ],
      "heights": {
        "2023": 0.798,
        "2019": 0.65,
        "2020": 0.684,
        "2021": 0.72,
        "2022": 0.758,
        "2024": 0.822,
        "2025": 0.847
      },
      "top_models": {
        "2023": [
          {
            "model": "falcon-180B",
            "org": "Technology Innovation Institute",
            "benchmark": "lambada",
            "score": 0.798,
            "normalized_score": 0.798,
            "date": "2023-09-06"
          }
        ]
      }
    },
    "terminal_usage": {
      "name": "Terminal Usage",
      "category": "agents",
      "x": 0.45,
      "y": 0.85,
      "description": "Execute commands and navigate command-line interfaces",
      "benchmarks": [
        "terminalbench"
      ],
      "heights": {},
      "top_models": {}
    }
  },
  "chinese_labs": {
    "code_generation": {
      "name": "Code Generation",
      "category": "coding",
      "x": 0.65,
      "y": 0.5,
      "description": "Generate functional code from natural language descriptions",
      "benchmarks": [
        "aider_polyglot",
        "swe_bench_verified",
        "live_bench"
      ],
      "heights": {
        "2024": 0.544,
        "2025": 0.485,
        "2019": 0.421,
        "2020": 0.443,
        "2021": 0.466,
        "2022": 0.491,
        "2023": 0.517
      },
      "top_models": {
        "2024": [
          {
            "model": "DeepSeek-V3",
            "org": "DeepSeek",
            "benchmark": "live_bench",
            "score": 60.45,
            "normalized_score": 0.6045,
            "date": "2024-12-26"
          },
          {
            "model": "DeepSeek-V3",
            "org": "DeepSeek",
            "benchmark": "aider_polyglot",
            "score": 48.4,
            "normalized_score": 0.484,
            "date": "2024-12-26"
          }
        ],
        "2025": [
          {
            "model": "QwQ-32B",
            "org": "Alibaba",
            "benchmark": "live_bench",
            "score": 71.96,
            "normalized_score": 0.7195999999999999,
            "date": "2025-03-05"
          },
          {
            "model": "DeepSeek-R1-0528",
            "org": "DeepSeek",
            "benchmark": "aider_polyglot",
            "score": 71.4,
            "normalized_score": 0.7140000000000001,
            "date": "2025-05-28"
          },
          {
            "model": "DeepSeek-V3.1",
            "org": "DeepSeek",
            "benchmark": "swe_bench_verified",
            "score": 0.0223856859876182,
            "normalized_score": 0.0223856859876182,
            "date": "2025-08-21"
          }
        ]
      }
    },
    "physical_intuition": {
      "name": "Physical Intuition",
      "category": "reasoning",
      "x": 0.5,
      "y": 0.5,
      "description": "Apply understanding of physical laws and object behavior",
      "benchmarks": [
        "piqa"
      ],
      "heights": {
        "2023": 0.799,
        "2024": 0.847,
        "2019": 0.651,
        "2020": 0.685,
        "2021": 0.721,
        "2022": 0.759,
        "2025": 0.872
      },
      "top_models": {
        "2023": [
          {
            "model": "Qwen-14B",
            "org": "Alibaba",
            "benchmark": "piqa",
            "score": 0.799,
            "normalized_score": 0.799,
            "date": "2023-09-28"
          }
        ],
        "2024": [
          {
            "model": "DeepSeek-V3-Base",
            "org": "DeepSeek",
            "benchmark": "piqa",
            "score": 0.847,
            "normalized_score": 0.847,
            "date": "2024-12-26"
          }
        ]
      }
    },
    "scientific_reasoning": {
      "name": "Scientific Reasoning",
      "category": "knowledge",
      "x": 0.3,
      "y": 0.55,
      "description": "Apply scientific methods and domain knowledge to problems",
      "benchmarks": [
        "science_qa"
      ],
      "heights": {},
      "top_models": {}
    },
    "game_strategy": {
      "name": "Game Strategy",
      "category": "games",
      "x": 0.6,
      "y": 0.2,
      "description": "Develop winning approaches in strategic games",
      "benchmarks": [
        "factorio_learning_environment"
      ],
      "heights": {
        "2024": 485.85,
        "2019": 375.941,
        "2020": 395.728,
        "2021": 416.556,
        "2022": 438.48,
        "2023": 461.558,
        "2025": 1.0
      },
      "top_models": {
        "2024": [
          {
            "model": "DeepSeek-V3",
            "org": "DeepSeek",
            "benchmark": "factorio_learning_environment",
            "score": 48585.0,
            "normalized_score": 485.85,
            "date": "2024-12-26"
          }
        ]
      }
    },
    "commonsense_reasoning": {
      "name": "Commonsense Reasoning",
      "category": "reasoning",
      "x": 0.45,
      "y": 0.55,
      "description": "Apply everyday knowledge and intuitive logic",
      "benchmarks": [
        "common_sense_qa_2",
        "wino_grande",
        "arc_ai2",
        "hella_swag"
      ],
      "heights": {
        "2023": 0.767,
        "2024": 0.902,
        "2019": 0.625,
        "2020": 0.658,
        "2021": 0.692,
        "2022": 0.729,
        "2025": 0.929
      },
      "top_models": {
        "2023": [
          {
            "model": "Qwen-14B",
            "org": "Alibaba",
            "benchmark": "arc_ai2",
            "score": 0.844,
            "normalized_score": 0.844,
            "date": "2023-09-28"
          },
          {
            "model": "Yi-6B",
            "org": "01.AI",
            "benchmark": "hella_swag",
            "score": 0.744,
            "normalized_score": 0.744,
            "date": "2023-11-02"
          },
          {
            "model": "Yi-6B",
            "org": "01.AI",
            "benchmark": "wino_grande",
            "score": 0.713,
            "normalized_score": 0.713,
            "date": "2023-11-02"
          }
        ],
        "2024": [
          {
            "model": "DeepSeek-V3",
            "org": "DeepSeek",
            "benchmark": "arc_ai2",
            "score": 0.953,
            "normalized_score": 0.953,
            "date": "2024-12-26"
          },
          {
            "model": "DeepSeek-V3",
            "org": "DeepSeek",
            "benchmark": "hella_swag",
            "score": 0.889,
            "normalized_score": 0.889,
            "date": "2024-12-26"
          },
          {
            "model": "DeepSeek-V2",
            "org": "DeepSeek",
            "benchmark": "wino_grande",
            "score": 0.863,
            "normalized_score": 0.863,
            "date": "2024-05-07"
          }
        ]
      }
    },
    "reading_comprehension": {
      "name": "Reading Comprehension",
      "category": "language",
      "x": 0.35,
      "y": 0.65,
      "description": "Extract meaning and answer questions from written passages",
      "benchmarks": [
        "open_book_qa"
      ],
      "heights": {},
      "top_models": {}
    },
    "game_playing": {
      "name": "Game Playing",
      "category": "games",
      "x": 0.65,
      "y": 0.25,
      "description": "Learn and execute strategies in game environments",
      "benchmarks": [
        "balrog"
      ],
      "heights": {
        "2024": 0.162,
        "2025": 0.349,
        "2019": 0.125,
        "2020": 0.132,
        "2021": 0.139,
        "2022": 0.146,
        "2023": 0.154
      },
      "top_models": {
        "2024": [
          {
            "model": "qwen2.5-72b-instruct",
            "org": "Alibaba",
            "benchmark": "balrog",
            "score": 0.162,
            "normalized_score": 0.162,
            "date": "2024-09-19"
          }
        ],
        "2025": [
          {
            "model": "DeepSeek-R1",
            "org": "DeepSeek",
            "benchmark": "balrog",
            "score": 0.349,
            "normalized_score": 0.349,
            "date": "2025-01-20"
          }
        ]
      }
    },
    "creative_writing": {
      "name": "Creative Writing",
      "category": "language",
      "x": 0.2,
      "y": 0.3,
      "description": "Generate original, engaging narrative and expressive text",
      "benchmarks": [
        "fictionlivebench"
      ],
      "heights": {
        "2025": 0.688,
        "2019": 0.506,
        "2020": 0.532,
        "2021": 0.56,
        "2022": 0.59,
        "2023": 0.621,
        "2024": 0.654
      },
      "top_models": {
        "2025": [
          {
            "model": "chutes/Qwen3-235B-A22B-Thinking-2507",
            "org": "Alibaba",
            "benchmark": "fictionlivebench",
            "score": 0.688,
            "normalized_score": 0.688,
            "date": "2025-07-25"
          }
        ]
      }
    },
    "competition_math": {
      "name": "Competition Math",
      "category": "mathematics",
      "x": 0.85,
      "y": 0.45,
      "description": "Solve competition-level mathematics problems (AMC, AIME, IMO)",
      "benchmarks": [
        "otis_mock_aime_2024_2025"
      ],
      "heights": {
        "2024": 0.043,
        "2025": 0.075,
        "2019": 0.033,
        "2020": 0.035,
        "2021": 0.037,
        "2022": 0.039,
        "2023": 0.041
      },
      "top_models": {
        "2024": [
          {
            "model": "DeepSeek-V3",
            "org": "DeepSeek",
            "benchmark": "otis_mock_aime_2024_2025",
            "score": 0.0433650088193118,
            "normalized_score": 0.0433650088193118,
            "date": "2024-12-26"
          }
        ],
        "2025": [
          {
            "model": "DeepSeek-R1",
            "org": "DeepSeek",
            "benchmark": "otis_mock_aime_2024_2025",
            "score": 0.0752101433090354,
            "normalized_score": 0.0752101433090354,
            "date": "2025-01-20"
          }
        ]
      }
    },
    "advanced_reasoning": {
      "name": "Advanced Reasoning",
      "category": "reasoning",
      "x": 0.7,
      "y": 0.4,
      "description": "Handle complex multi-step reasoning across diverse domains",
      "benchmarks": [
        "gpqa_diamond"
      ],
      "heights": {
        "2023": 0.014,
        "2024": 0.028,
        "2025": 0.031,
        "2019": 0.011,
        "2020": 0.012,
        "2021": 0.013,
        "2022": 0.013
      },
      "top_models": {
        "2023": [
          {
            "model": "deepseek-llm-67b-chat",
            "org": "DeepSeek",
            "benchmark": "gpqa_diamond",
            "score": 0.0136233519507619,
            "normalized_score": 0.0136233519507619,
            "date": "2023-11-29"
          }
        ],
        "2024": [
          {
            "model": "DeepSeek-V3",
            "org": "DeepSeek",
            "benchmark": "gpqa_diamond",
            "score": 0.0276399002995089,
            "normalized_score": 0.0276399002995089,
            "date": "2024-12-26"
          }
        ],
        "2025": [
          {
            "model": "DeepSeek-R1",
            "org": "DeepSeek",
            "benchmark": "gpqa_diamond",
            "score": 0.0307048569332127,
            "normalized_score": 0.0307048569332127,
            "date": "2025-01-20"
          }
        ]
      }
    },
    "mathematical_reasoning": {
      "name": "Mathematical Reasoning",
      "category": "mathematics",
      "x": 0.75,
      "y": 0.45,
      "description": "Solve math problems with step-by-step logical reasoning",
      "benchmarks": [
        "math_level_5",
        "gsm8k"
      ],
      "heights": {
        "2023": 0.382,
        "2024": 0.478,
        "2025": 0.011,
        "2019": 0.311,
        "2020": 0.328,
        "2021": 0.345,
        "2022": 0.363
      },
      "top_models": {
        "2023": [
          {
            "model": "Yi-34B-Chat",
            "org": "01.AI",
            "benchmark": "gsm8k",
            "score": 0.76,
            "normalized_score": 0.76,
            "date": "2023-11-22"
          },
          {
            "model": "deepseek-llm-67b-chat",
            "org": "DeepSeek",
            "benchmark": "math_level_5",
            "score": 0.0040168441495506,
            "normalized_score": 0.0040168441495506,
            "date": "2023-11-29"
          }
        ],
        "2024": [
          {
            "model": "DeepSeek-Coder-V2-Instruct",
            "org": "DeepSeek",
            "benchmark": "gsm8k",
            "score": 0.945,
            "normalized_score": 0.945,
            "date": "2024-06-17"
          },
          {
            "model": "qwen-turbo-2024-11-01",
            "org": "Alibaba",
            "benchmark": "math_level_5",
            "score": 0.0113646309475505,
            "normalized_score": 0.0113646309475505,
            "date": "2024-11-01"
          }
        ],
        "2025": [
          {
            "model": "qwen-plus-2025-01-25",
            "org": "Alibaba",
            "benchmark": "math_level_5",
            "score": 0.0113346547740465,
            "normalized_score": 0.0113346547740465,
            "date": "2025-01-25"
          }
        ]
      }
    },
    "long_horizon_planning": {
      "name": "Long Horizon Planning",
      "category": "reasoning",
      "x": 0.55,
      "y": 0.75,
      "description": "Plan and reason about extended sequences of actions",
      "benchmarks": [
        "metr_time_horizons"
      ],
      "heights": {
        "2024": 0.474,
        "2025": 0.538,
        "2019": 0.367,
        "2020": 0.386,
        "2021": 0.406,
        "2022": 0.428,
        "2023": 0.45
      },
      "top_models": {
        "2024": [
          {
            "model": "DeepSeek-V3",
            "org": "DeepSeek",
            "benchmark": "metr_time_horizons",
            "score": 0.473627,
            "normalized_score": 0.473627,
            "date": "2024-12-26"
          }
        ],
        "2025": [
          {
            "model": "DeepSeek-R1-0528",
            "org": "DeepSeek",
            "benchmark": "metr_time_horizons",
            "score": 0.537826,
            "normalized_score": 0.537826,
            "date": "2025-05-28"
          }
        ]
      }
    },
    "writing_quality": {
      "name": "Writing Quality",
      "category": "language",
      "x": 0.25,
      "y": 0.35,
      "description": "Produce well-structured, grammatically correct, compelling text",
      "benchmarks": [
        "lech_mazur_writing"
      ],
      "heights": {
        "2025": 0.083,
        "2019": 0.061,
        "2020": 0.064,
        "2021": 0.068,
        "2022": 0.071,
        "2023": 0.075,
        "2024": 0.079
      },
      "top_models": {
        "2025": [
          {
            "model": "qwen3-235b-a22b",
            "org": "Alibaba",
            "benchmark": "lech_mazur_writing",
            "score": 8.3,
            "normalized_score": 0.083,
            "date": "2025-04-29"
          },
          {
            "model": "DeepSeek-R1",
            "org": "DeepSeek",
            "benchmark": "lech_mazur_writing",
            "score": 8.3,
            "normalized_score": 0.083,
            "date": "2025-01-20"
          }
        ]
      }
    },
    "cad_design": {
      "name": "Cad Design",
      "category": "reasoning",
      "x": 0.75,
      "y": 0.25,
      "description": "Create and manipulate computer-aided design models",
      "benchmarks": [
        "cad_eval"
      ],
      "heights": {},
      "top_models": {}
    },
    "advanced_mathematics": {
      "name": "Advanced Mathematics",
      "category": "mathematics",
      "x": 0.8,
      "y": 0.4,
      "description": "Solve graduate-level and research mathematics problems",
      "benchmarks": [
        "frontiermath",
        "frontiermath_tier_4"
      ],
      "heights": {
        "2024": 0.008,
        "2025": 0.004,
        "2019": 0.006,
        "2020": 0.007,
        "2021": 0.007,
        "2022": 0.007,
        "2023": 0.008
      },
      "top_models": {
        "2024": [
          {
            "model": "DeepSeek-V3",
            "org": "DeepSeek",
            "benchmark": "frontiermath",
            "score": 0.0076570328958121,
            "normalized_score": 0.0076570328958121,
            "date": "2024-12-26"
          }
        ],
        "2025": [
          {
            "model": "Kimi-K2-Instruct",
            "org": "Moonshot",
            "benchmark": "frontiermath",
            "score": 0.0083731308075254,
            "normalized_score": 0.0083731308075254,
            "date": "2025-07-12"
          },
          {
            "model": "Kimi-K2-Instruct",
            "org": "Moonshot",
            "benchmark": "frontiermath_tier_4",
            "score": 0.0,
            "normalized_score": 0.0,
            "date": "2025-07-12"
          }
        ]
      }
    },
    "abstract_reasoning": {
      "name": "Abstract Reasoning",
      "category": "reasoning",
      "x": 0.75,
      "y": 0.35,
      "description": "Recognize patterns and solve problems requiring high-level conceptual thinking",
      "benchmarks": [
        "arc_agi"
      ],
      "heights": {
        "2025": 0.212,
        "2019": 0.156,
        "2020": 0.164,
        "2021": 0.173,
        "2022": 0.182,
        "2023": 0.191,
        "2024": 0.201
      },
      "top_models": {
        "2025": [
          {
            "model": "DeepSeek-R1-0528",
            "org": "DeepSeek",
            "benchmark": "arc_agi",
            "score": 0.212,
            "normalized_score": 0.212,
            "date": "2025-05-28"
          }
        ]
      }
    },
    "basic_tasks": {
      "name": "Basic Tasks",
      "category": "reasoning",
      "x": 0.4,
      "y": 0.4,
      "description": "Perform fundamental operations and simple problem-solving",
      "benchmarks": [
        "simplebench"
      ],
      "heights": {
        "2024": 0.189,
        "2025": 0.408,
        "2019": 0.146,
        "2020": 0.154,
        "2021": 0.162,
        "2022": 0.171,
        "2023": 0.18
      },
      "top_models": {
        "2024": [
          {
            "model": "DeepSeek-V3",
            "org": "DeepSeek",
            "benchmark": "simplebench",
            "score": 0.189,
            "normalized_score": 0.189,
            "date": "2024-12-26"
          }
        ],
        "2025": [
          {
            "model": "DeepSeek-R1-0528",
            "org": "DeepSeek",
            "benchmark": "simplebench",
            "score": 0.408,
            "normalized_score": 0.408,
            "date": "2025-05-28"
          }
        ]
      }
    },
    "general_knowledge": {
      "name": "General Knowledge",
      "category": "knowledge",
      "x": 0.25,
      "y": 0.6,
      "description": "Answer questions across diverse academic and cultural domains",
      "benchmarks": [
        "mmlu"
      ],
      "heights": {
        "2023": 0.763,
        "2024": 0.872,
        "2025": 0.799,
        "2019": 0.621,
        "2020": 0.654,
        "2021": 0.689,
        "2022": 0.725
      },
      "top_models": {
        "2023": [
          {
            "model": "Yi-34B",
            "org": "01.AI",
            "benchmark": "mmlu",
            "score": 0.763,
            "normalized_score": 0.763,
            "date": "2023-11-02"
          }
        ],
        "2024": [
          {
            "model": "DeepSeek-V3",
            "org": "DeepSeek",
            "benchmark": "mmlu",
            "score": 0.872,
            "normalized_score": 0.872,
            "date": "2024-12-26"
          }
        ],
        "2025": [
          {
            "model": "qwen2.5-14b-instruct",
            "org": "Alibaba",
            "benchmark": "mmlu",
            "score": 0.799,
            "normalized_score": 0.799,
            "date": "2025-02-26"
          }
        ]
      }
    },
    "os_interaction": {
      "name": "Os Interaction",
      "category": "agents",
      "x": 0.6,
      "y": 0.8,
      "description": "Navigate and manipulate operating system interfaces",
      "benchmarks": [
        "os_universe"
      ],
      "heights": {
        "2024": 0.186,
        "2019": 0.144,
        "2020": 0.151,
        "2021": 0.159,
        "2022": 0.168,
        "2023": 0.177,
        "2025": 0.192
      },
      "top_models": {
        "2024": [
          {
            "model": "Qwen2.5-VL-72B-Instruct",
            "org": "Alibaba",
            "benchmark": "os_universe",
            "score": 0.1864,
            "normalized_score": 0.1864,
            "date": "2024-09-19"
          }
        ]
      }
    },
    "factual_knowledge": {
      "name": "Factual Knowledge",
      "category": "knowledge",
      "x": 0.2,
      "y": 0.55,
      "description": "Retrieve and apply specific facts across domains",
      "benchmarks": [
        "trivia_qa"
      ],
      "heights": {
        "2024": 0.829,
        "2019": 0.641,
        "2020": 0.675,
        "2021": 0.711,
        "2022": 0.748,
        "2023": 0.788,
        "2025": 0.854
      },
      "top_models": {
        "2024": [
          {
            "model": "DeepSeek-V3",
            "org": "DeepSeek",
            "benchmark": "trivia_qa",
            "score": 0.829,
            "normalized_score": 0.829,
            "date": "2024-12-26"
          }
        ]
      }
    },
    "unusual_tasks": {
      "name": "Unusual Tasks",
      "category": "reasoning",
      "x": 0.5,
      "y": 0.3,
      "description": "Handle novel or atypical challenges outside standard benchmarks",
      "benchmarks": [
        "weirdml"
      ],
      "heights": {
        "2024": 0.374,
        "2025": 0.514,
        "2019": 0.289,
        "2020": 0.305,
        "2021": 0.321,
        "2022": 0.338,
        "2023": 0.355
      },
      "top_models": {
        "2024": [
          {
            "model": "DeepSeek-V3",
            "org": "DeepSeek",
            "benchmark": "weirdml",
            "score": 0.3737,
            "normalized_score": 0.3737,
            "date": "2024-12-26"
          }
        ],
        "2025": [
          {
            "model": "DeepSeek-R1",
            "org": "DeepSeek",
            "benchmark": "weirdml",
            "score": 0.5144,
            "normalized_score": 0.5144,
            "date": "2025-01-20"
          }
        ]
      }
    },
    "geographic_knowledge": {
      "name": "Geographic Knowledge",
      "category": "knowledge",
      "x": 0.25,
      "y": 0.5,
      "description": "Understand spatial relationships, locations, and geographic data",
      "benchmarks": [
        "geobench"
      ],
      "heights": {
        "2024": 34.48,
        "2019": 26.68,
        "2020": 28.084,
        "2021": 29.562,
        "2022": 31.118,
        "2023": 32.756,
        "2025": 1.0
      },
      "top_models": {
        "2024": [
          {
            "model": "Qwen2.5-VL-72B-Instruct",
            "org": "Alibaba",
            "benchmark": "geobench",
            "score": 3448.0,
            "normalized_score": 34.48,
            "date": "2024-09-19"
          }
        ]
      }
    },
    "complex_reasoning": {
      "name": "Complex Reasoning",
      "category": "reasoning",
      "x": 0.65,
      "y": 0.45,
      "description": "Navigate multi-layered logical problems requiring synthesis",
      "benchmarks": [
        "bbh"
      ],
      "heights": {
        "2023": 0.717,
        "2024": 0.875,
        "2019": 0.584,
        "2020": 0.615,
        "2021": 0.647,
        "2022": 0.681,
        "2025": 0.901
      },
      "top_models": {
        "2023": [
          {
            "model": "Yi-34B-Chat",
            "org": "01.AI",
            "benchmark": "bbh",
            "score": 0.717,
            "normalized_score": 0.717,
            "date": "2023-11-22"
          }
        ],
        "2024": [
          {
            "model": "DeepSeek-V3",
            "org": "DeepSeek",
            "benchmark": "bbh",
            "score": 0.875,
            "normalized_score": 0.875,
            "date": "2024-12-26"
          }
        ]
      }
    },
    "spatial_reasoning": {
      "name": "Spatial Reasoning",
      "category": "games",
      "x": 0.55,
      "y": 0.25,
      "description": "Understand and manipulate objects in 2D and 3D space",
      "benchmarks": [
        "gso"
      ],
      "heights": {
        "2025": 0.049,
        "2019": 0.036,
        "2020": 0.038,
        "2021": 0.04,
        "2022": 0.042,
        "2023": 0.044,
        "2024": 0.047
      },
      "top_models": {
        "2025": [
          {
            "model": "Kimi-K2-Instruct",
            "org": "Moonshot",
            "benchmark": "gso",
            "score": 0.049,
            "normalized_score": 0.049,
            "date": "2025-07-12"
          },
          {
            "model": "Qwen3-Coder-480B-A35B-Instruct",
            "org": "Alibaba",
            "benchmark": "gso",
            "score": 0.049,
            "normalized_score": 0.049,
            "date": "2025-07-31"
          }
        ]
      }
    },
    "cybersecurity": {
      "name": "Cybersecurity",
      "category": "reasoning",
      "x": 0.7,
      "y": 0.2,
      "description": "Identify vulnerabilities and solve security-related challenges",
      "benchmarks": [
        "cybench"
      ],
      "heights": {},
      "top_models": {}
    },
    "language_understanding": {
      "name": "Language Understanding",
      "category": "language",
      "x": 0.4,
      "y": 0.65,
      "description": "Comprehend meaning, context, and nuance in text",
      "benchmarks": [
        "superglue"
      ],
      "heights": {},
      "top_models": {}
    },
    "os_navigation": {
      "name": "Os Navigation",
      "category": "agents",
      "x": 0.55,
      "y": 0.85,
      "description": "Find and access files and programs within operating systems",
      "benchmarks": [
        "os_world"
      ],
      "heights": {
        "2024": 0.088,
        "2019": 0.068,
        "2020": 0.072,
        "2021": 0.075,
        "2022": 0.079,
        "2023": 0.084,
        "2025": 0.091
      },
      "top_models": {
        "2024": [
          {
            "model": "Qwen2.5-VL-72B-Instruct",
            "org": "Alibaba",
            "benchmark": "os_world",
            "score": 8.8,
            "normalized_score": 0.08800000000000001,
            "date": "2024-09-19"
          }
        ]
      }
    },
    "natural_language_inference": {
      "name": "Natural Language Inference",
      "category": "language",
      "x": 0.35,
      "y": 0.6,
      "description": "Determine logical relationships between text passages",
      "benchmarks": [
        "adversarial_nli"
      ],
      "heights": {},
      "top_models": {}
    },
    "agent_reasoning": {
      "name": "Agent Reasoning",
      "category": "agents",
      "x": 0.5,
      "y": 0.8,
      "description": "Plan and execute multi-step tasks autonomously",
      "benchmarks": [
        "the_agent_company"
      ],
      "heights": {
        "2024": 0.118,
        "2019": 0.091,
        "2020": 0.096,
        "2021": 0.101,
        "2022": 0.106,
        "2023": 0.112,
        "2025": 0.122
      },
      "top_models": {
        "2024": [
          {
            "model": "qwen2.5-72b-instruct",
            "org": "Alibaba",
            "benchmark": "the_agent_company",
            "score": 0.118,
            "normalized_score": 0.118,
            "date": "2024-09-19"
          }
        ]
      }
    },
    "boolean_reasoning": {
      "name": "Boolean Reasoning",
      "category": "reasoning",
      "x": 0.4,
      "y": 0.5,
      "description": "Answer yes/no questions requiring logical deduction",
      "benchmarks": [
        "bool_q"
      ],
      "heights": {
        "2023": 0.862,
        "2019": 0.702,
        "2020": 0.739,
        "2021": 0.778,
        "2022": 0.819,
        "2024": 0.888,
        "2025": 0.914
      },
      "top_models": {
        "2023": [
          {
            "model": "Qwen-14B",
            "org": "Alibaba",
            "benchmark": "bool_q",
            "score": 0.862,
            "normalized_score": 0.862,
            "date": "2023-09-28"
          }
        ]
      }
    },
    "language_modeling": {
      "name": "Language Modeling",
      "category": "language",
      "x": 0.3,
      "y": 0.7,
      "description": "Predict and generate coherent natural language sequences",
      "benchmarks": [
        "lambada"
      ],
      "heights": {
        "2023": 0.74,
        "2019": 0.603,
        "2020": 0.634,
        "2021": 0.668,
        "2022": 0.703,
        "2024": 0.762,
        "2025": 0.785
      },
      "top_models": {
        "2023": [
          {
            "model": "Baichuan-2-13B-Base",
            "org": "Baichuan",
            "benchmark": "lambada",
            "score": 0.74,
            "normalized_score": 0.74,
            "date": "2023-09-06"
          }
        ]
      }
    },
    "terminal_usage": {
      "name": "Terminal Usage",
      "category": "agents",
      "x": 0.45,
      "y": 0.85,
      "description": "Execute commands and navigate command-line interfaces",
      "benchmarks": [
        "terminalbench"
      ],
      "heights": {
        "2025": 0.399,
        "2019": 0.293,
        "2020": 0.309,
        "2021": 0.325,
        "2022": 0.342,
        "2023": 0.36,
        "2024": 0.379
      },
      "top_models": {
        "2025": [
          {
            "model": "glm-4.5",
            "org": "Zhipu AI,Tsinghua University",
            "benchmark": "terminalbench",
            "score": 0.399,
            "normalized_score": 0.399,
            "date": "2025-08-03"
          }
        ]
      }
    }
  },
  "microsoft": {
    "code_generation": {
      "name": "Code Generation",
      "category": "coding",
      "x": 0.65,
      "y": 0.5,
      "description": "Generate functional code from natural language descriptions",
      "benchmarks": [
        "aider_polyglot",
        "swe_bench_verified",
        "live_bench"
      ],
      "heights": {
        "2024": 0.416,
        "2019": 0.322,
        "2020": 0.339,
        "2021": 0.357,
        "2022": 0.375,
        "2023": 0.395,
        "2025": 0.428
      },
      "top_models": {
        "2024": [
          {
            "model": "phi-4",
            "org": "Microsoft Research",
            "benchmark": "live_bench",
            "score": 41.61,
            "normalized_score": 0.41609999999999997,
            "date": "2024-12-12"
          }
        ]
      }
    },
    "physical_intuition": {
      "name": "Physical Intuition",
      "category": "reasoning",
      "x": 0.5,
      "y": 0.5,
      "description": "Apply understanding of physical laws and object behavior",
      "benchmarks": [
        "piqa"
      ],
      "heights": {
        "2022": 0.832,
        "2024": 0.886,
        "2023": 0.859,
        "2019": 0.713,
        "2020": 0.751,
        "2021": 0.79,
        "2025": 0.913
      },
      "top_models": {
        "2022": [
          {
            "model": "Megatron-Turing NLG 530B",
            "org": "Microsoft,NVIDIA",
            "benchmark": "piqa",
            "score": 0.8319,
            "normalized_score": 0.8319,
            "date": "2022-01-28"
          }
        ],
        "2024": [
          {
            "model": "Phi-3.5-MoE-instruct",
            "org": "Microsoft",
            "benchmark": "piqa",
            "score": 0.886,
            "normalized_score": 0.886,
            "date": "2024-08-17"
          }
        ]
      }
    },
    "scientific_reasoning": {
      "name": "Scientific Reasoning",
      "category": "knowledge",
      "x": 0.3,
      "y": 0.55,
      "description": "Apply scientific methods and domain knowledge to problems",
      "benchmarks": [
        "science_qa"
      ],
      "heights": {},
      "top_models": {}
    },
    "game_strategy": {
      "name": "Game Strategy",
      "category": "games",
      "x": 0.6,
      "y": 0.2,
      "description": "Develop winning approaches in strategic games",
      "benchmarks": [
        "factorio_learning_environment"
      ],
      "heights": {},
      "top_models": {}
    },
    "commonsense_reasoning": {
      "name": "Commonsense Reasoning",
      "category": "reasoning",
      "x": 0.45,
      "y": 0.55,
      "description": "Apply everyday knowledge and intuitive logic",
      "benchmarks": [
        "common_sense_qa_2",
        "wino_grande",
        "arc_ai2",
        "hella_swag"
      ],
      "heights": {
        "2022": 0.806,
        "2023": 0.676,
        "2024": 0.852,
        "2019": 0.691,
        "2020": 0.727,
        "2021": 0.766,
        "2025": 0.878
      },
      "top_models": {
        "2022": [
          {
            "model": "Megatron-Turing NLG 530B",
            "org": "Microsoft,NVIDIA",
            "benchmark": "hella_swag",
            "score": 0.824,
            "normalized_score": 0.824,
            "date": "2022-01-28"
          },
          {
            "model": "Megatron-Turing NLG 530B",
            "org": "Microsoft,NVIDIA",
            "benchmark": "wino_grande",
            "score": 0.789,
            "normalized_score": 0.789,
            "date": "2022-01-28"
          }
        ],
        "2023": [
          {
            "model": "phi-2",
            "org": "Microsoft",
            "benchmark": "arc_ai2",
            "score": 0.759,
            "normalized_score": 0.759,
            "date": "2023-12-12"
          },
          {
            "model": "phi-1_5",
            "org": "Microsoft",
            "benchmark": "wino_grande",
            "score": 0.734,
            "normalized_score": 0.734,
            "date": "2023-09-11"
          },
          {
            "model": "phi-2",
            "org": "Microsoft",
            "benchmark": "hella_swag",
            "score": 0.536,
            "normalized_score": 0.536,
            "date": "2023-12-12"
          }
        ],
        "2024": [
          {
            "model": "Phi-3-medium-128k-instruct",
            "org": "Microsoft",
            "benchmark": "arc_ai2",
            "score": 0.916,
            "normalized_score": 0.916,
            "date": "2024-04-23"
          },
          {
            "model": "Phi-3-medium-128k-instruct",
            "org": "Microsoft",
            "benchmark": "hella_swag",
            "score": 0.824,
            "normalized_score": 0.824,
            "date": "2024-04-23"
          },
          {
            "model": "Phi-3-small-8k-instruct",
            "org": "Microsoft",
            "benchmark": "wino_grande",
            "score": 0.815,
            "normalized_score": 0.815,
            "date": "2024-04-23"
          },
          {
            "model": "Phi-3-medium-128k-instruct",
            "org": "Microsoft",
            "benchmark": "wino_grande",
            "score": 0.815,
            "normalized_score": 0.815,
            "date": "2024-04-23"
          }
        ]
      }
    },
    "reading_comprehension": {
      "name": "Reading Comprehension",
      "category": "language",
      "x": 0.35,
      "y": 0.65,
      "description": "Extract meaning and answer questions from written passages",
      "benchmarks": [
        "open_book_qa"
      ],
      "heights": {
        "2023": 0.736,
        "2024": 0.88,
        "2019": 0.599,
        "2020": 0.631,
        "2021": 0.664,
        "2022": 0.699,
        "2025": 0.906
      },
      "top_models": {
        "2023": [
          {
            "model": "phi-2",
            "org": "Microsoft",
            "benchmark": "open_book_qa",
            "score": 0.736,
            "normalized_score": 0.736,
            "date": "2023-12-12"
          }
        ],
        "2024": [
          {
            "model": "Phi-3-mini-4k-instruct",
            "org": "Microsoft",
            "benchmark": "open_book_qa",
            "score": 0.88,
            "normalized_score": 0.88,
            "date": "2024-04-23"
          },
          {
            "model": "Phi-3-small-8k-instruct",
            "org": "Microsoft",
            "benchmark": "open_book_qa",
            "score": 0.88,
            "normalized_score": 0.88,
            "date": "2024-04-23"
          }
        ]
      }
    },
    "game_playing": {
      "name": "Game Playing",
      "category": "games",
      "x": 0.65,
      "y": 0.25,
      "description": "Learn and execute strategies in game environments",
      "benchmarks": [
        "balrog"
      ],
      "heights": {
        "2024": 0.116,
        "2019": 0.09,
        "2020": 0.094,
        "2021": 0.099,
        "2022": 0.105,
        "2023": 0.11,
        "2025": 0.119
      },
      "top_models": {
        "2024": [
          {
            "model": "phi-4",
            "org": "Microsoft Research",
            "benchmark": "balrog",
            "score": 0.116,
            "normalized_score": 0.116,
            "date": "2024-12-12"
          }
        ]
      }
    },
    "creative_writing": {
      "name": "Creative Writing",
      "category": "language",
      "x": 0.2,
      "y": 0.3,
      "description": "Generate original, engaging narrative and expressive text",
      "benchmarks": [
        "fictionlivebench"
      ],
      "heights": {},
      "top_models": {}
    },
    "competition_math": {
      "name": "Competition Math",
      "category": "mathematics",
      "x": 0.85,
      "y": 0.45,
      "description": "Solve competition-level mathematics problems (AMC, AIME, IMO)",
      "benchmarks": [
        "otis_mock_aime_2024_2025"
      ],
      "heights": {
        "2024": 0.037,
        "2019": 0.029,
        "2020": 0.03,
        "2021": 0.032,
        "2022": 0.033,
        "2023": 0.035,
        "2025": 0.038
      },
      "top_models": {
        "2024": [
          {
            "model": "phi-4",
            "org": "Microsoft Research",
            "benchmark": "otis_mock_aime_2024_2025",
            "score": 0.0369808338292563,
            "normalized_score": 0.0369808338292563,
            "date": "2024-12-12"
          }
        ]
      }
    },
    "advanced_reasoning": {
      "name": "Advanced Reasoning",
      "category": "reasoning",
      "x": 0.7,
      "y": 0.4,
      "description": "Handle complex multi-step reasoning across diverse domains",
      "benchmarks": [
        "gpqa_diamond"
      ],
      "heights": {
        "2024": 0.026,
        "2019": 0.02,
        "2020": 0.021,
        "2021": 0.022,
        "2022": 0.023,
        "2023": 0.025,
        "2025": 0.027
      },
      "top_models": {
        "2024": [
          {
            "model": "phi-4",
            "org": "Microsoft Research",
            "benchmark": "gpqa_diamond",
            "score": 0.0259027466413267,
            "normalized_score": 0.0259027466413267,
            "date": "2024-12-12"
          }
        ]
      }
    },
    "mathematical_reasoning": {
      "name": "Mathematical Reasoning",
      "category": "mathematics",
      "x": 0.75,
      "y": 0.45,
      "description": "Solve math problems with step-by-step logical reasoning",
      "benchmarks": [
        "math_level_5",
        "gsm8k"
      ],
      "heights": {
        "2024": 0.449,
        "2019": 0.347,
        "2020": 0.366,
        "2021": 0.385,
        "2022": 0.405,
        "2023": 0.427,
        "2025": 0.462
      },
      "top_models": {
        "2024": [
          {
            "model": "Phi-3.5-MoE-instruct",
            "org": "Microsoft",
            "benchmark": "gsm8k",
            "score": 0.887,
            "normalized_score": 0.887,
            "date": "2024-08-17"
          },
          {
            "model": "phi-4",
            "org": "Microsoft Research",
            "benchmark": "math_level_5",
            "score": 0.0106568713840848,
            "normalized_score": 0.0106568713840848,
            "date": "2024-12-12"
          }
        ]
      }
    },
    "long_horizon_planning": {
      "name": "Long Horizon Planning",
      "category": "reasoning",
      "x": 0.55,
      "y": 0.75,
      "description": "Plan and reason about extended sequences of actions",
      "benchmarks": [
        "metr_time_horizons"
      ],
      "heights": {},
      "top_models": {}
    },
    "writing_quality": {
      "name": "Writing Quality",
      "category": "language",
      "x": 0.25,
      "y": 0.35,
      "description": "Produce well-structured, grammatically correct, compelling text",
      "benchmarks": [
        "lech_mazur_writing"
      ],
      "heights": {
        "2024": 0.063,
        "2019": 0.049,
        "2020": 0.051,
        "2021": 0.054,
        "2022": 0.057,
        "2023": 0.06,
        "2025": 0.065
      },
      "top_models": {
        "2024": [
          {
            "model": "phi-4",
            "org": "Microsoft Research",
            "benchmark": "lech_mazur_writing",
            "score": 6.26,
            "normalized_score": 0.0626,
            "date": "2024-12-12"
          }
        ]
      }
    },
    "cad_design": {
      "name": "Cad Design",
      "category": "reasoning",
      "x": 0.75,
      "y": 0.25,
      "description": "Create and manipulate computer-aided design models",
      "benchmarks": [
        "cad_eval"
      ],
      "heights": {},
      "top_models": {}
    },
    "advanced_mathematics": {
      "name": "Advanced Mathematics",
      "category": "mathematics",
      "x": 0.8,
      "y": 0.4,
      "description": "Solve graduate-level and research mathematics problems",
      "benchmarks": [
        "frontiermath",
        "frontiermath_tier_4"
      ],
      "heights": {},
      "top_models": {}
    },
    "abstract_reasoning": {
      "name": "Abstract Reasoning",
      "category": "reasoning",
      "x": 0.75,
      "y": 0.35,
      "description": "Recognize patterns and solve problems requiring high-level conceptual thinking",
      "benchmarks": [
        "arc_agi"
      ],
      "heights": {},
      "top_models": {}
    },
    "basic_tasks": {
      "name": "Basic Tasks",
      "category": "reasoning",
      "x": 0.4,
      "y": 0.4,
      "description": "Perform fundamental operations and simple problem-solving",
      "benchmarks": [
        "simplebench"
      ],
      "heights": {},
      "top_models": {}
    },
    "general_knowledge": {
      "name": "General Knowledge",
      "category": "knowledge",
      "x": 0.25,
      "y": 0.6,
      "description": "Answer questions across diverse academic and cultural domains",
      "benchmarks": [
        "mmlu"
      ],
      "heights": {
        "2023": 0.584,
        "2024": 0.848,
        "2019": 0.476,
        "2020": 0.501,
        "2021": 0.527,
        "2022": 0.555,
        "2025": 0.873
      },
      "top_models": {
        "2023": [
          {
            "model": "phi-2",
            "org": "Microsoft",
            "benchmark": "mmlu",
            "score": 0.584,
            "normalized_score": 0.584,
            "date": "2023-12-12"
          }
        ],
        "2024": [
          {
            "model": "phi-4",
            "org": "Microsoft Research",
            "benchmark": "mmlu",
            "score": 0.848,
            "normalized_score": 0.848,
            "date": "2024-12-12"
          }
        ]
      }
    },
    "os_interaction": {
      "name": "Os Interaction",
      "category": "agents",
      "x": 0.6,
      "y": 0.8,
      "description": "Navigate and manipulate operating system interfaces",
      "benchmarks": [
        "os_universe"
      ],
      "heights": {},
      "top_models": {}
    },
    "factual_knowledge": {
      "name": "Factual Knowledge",
      "category": "knowledge",
      "x": 0.2,
      "y": 0.55,
      "description": "Retrieve and apply specific facts across domains",
      "benchmarks": [
        "trivia_qa"
      ],
      "heights": {
        "2023": 0.452,
        "2024": 0.739,
        "2019": 0.368,
        "2020": 0.388,
        "2021": 0.408,
        "2022": 0.429,
        "2025": 0.761
      },
      "top_models": {
        "2023": [
          {
            "model": "phi-2",
            "org": "Microsoft",
            "benchmark": "trivia_qa",
            "score": 0.452,
            "normalized_score": 0.452,
            "date": "2023-12-12"
          }
        ],
        "2024": [
          {
            "model": "Phi-3-medium-128k-instruct",
            "org": "Microsoft",
            "benchmark": "trivia_qa",
            "score": 0.739,
            "normalized_score": 0.739,
            "date": "2024-04-23"
          }
        ]
      }
    },
    "unusual_tasks": {
      "name": "Unusual Tasks",
      "category": "reasoning",
      "x": 0.5,
      "y": 0.3,
      "description": "Handle novel or atypical challenges outside standard benchmarks",
      "benchmarks": [
        "weirdml"
      ],
      "heights": {
        "2025": 0.132,
        "2019": 0.097,
        "2020": 0.102,
        "2021": 0.108,
        "2022": 0.113,
        "2023": 0.119,
        "2024": 0.125
      },
      "top_models": {
        "2025": [
          {
            "model": "phi4:14b-q8_0",
            "org": "Microsoft Research",
            "benchmark": "weirdml",
            "score": 0.1316,
            "normalized_score": 0.1316,
            "date": "2025-02-26"
          }
        ]
      }
    },
    "geographic_knowledge": {
      "name": "Geographic Knowledge",
      "category": "knowledge",
      "x": 0.25,
      "y": 0.5,
      "description": "Understand spatial relationships, locations, and geographic data",
      "benchmarks": [
        "geobench"
      ],
      "heights": {},
      "top_models": {}
    },
    "complex_reasoning": {
      "name": "Complex Reasoning",
      "category": "reasoning",
      "x": 0.65,
      "y": 0.45,
      "description": "Navigate multi-layered logical problems requiring synthesis",
      "benchmarks": [
        "bbh"
      ],
      "heights": {
        "2023": 0.594,
        "2024": 0.814,
        "2019": 0.484,
        "2020": 0.509,
        "2021": 0.536,
        "2022": 0.564,
        "2025": 0.838
      },
      "top_models": {
        "2023": [
          {
            "model": "phi-2",
            "org": "Microsoft",
            "benchmark": "bbh",
            "score": 0.594,
            "normalized_score": 0.594,
            "date": "2023-12-12"
          }
        ],
        "2024": [
          {
            "model": "Phi-3-medium-128k-instruct",
            "org": "Microsoft",
            "benchmark": "bbh",
            "score": 0.814,
            "normalized_score": 0.814,
            "date": "2024-04-23"
          }
        ]
      }
    },
    "spatial_reasoning": {
      "name": "Spatial Reasoning",
      "category": "games",
      "x": 0.55,
      "y": 0.25,
      "description": "Understand and manipulate objects in 2D and 3D space",
      "benchmarks": [
        "gso"
      ],
      "heights": {},
      "top_models": {}
    },
    "cybersecurity": {
      "name": "Cybersecurity",
      "category": "reasoning",
      "x": 0.7,
      "y": 0.2,
      "description": "Identify vulnerabilities and solve security-related challenges",
      "benchmarks": [
        "cybench"
      ],
      "heights": {},
      "top_models": {}
    },
    "language_understanding": {
      "name": "Language Understanding",
      "category": "language",
      "x": 0.4,
      "y": 0.65,
      "description": "Comprehend meaning, context, and nuance in text",
      "benchmarks": [
        "superglue"
      ],
      "heights": {},
      "top_models": {}
    },
    "os_navigation": {
      "name": "Os Navigation",
      "category": "agents",
      "x": 0.55,
      "y": 0.85,
      "description": "Find and access files and programs within operating systems",
      "benchmarks": [
        "os_world"
      ],
      "heights": {},
      "top_models": {}
    },
    "natural_language_inference": {
      "name": "Natural Language Inference",
      "category": "language",
      "x": 0.35,
      "y": 0.6,
      "description": "Determine logical relationships between text passages",
      "benchmarks": [
        "adversarial_nli"
      ],
      "heights": {
        "2022": 0.397,
        "2023": 0.425,
        "2024": 0.581,
        "2019": 0.34,
        "2020": 0.358,
        "2021": 0.377,
        "2025": 0.598
      },
      "top_models": {
        "2022": [
          {
            "model": "Megatron-Turing NLG 530B",
            "org": "Microsoft,NVIDIA",
            "benchmark": "adversarial_nli",
            "score": 0.397,
            "normalized_score": 0.397,
            "date": "2022-01-28"
          }
        ],
        "2023": [
          {
            "model": "phi-2",
            "org": "Microsoft",
            "benchmark": "adversarial_nli",
            "score": 0.425,
            "normalized_score": 0.425,
            "date": "2023-12-12"
          }
        ],
        "2024": [
          {
            "model": "Phi-3-small-8k-instruct",
            "org": "Microsoft",
            "benchmark": "adversarial_nli",
            "score": 0.581,
            "normalized_score": 0.581,
            "date": "2024-04-23"
          }
        ]
      }
    },
    "agent_reasoning": {
      "name": "Agent Reasoning",
      "category": "agents",
      "x": 0.5,
      "y": 0.8,
      "description": "Plan and execute multi-step tasks autonomously",
      "benchmarks": [
        "the_agent_company"
      ],
      "heights": {},
      "top_models": {}
    },
    "boolean_reasoning": {
      "name": "Boolean Reasoning",
      "category": "reasoning",
      "x": 0.4,
      "y": 0.5,
      "description": "Answer yes/no questions requiring logical deduction",
      "benchmarks": [
        "bool_q"
      ],
      "heights": {
        "2022": 0.848,
        "2023": 0.758,
        "2024": 0.846,
        "2019": 0.727,
        "2020": 0.765,
        "2021": 0.806,
        "2025": 0.871
      },
      "top_models": {
        "2022": [
          {
            "model": "Megatron-Turing NLG 530B",
            "org": "Microsoft,NVIDIA",
            "benchmark": "bool_q",
            "score": 0.8483,
            "normalized_score": 0.8483,
            "date": "2022-01-28"
          }
        ],
        "2023": [
          {
            "model": "phi-1_5",
            "org": "Microsoft",
            "benchmark": "bool_q",
            "score": 0.758,
            "normalized_score": 0.758,
            "date": "2023-09-11"
          }
        ],
        "2024": [
          {
            "model": "Phi-3.5-MoE-instruct",
            "org": "Microsoft",
            "benchmark": "bool_q",
            "score": 0.846,
            "normalized_score": 0.846,
            "date": "2024-08-17"
          }
        ]
      }
    },
    "language_modeling": {
      "name": "Language Modeling",
      "category": "language",
      "x": 0.3,
      "y": 0.7,
      "description": "Predict and generate coherent natural language sequences",
      "benchmarks": [
        "lambada"
      ],
      "heights": {
        "2022": 0.872,
        "2019": 0.748,
        "2020": 0.787,
        "2021": 0.828,
        "2023": 0.898,
        "2024": 0.925,
        "2025": 0.953
      },
      "top_models": {
        "2022": [
          {
            "model": "Megatron-Turing NLG 530B",
            "org": "Microsoft,NVIDIA",
            "benchmark": "lambada",
            "score": 0.8715,
            "normalized_score": 0.8715,
            "date": "2022-01-28"
          }
        ]
      }
    },
    "terminal_usage": {
      "name": "Terminal Usage",
      "category": "agents",
      "x": 0.45,
      "y": 0.85,
      "description": "Execute commands and navigate command-line interfaces",
      "benchmarks": [
        "terminalbench"
      ],
      "heights": {},
      "top_models": {}
    }
  },
  "startups": {
    "code_generation": {
      "name": "Code Generation",
      "category": "coding",
      "x": 0.65,
      "y": 0.5,
      "description": "Generate functional code from natural language descriptions",
      "benchmarks": [
        "aider_polyglot",
        "swe_bench_verified",
        "live_bench"
      ],
      "heights": {
        "2024": 0.543,
        "2025": 0.409,
        "2019": 0.42,
        "2020": 0.442,
        "2021": 0.466,
        "2022": 0.49,
        "2023": 0.516
      },
      "top_models": {
        "2024": [
          {
            "model": "grok-2-1212",
            "org": "xAI",
            "benchmark": "live_bench",
            "score": 54.3,
            "normalized_score": 0.5429999999999999,
            "date": "2024-12-12"
          }
        ],
        "2025": [
          {
            "model": "grok-4-0709",
            "org": "xAI",
            "benchmark": "aider_polyglot",
            "score": 79.6,
            "normalized_score": 0.7959999999999999,
            "date": "2025-07-09"
          },
          {
            "model": "grok-3-beta",
            "org": "xAI",
            "benchmark": "swe_bench_verified",
            "score": 0.0217935292192811,
            "normalized_score": 0.0217935292192811,
            "date": "2025-04-09"
          }
        ]
      }
    },
    "physical_intuition": {
      "name": "Physical Intuition",
      "category": "reasoning",
      "x": 0.5,
      "y": 0.5,
      "description": "Apply understanding of physical laws and object behavior",
      "benchmarks": [
        "piqa"
      ],
      "heights": {
        "2023": 0.842,
        "2019": 0.686,
        "2020": 0.722,
        "2021": 0.76,
        "2022": 0.8,
        "2024": 0.867,
        "2025": 0.893
      },
      "top_models": {
        "2023": [
          {
            "model": "Inflection-1",
            "org": "Inflection AI",
            "benchmark": "piqa",
            "score": 0.842,
            "normalized_score": 0.842,
            "date": "2023-06-22"
          }
        ]
      }
    },
    "scientific_reasoning": {
      "name": "Scientific Reasoning",
      "category": "knowledge",
      "x": 0.3,
      "y": 0.55,
      "description": "Apply scientific methods and domain knowledge to problems",
      "benchmarks": [
        "science_qa"
      ],
      "heights": {},
      "top_models": {}
    },
    "game_strategy": {
      "name": "Game Strategy",
      "category": "games",
      "x": 0.6,
      "y": 0.2,
      "description": "Develop winning approaches in strategic games",
      "benchmarks": [
        "factorio_learning_environment"
      ],
      "heights": {},
      "top_models": {}
    },
    "commonsense_reasoning": {
      "name": "Commonsense Reasoning",
      "category": "reasoning",
      "x": 0.45,
      "y": 0.55,
      "description": "Apply everyday knowledge and intuitive logic",
      "benchmarks": [
        "common_sense_qa_2",
        "wino_grande",
        "arc_ai2",
        "hella_swag"
      ],
      "heights": {},
      "top_models": {}
    },
    "reading_comprehension": {
      "name": "Reading Comprehension",
      "category": "language",
      "x": 0.35,
      "y": 0.65,
      "description": "Extract meaning and answer questions from written passages",
      "benchmarks": [
        "open_book_qa"
      ],
      "heights": {},
      "top_models": {}
    },
    "game_playing": {
      "name": "Game Playing",
      "category": "games",
      "x": 0.65,
      "y": 0.25,
      "description": "Learn and execute strategies in game environments",
      "benchmarks": [
        "balrog"
      ],
      "heights": {
        "2025": 0.436,
        "2019": 0.321,
        "2020": 0.337,
        "2021": 0.355,
        "2022": 0.374,
        "2023": 0.393,
        "2024": 0.414
      },
      "top_models": {
        "2025": [
          {
            "model": "grok-4-0709",
            "org": "xAI",
            "benchmark": "balrog",
            "score": 0.436,
            "normalized_score": 0.436,
            "date": "2025-07-09"
          }
        ]
      }
    },
    "creative_writing": {
      "name": "Creative Writing",
      "category": "language",
      "x": 0.2,
      "y": 0.3,
      "description": "Generate original, engaging narrative and expressive text",
      "benchmarks": [
        "fictionlivebench"
      ],
      "heights": {
        "2025": 0.969,
        "2019": 0.712,
        "2020": 0.75,
        "2021": 0.789,
        "2022": 0.831,
        "2023": 0.875,
        "2024": 0.921
      },
      "top_models": {
        "2025": [
          {
            "model": "grok-4-0709",
            "org": "xAI",
            "benchmark": "fictionlivebench",
            "score": 0.969,
            "normalized_score": 0.969,
            "date": "2025-07-09"
          }
        ]
      }
    },
    "competition_math": {
      "name": "Competition Math",
      "category": "mathematics",
      "x": 0.85,
      "y": 0.45,
      "description": "Solve competition-level mathematics problems (AMC, AIME, IMO)",
      "benchmarks": [
        "otis_mock_aime_2024_2025"
      ],
      "heights": {
        "2024": 0.034,
        "2025": 0.075,
        "2019": 0.026,
        "2020": 0.028,
        "2021": 0.029,
        "2022": 0.031,
        "2023": 0.032
      },
      "top_models": {
        "2024": [
          {
            "model": "grok-2-1212",
            "org": "xAI",
            "benchmark": "otis_mock_aime_2024_2025",
            "score": 0.0338242470093031,
            "normalized_score": 0.0338242470093031,
            "date": "2024-12-12"
          }
        ],
        "2025": [
          {
            "model": "grok-3-beta",
            "org": "xAI",
            "benchmark": "otis_mock_aime_2024_2025",
            "score": 0.0749110958292491,
            "normalized_score": 0.0749110958292491,
            "date": "2025-04-09"
          }
        ]
      }
    },
    "advanced_reasoning": {
      "name": "Advanced Reasoning",
      "category": "reasoning",
      "x": 0.7,
      "y": 0.4,
      "description": "Handle complex multi-step reasoning across diverse domains",
      "benchmarks": [
        "gpqa_diamond"
      ],
      "heights": {
        "2024": 0.027,
        "2025": 0.03,
        "2019": 0.021,
        "2020": 0.022,
        "2021": 0.023,
        "2022": 0.024,
        "2023": 0.026
      },
      "top_models": {
        "2024": [
          {
            "model": "grok-2-1212",
            "org": "xAI",
            "benchmark": "gpqa_diamond",
            "score": 0.0270663423166071,
            "normalized_score": 0.0270663423166071,
            "date": "2024-12-12"
          }
        ],
        "2025": [
          {
            "model": "grok-3-mini-beta_low",
            "org": "xAI",
            "benchmark": "gpqa_diamond",
            "score": 0.0303137105381989,
            "normalized_score": 0.0303137105381989,
            "date": "2025-04-09"
          }
        ]
      }
    },
    "mathematical_reasoning": {
      "name": "Mathematical Reasoning",
      "category": "mathematics",
      "x": 0.75,
      "y": 0.45,
      "description": "Solve math problems with step-by-step logical reasoning",
      "benchmarks": [
        "math_level_5",
        "gsm8k"
      ],
      "heights": {
        "2024": 0.013,
        "2025": 0.009,
        "2019": 0.01,
        "2020": 0.011,
        "2021": 0.011,
        "2022": 0.012,
        "2023": 0.012
      },
      "top_models": {
        "2024": [
          {
            "model": "grok-2-1212",
            "org": "xAI",
            "benchmark": "math_level_5",
            "score": 0.0132343816959083,
            "normalized_score": 0.0132343816959083,
            "date": "2024-12-12"
          }
        ],
        "2025": [
          {
            "model": "grok-3-mini-beta_high",
            "org": "xAI",
            "benchmark": "math_level_5",
            "score": 0.0089127127854116,
            "normalized_score": 0.0089127127854116,
            "date": "2025-04-09"
          }
        ]
      }
    },
    "long_horizon_planning": {
      "name": "Long Horizon Planning",
      "category": "reasoning",
      "x": 0.55,
      "y": 0.75,
      "description": "Plan and reason about extended sequences of actions",
      "benchmarks": [
        "metr_time_horizons"
      ],
      "heights": {
        "2025": 0.666,
        "2019": 0.49,
        "2020": 0.515,
        "2021": 0.542,
        "2022": 0.571,
        "2023": 0.601,
        "2024": 0.633
      },
      "top_models": {
        "2025": [
          {
            "model": "grok-4-0709",
            "org": "xAI",
            "benchmark": "metr_time_horizons",
            "score": 0.665803,
            "normalized_score": 0.665803,
            "date": "2025-07-09"
          }
        ]
      }
    },
    "writing_quality": {
      "name": "Writing Quality",
      "category": "language",
      "x": 0.25,
      "y": 0.35,
      "description": "Produce well-structured, grammatically correct, compelling text",
      "benchmarks": [
        "lech_mazur_writing"
      ],
      "heights": {
        "2024": 0.064,
        "2025": 0.076,
        "2019": 0.05,
        "2020": 0.052,
        "2021": 0.055,
        "2022": 0.058,
        "2023": 0.061
      },
      "top_models": {
        "2024": [
          {
            "model": "grok-2-1212",
            "org": "xAI",
            "benchmark": "lech_mazur_writing",
            "score": 6.36,
            "normalized_score": 0.0636,
            "date": "2024-12-12"
          }
        ],
        "2025": [
          {
            "model": "grok-3-beta",
            "org": "xAI",
            "benchmark": "lech_mazur_writing",
            "score": 7.64,
            "normalized_score": 0.0764,
            "date": "2025-04-09"
          }
        ]
      }
    },
    "cad_design": {
      "name": "Cad Design",
      "category": "reasoning",
      "x": 0.75,
      "y": 0.25,
      "description": "Create and manipulate computer-aided design models",
      "benchmarks": [
        "cad_eval"
      ],
      "heights": {},
      "top_models": {}
    },
    "advanced_mathematics": {
      "name": "Advanced Mathematics",
      "category": "mathematics",
      "x": 0.8,
      "y": 0.4,
      "description": "Solve graduate-level and research mathematics problems",
      "benchmarks": [
        "frontiermath",
        "frontiermath_tier_4"
      ],
      "heights": {
        "2024": 0.005,
        "2025": 0.02,
        "2019": 0.004,
        "2020": 0.004,
        "2021": 0.004,
        "2022": 0.005,
        "2023": 0.005
      },
      "top_models": {
        "2024": [
          {
            "model": "grok-2-1212",
            "org": "xAI",
            "benchmark": "frontiermath",
            "score": 0.004868154158215,
            "normalized_score": 0.004868154158215,
            "date": "2024-12-12"
          }
        ],
        "2025": [
          {
            "model": "grok-4-0709",
            "org": "xAI",
            "benchmark": "frontiermath_tier_4",
            "score": 0.0208333333333333,
            "normalized_score": 0.0208333333333333,
            "date": "2025-07-09"
          },
          {
            "model": "grok-4-0709",
            "org": "xAI",
            "benchmark": "frontiermath",
            "score": 0.0192,
            "normalized_score": 0.0192,
            "date": "2025-07-09"
          }
        ]
      }
    },
    "abstract_reasoning": {
      "name": "Abstract Reasoning",
      "category": "reasoning",
      "x": 0.75,
      "y": 0.35,
      "description": "Recognize patterns and solve problems requiring high-level conceptual thinking",
      "benchmarks": [
        "arc_agi"
      ],
      "heights": {
        "2025": 0.165,
        "2019": 0.121,
        "2020": 0.128,
        "2021": 0.134,
        "2022": 0.141,
        "2023": 0.149,
        "2024": 0.157
      },
      "top_models": {
        "2025": [
          {
            "model": "grok-3-mini-beta_low",
            "org": "xAI",
            "benchmark": "arc_agi",
            "score": 0.165,
            "normalized_score": 0.165,
            "date": "2025-04-09"
          }
        ]
      }
    },
    "basic_tasks": {
      "name": "Basic Tasks",
      "category": "reasoning",
      "x": 0.4,
      "y": 0.4,
      "description": "Perform fundamental operations and simple problem-solving",
      "benchmarks": [
        "simplebench"
      ],
      "heights": {
        "2024": 0.227,
        "2025": 0.605,
        "2019": 0.176,
        "2020": 0.185,
        "2021": 0.195,
        "2022": 0.205,
        "2023": 0.216
      },
      "top_models": {
        "2024": [
          {
            "model": "grok-2-1212",
            "org": "xAI",
            "benchmark": "simplebench",
            "score": 0.227,
            "normalized_score": 0.227,
            "date": "2024-12-12"
          }
        ],
        "2025": [
          {
            "model": "grok-4-0709",
            "org": "xAI",
            "benchmark": "simplebench",
            "score": 0.605,
            "normalized_score": 0.605,
            "date": "2025-07-09"
          }
        ]
      }
    },
    "general_knowledge": {
      "name": "General Knowledge",
      "category": "knowledge",
      "x": 0.25,
      "y": 0.6,
      "description": "Answer questions across diverse academic and cultural domains",
      "benchmarks": [
        "mmlu"
      ],
      "heights": {
        "2023": 0.727,
        "2024": 0.694,
        "2019": 0.592,
        "2020": 0.623,
        "2021": 0.656,
        "2022": 0.691,
        "2025": 0.715
      },
      "top_models": {
        "2023": [
          {
            "model": "Inflection-1",
            "org": "Inflection AI",
            "benchmark": "mmlu",
            "score": 0.727,
            "normalized_score": 0.727,
            "date": "2023-06-22"
          }
        ],
        "2024": [
          {
            "model": "c4ai-command-r-plus-08-2024",
            "org": "Cohere,Cohere for AI",
            "benchmark": "mmlu",
            "score": 0.694,
            "normalized_score": 0.694,
            "date": "2024-08-30"
          }
        ]
      }
    },
    "os_interaction": {
      "name": "Os Interaction",
      "category": "agents",
      "x": 0.6,
      "y": 0.8,
      "description": "Navigate and manipulate operating system interfaces",
      "benchmarks": [
        "os_universe"
      ],
      "heights": {},
      "top_models": {}
    },
    "factual_knowledge": {
      "name": "Factual Knowledge",
      "category": "knowledge",
      "x": 0.2,
      "y": 0.55,
      "description": "Retrieve and apply specific facts across domains",
      "benchmarks": [
        "trivia_qa"
      ],
      "heights": {},
      "top_models": {}
    },
    "unusual_tasks": {
      "name": "Unusual Tasks",
      "category": "reasoning",
      "x": 0.5,
      "y": 0.3,
      "description": "Handle novel or atypical challenges outside standard benchmarks",
      "benchmarks": [
        "weirdml"
      ],
      "heights": {
        "2024": 0.276,
        "2025": 0.521,
        "2019": 0.214,
        "2020": 0.225,
        "2021": 0.237,
        "2022": 0.249,
        "2023": 0.262
      },
      "top_models": {
        "2024": [
          {
            "model": "grok-2-1212",
            "org": "xAI",
            "benchmark": "weirdml",
            "score": 0.2762,
            "normalized_score": 0.2762,
            "date": "2024-12-12"
          }
        ],
        "2025": [
          {
            "model": "grok-3-beta",
            "org": "xAI",
            "benchmark": "weirdml",
            "score": 0.5208,
            "normalized_score": 0.5208,
            "date": "2025-04-09"
          }
        ]
      }
    },
    "geographic_knowledge": {
      "name": "Geographic Knowledge",
      "category": "knowledge",
      "x": 0.25,
      "y": 0.5,
      "description": "Understand spatial relationships, locations, and geographic data",
      "benchmarks": [
        "geobench"
      ],
      "heights": {
        "2025": 27.19,
        "2019": 19.987,
        "2020": 21.039,
        "2021": 22.146,
        "2022": 23.312,
        "2023": 24.539,
        "2024": 25.831
      },
      "top_models": {
        "2025": [
          {
            "model": "grok-4-0709",
            "org": "xAI",
            "benchmark": "geobench",
            "score": 2719.0,
            "normalized_score": 27.19,
            "date": "2025-07-09"
          }
        ]
      }
    },
    "complex_reasoning": {
      "name": "Complex Reasoning",
      "category": "reasoning",
      "x": 0.65,
      "y": 0.45,
      "description": "Navigate multi-layered logical problems requiring synthesis",
      "benchmarks": [
        "bbh"
      ],
      "heights": {},
      "top_models": {}
    },
    "spatial_reasoning": {
      "name": "Spatial Reasoning",
      "category": "games",
      "x": 0.55,
      "y": 0.25,
      "description": "Understand and manipulate objects in 2D and 3D space",
      "benchmarks": [
        "gso"
      ],
      "heights": {},
      "top_models": {}
    },
    "cybersecurity": {
      "name": "Cybersecurity",
      "category": "reasoning",
      "x": 0.7,
      "y": 0.2,
      "description": "Identify vulnerabilities and solve security-related challenges",
      "benchmarks": [
        "cybench"
      ],
      "heights": {},
      "top_models": {}
    },
    "language_understanding": {
      "name": "Language Understanding",
      "category": "language",
      "x": 0.4,
      "y": 0.65,
      "description": "Comprehend meaning, context, and nuance in text",
      "benchmarks": [
        "superglue"
      ],
      "heights": {},
      "top_models": {}
    },
    "os_navigation": {
      "name": "Os Navigation",
      "category": "agents",
      "x": 0.55,
      "y": 0.85,
      "description": "Find and access files and programs within operating systems",
      "benchmarks": [
        "os_world"
      ],
      "heights": {},
      "top_models": {}
    },
    "natural_language_inference": {
      "name": "Natural Language Inference",
      "category": "language",
      "x": 0.35,
      "y": 0.6,
      "description": "Determine logical relationships between text passages",
      "benchmarks": [
        "adversarial_nli"
      ],
      "heights": {},
      "top_models": {}
    },
    "agent_reasoning": {
      "name": "Agent Reasoning",
      "category": "agents",
      "x": 0.5,
      "y": 0.8,
      "description": "Plan and execute multi-step tasks autonomously",
      "benchmarks": [
        "the_agent_company"
      ],
      "heights": {},
      "top_models": {}
    },
    "boolean_reasoning": {
      "name": "Boolean Reasoning",
      "category": "reasoning",
      "x": 0.4,
      "y": 0.5,
      "description": "Answer yes/no questions requiring logical deduction",
      "benchmarks": [
        "bool_q"
      ],
      "heights": {
        "2023": 0.897,
        "2019": 0.731,
        "2020": 0.769,
        "2021": 0.81,
        "2022": 0.852,
        "2024": 0.924,
        "2025": 0.952
      },
      "top_models": {
        "2023": [
          {
            "model": "Inflection-1",
            "org": "Inflection AI",
            "benchmark": "bool_q",
            "score": 0.897,
            "normalized_score": 0.897,
            "date": "2023-06-22"
          }
        ]
      }
    },
    "language_modeling": {
      "name": "Language Modeling",
      "category": "language",
      "x": 0.3,
      "y": 0.7,
      "description": "Predict and generate coherent natural language sequences",
      "benchmarks": [
        "lambada"
      ],
      "heights": {
        "2023": 0.785,
        "2019": 0.639,
        "2020": 0.673,
        "2021": 0.708,
        "2022": 0.746,
        "2024": 0.809,
        "2025": 0.833
      },
      "top_models": {
        "2023": [
          {
            "model": "Inflection-1",
            "org": "Inflection AI",
            "benchmark": "lambada",
            "score": 0.785,
            "normalized_score": 0.785,
            "date": "2023-06-22"
          }
        ]
      }
    },
    "terminal_usage": {
      "name": "Terminal Usage",
      "category": "agents",
      "x": 0.45,
      "y": 0.85,
      "description": "Execute commands and navigate command-line interfaces",
      "benchmarks": [
        "terminalbench"
      ],
      "heights": {
        "2025": 0.39,
        "2019": 0.287,
        "2020": 0.302,
        "2021": 0.318,
        "2022": 0.334,
        "2023": 0.352,
        "2024": 0.37
      },
      "top_models": {
        "2025": [
          {
            "model": "grok-4-0709",
            "org": "xAI",
            "benchmark": "terminalbench",
            "score": 0.39,
            "normalized_score": 0.39,
            "date": "2025-07-09"
          }
        ]
      }
    }
  },
  "research_open": {
    "code_generation": {
      "name": "Code Generation",
      "category": "coding",
      "x": 0.65,
      "y": 0.5,
      "description": "Generate functional code from natural language descriptions",
      "benchmarks": [
        "aider_polyglot",
        "swe_bench_verified",
        "live_bench"
      ],
      "heights": {
        "2024": 0.221,
        "2019": 0.171,
        "2020": 0.18,
        "2021": 0.189,
        "2022": 0.199,
        "2023": 0.21,
        "2025": 0.228
      },
      "top_models": {
        "2024": [
          {
            "model": "OLMo-2-1124-13B-Instruct",
            "org": "Allen Institute for AI,University of Washington,New York University (NYU)",
            "benchmark": "live_bench",
            "score": 22.12,
            "normalized_score": 0.2212,
            "date": "2024-12-31"
          }
        ]
      }
    },
    "physical_intuition": {
      "name": "Physical Intuition",
      "category": "reasoning",
      "x": 0.5,
      "y": 0.5,
      "description": "Apply understanding of physical laws and object behavior",
      "benchmarks": [
        "piqa"
      ],
      "heights": {
        "2021": 0.754,
        "2022": 0.767,
        "2023": 0.819,
        "2019": 0.68,
        "2020": 0.716,
        "2024": 0.844,
        "2025": 0.869
      },
      "top_models": {
        "2021": [
          {
            "model": "gpt-j-6b",
            "org": "EleutherAI,LAION",
            "benchmark": "piqa",
            "score": 0.754,
            "normalized_score": 0.754,
            "date": "2021-08-05"
          }
        ],
        "2022": [
          {
            "model": "gpt-neox-20b",
            "org": "EleutherAI",
            "benchmark": "piqa",
            "score": 0.767,
            "normalized_score": 0.767,
            "date": "2022-04-07"
          }
        ],
        "2023": [
          {
            "model": "mpt-30b",
            "org": "MosaicML",
            "benchmark": "piqa",
            "score": 0.819,
            "normalized_score": 0.819,
            "date": "2023-06-22"
          }
        ]
      }
    },
    "scientific_reasoning": {
      "name": "Scientific Reasoning",
      "category": "knowledge",
      "x": 0.3,
      "y": 0.55,
      "description": "Apply scientific methods and domain knowledge to problems",
      "benchmarks": [
        "science_qa"
      ],
      "heights": {
        "2023": 0.742,
        "2019": 0.604,
        "2020": 0.636,
        "2021": 0.67,
        "2022": 0.705,
        "2024": 0.764,
        "2025": 0.787
      },
      "top_models": {
        "2023": [
          {
            "model": "blip2-opt-2.7b",
            "org": "Salesforce Research",
            "benchmark": "science_qa",
            "score": 0.7417,
            "normalized_score": 0.7417,
            "date": "2023-02-06"
          }
        ]
      }
    },
    "game_strategy": {
      "name": "Game Strategy",
      "category": "games",
      "x": 0.6,
      "y": 0.2,
      "description": "Develop winning approaches in strategic games",
      "benchmarks": [
        "factorio_learning_environment"
      ],
      "heights": {},
      "top_models": {}
    },
    "commonsense_reasoning": {
      "name": "Commonsense Reasoning",
      "category": "reasoning",
      "x": 0.45,
      "y": 0.55,
      "description": "Apply everyday knowledge and intuitive logic",
      "benchmarks": [
        "common_sense_qa_2",
        "wino_grande",
        "arc_ai2",
        "hella_swag"
      ],
      "heights": {
        "2021": 0.557,
        "2022": 0.605,
        "2023": 0.66,
        "2019": 0.503,
        "2020": 0.529,
        "2024": 0.68,
        "2025": 0.7
      },
      "top_models": {
        "2021": [
          {
            "model": "gpt-j-6b",
            "org": "EleutherAI,LAION",
            "benchmark": "hella_swag",
            "score": 0.662,
            "normalized_score": 0.662,
            "date": "2021-08-05"
          },
          {
            "model": "gpt-j-6b",
            "org": "EleutherAI,LAION",
            "benchmark": "wino_grande",
            "score": 0.645,
            "normalized_score": 0.645,
            "date": "2021-08-05"
          },
          {
            "model": "gpt-j-6b",
            "org": "EleutherAI,LAION",
            "benchmark": "arc_ai2",
            "score": 0.363,
            "normalized_score": 0.363,
            "date": "2021-08-05"
          }
        ],
        "2022": [
          {
            "model": "bloom",
            "org": "Hugging Face,BigScience",
            "benchmark": "hella_swag",
            "score": 0.744,
            "normalized_score": 0.744,
            "date": "2022-07-06"
          },
          {
            "model": "gpt-neox-20b",
            "org": "EleutherAI",
            "benchmark": "wino_grande",
            "score": 0.661,
            "normalized_score": 0.661,
            "date": "2022-04-07"
          },
          {
            "model": "gpt-neox-20b",
            "org": "EleutherAI",
            "benchmark": "arc_ai2",
            "score": 0.411,
            "normalized_score": 0.411,
            "date": "2022-04-07"
          }
        ],
        "2023": [
          {
            "model": "mpt-7b",
            "org": "MosaicML",
            "benchmark": "hella_swag",
            "score": 0.764,
            "normalized_score": 0.764,
            "date": "2023-05-05"
          },
          {
            "model": "mpt-30b",
            "org": "MosaicML",
            "benchmark": "wino_grande",
            "score": 0.71,
            "normalized_score": 0.71,
            "date": "2023-06-22"
          },
          {
            "model": "mpt-30b",
            "org": "MosaicML",
            "benchmark": "arc_ai2",
            "score": 0.506,
            "normalized_score": 0.506,
            "date": "2023-06-22"
          }
        ]
      }
    },
    "reading_comprehension": {
      "name": "Reading Comprehension",
      "category": "language",
      "x": 0.35,
      "y": 0.65,
      "description": "Extract meaning and answer questions from written passages",
      "benchmarks": [
        "open_book_qa"
      ],
      "heights": {
        "2021": 0.382,
        "2022": 0.388,
        "2023": 0.52,
        "2019": 0.345,
        "2020": 0.363,
        "2024": 0.536,
        "2025": 0.552
      },
      "top_models": {
        "2021": [
          {
            "model": "gpt-j-6b",
            "org": "EleutherAI,LAION",
            "benchmark": "open_book_qa",
            "score": 0.382,
            "normalized_score": 0.382,
            "date": "2021-08-05"
          }
        ],
        "2022": [
          {
            "model": "gpt-neox-20b",
            "org": "EleutherAI",
            "benchmark": "open_book_qa",
            "score": 0.388,
            "normalized_score": 0.388,
            "date": "2022-04-07"
          }
        ],
        "2023": [
          {
            "model": "mpt-30b",
            "org": "MosaicML",
            "benchmark": "open_book_qa",
            "score": 0.52,
            "normalized_score": 0.52,
            "date": "2023-06-22"
          }
        ]
      }
    },
    "game_playing": {
      "name": "Game Playing",
      "category": "games",
      "x": 0.65,
      "y": 0.25,
      "description": "Learn and execute strategies in game environments",
      "benchmarks": [
        "balrog"
      ],
      "heights": {},
      "top_models": {}
    },
    "creative_writing": {
      "name": "Creative Writing",
      "category": "language",
      "x": 0.2,
      "y": 0.3,
      "description": "Generate original, engaging narrative and expressive text",
      "benchmarks": [
        "fictionlivebench"
      ],
      "heights": {},
      "top_models": {}
    },
    "competition_math": {
      "name": "Competition Math",
      "category": "mathematics",
      "x": 0.85,
      "y": 0.45,
      "description": "Solve competition-level mathematics problems (AMC, AIME, IMO)",
      "benchmarks": [
        "otis_mock_aime_2024_2025"
      ],
      "heights": {
        "2024": 0.018,
        "2019": 0.014,
        "2020": 0.015,
        "2021": 0.015,
        "2022": 0.016,
        "2023": 0.017,
        "2025": 0.019
      },
      "top_models": {
        "2024": [
          {
            "model": "Llama-3.1-Tulu-3-70B-DPO",
            "org": "Allen Institute for AI,University of Washington",
            "benchmark": "otis_mock_aime_2024_2025",
            "score": 0.0182727803183086,
            "normalized_score": 0.0182727803183086,
            "date": "2024-11-21"
          }
        ]
      }
    },
    "advanced_reasoning": {
      "name": "Advanced Reasoning",
      "category": "reasoning",
      "x": 0.7,
      "y": 0.4,
      "description": "Handle complex multi-step reasoning across diverse domains",
      "benchmarks": [
        "gpqa_diamond"
      ],
      "heights": {
        "2024": 0.033,
        "2019": 0.026,
        "2020": 0.027,
        "2021": 0.028,
        "2022": 0.03,
        "2023": 0.031,
        "2025": 0.034
      },
      "top_models": {
        "2024": [
          {
            "model": "dbrx-instruct",
            "org": "Databricks",
            "benchmark": "gpqa_diamond",
            "score": 0.0325694433356493,
            "normalized_score": 0.0325694433356493,
            "date": "2024-03-27"
          }
        ]
      }
    },
    "mathematical_reasoning": {
      "name": "Mathematical Reasoning",
      "category": "mathematics",
      "x": 0.75,
      "y": 0.45,
      "description": "Solve math problems with step-by-step logical reasoning",
      "benchmarks": [
        "math_level_5",
        "gsm8k"
      ],
      "heights": {
        "2022": 0.095,
        "2023": 0.344,
        "2024": 0.01,
        "2019": 0.081,
        "2020": 0.086,
        "2021": 0.09,
        "2025": 0.01
      },
      "top_models": {
        "2022": [
          {
            "model": "bloom",
            "org": "Hugging Face,BigScience",
            "benchmark": "gsm8k",
            "score": 0.095,
            "normalized_score": 0.095,
            "date": "2022-07-06"
          }
        ],
        "2023": [
          {
            "model": "mpt-30b-instruct",
            "org": "MosaicML",
            "benchmark": "gsm8k",
            "score": 0.344,
            "normalized_score": 0.344,
            "date": "2023-06-22"
          }
        ],
        "2024": [
          {
            "model": "Llama-3.1-Tulu-3-70B-DPO",
            "org": "Allen Institute for AI,University of Washington",
            "benchmark": "math_level_5",
            "score": 0.0104058546835758,
            "normalized_score": 0.0104058546835758,
            "date": "2024-11-21"
          }
        ]
      }
    },
    "long_horizon_planning": {
      "name": "Long Horizon Planning",
      "category": "reasoning",
      "x": 0.55,
      "y": 0.75,
      "description": "Plan and reason about extended sequences of actions",
      "benchmarks": [
        "metr_time_horizons"
      ],
      "heights": {},
      "top_models": {}
    },
    "writing_quality": {
      "name": "Writing Quality",
      "category": "language",
      "x": 0.25,
      "y": 0.35,
      "description": "Produce well-structured, grammatically correct, compelling text",
      "benchmarks": [
        "lech_mazur_writing"
      ],
      "heights": {},
      "top_models": {}
    },
    "cad_design": {
      "name": "Cad Design",
      "category": "reasoning",
      "x": 0.75,
      "y": 0.25,
      "description": "Create and manipulate computer-aided design models",
      "benchmarks": [
        "cad_eval"
      ],
      "heights": {},
      "top_models": {}
    },
    "advanced_mathematics": {
      "name": "Advanced Mathematics",
      "category": "mathematics",
      "x": 0.8,
      "y": 0.4,
      "description": "Solve graduate-level and research mathematics problems",
      "benchmarks": [
        "frontiermath",
        "frontiermath_tier_4"
      ],
      "heights": {},
      "top_models": {}
    },
    "abstract_reasoning": {
      "name": "Abstract Reasoning",
      "category": "reasoning",
      "x": 0.75,
      "y": 0.35,
      "description": "Recognize patterns and solve problems requiring high-level conceptual thinking",
      "benchmarks": [
        "arc_agi"
      ],
      "heights": {},
      "top_models": {}
    },
    "basic_tasks": {
      "name": "Basic Tasks",
      "category": "reasoning",
      "x": 0.4,
      "y": 0.4,
      "description": "Perform fundamental operations and simple problem-solving",
      "benchmarks": [
        "simplebench"
      ],
      "heights": {},
      "top_models": {}
    },
    "general_knowledge": {
      "name": "General Knowledge",
      "category": "knowledge",
      "x": 0.25,
      "y": 0.6,
      "description": "Answer questions across diverse academic and cultural domains",
      "benchmarks": [
        "mmlu"
      ],
      "heights": {
        "2021": 0.257,
        "2023": 0.479,
        "2022": 0.368,
        "2019": 0.232,
        "2020": 0.244,
        "2024": 0.493,
        "2025": 0.508
      },
      "top_models": {
        "2021": [
          {
            "model": "gpt-j-6b",
            "org": "EleutherAI,LAION",
            "benchmark": "mmlu",
            "score": 0.257,
            "normalized_score": 0.257,
            "date": "2021-08-05"
          }
        ],
        "2023": [
          {
            "model": "mpt-30b",
            "org": "MosaicML",
            "benchmark": "mmlu",
            "score": 0.479,
            "normalized_score": 0.479,
            "date": "2023-06-22"
          }
        ]
      }
    },
    "os_interaction": {
      "name": "Os Interaction",
      "category": "agents",
      "x": 0.6,
      "y": 0.8,
      "description": "Navigate and manipulate operating system interfaces",
      "benchmarks": [
        "os_universe"
      ],
      "heights": {},
      "top_models": {}
    },
    "factual_knowledge": {
      "name": "Factual Knowledge",
      "category": "knowledge",
      "x": 0.2,
      "y": 0.55,
      "description": "Retrieve and apply specific facts across domains",
      "benchmarks": [
        "trivia_qa"
      ],
      "heights": {
        "2023": 0.736,
        "2019": 0.599,
        "2020": 0.631,
        "2021": 0.664,
        "2022": 0.699,
        "2024": 0.758,
        "2025": 0.781
      },
      "top_models": {
        "2023": [
          {
            "model": "mpt-30b",
            "org": "MosaicML",
            "benchmark": "trivia_qa",
            "score": 0.736,
            "normalized_score": 0.736,
            "date": "2023-06-22"
          }
        ]
      }
    },
    "unusual_tasks": {
      "name": "Unusual Tasks",
      "category": "reasoning",
      "x": 0.5,
      "y": 0.3,
      "description": "Handle novel or atypical challenges outside standard benchmarks",
      "benchmarks": [
        "weirdml"
      ],
      "heights": {},
      "top_models": {}
    },
    "geographic_knowledge": {
      "name": "Geographic Knowledge",
      "category": "knowledge",
      "x": 0.25,
      "y": 0.5,
      "description": "Understand spatial relationships, locations, and geographic data",
      "benchmarks": [
        "geobench"
      ],
      "heights": {},
      "top_models": {}
    },
    "complex_reasoning": {
      "name": "Complex Reasoning",
      "category": "reasoning",
      "x": 0.65,
      "y": 0.45,
      "description": "Navigate multi-layered logical problems requiring synthesis",
      "benchmarks": [
        "bbh"
      ],
      "heights": {
        "2023": 0.38,
        "2019": 0.31,
        "2020": 0.326,
        "2021": 0.343,
        "2022": 0.361,
        "2024": 0.391,
        "2025": 0.403
      },
      "top_models": {
        "2023": [
          {
            "model": "mpt-30b",
            "org": "MosaicML",
            "benchmark": "bbh",
            "score": 0.38,
            "normalized_score": 0.38,
            "date": "2023-06-22"
          }
        ]
      }
    },
    "spatial_reasoning": {
      "name": "Spatial Reasoning",
      "category": "games",
      "x": 0.55,
      "y": 0.25,
      "description": "Understand and manipulate objects in 2D and 3D space",
      "benchmarks": [
        "gso"
      ],
      "heights": {},
      "top_models": {}
    },
    "cybersecurity": {
      "name": "Cybersecurity",
      "category": "reasoning",
      "x": 0.7,
      "y": 0.2,
      "description": "Identify vulnerabilities and solve security-related challenges",
      "benchmarks": [
        "cybench"
      ],
      "heights": {},
      "top_models": {}
    },
    "language_understanding": {
      "name": "Language Understanding",
      "category": "language",
      "x": 0.4,
      "y": 0.65,
      "description": "Comprehend meaning, context, and nuance in text",
      "benchmarks": [
        "superglue"
      ],
      "heights": {},
      "top_models": {}
    },
    "os_navigation": {
      "name": "Os Navigation",
      "category": "agents",
      "x": 0.55,
      "y": 0.85,
      "description": "Find and access files and programs within operating systems",
      "benchmarks": [
        "os_world"
      ],
      "heights": {},
      "top_models": {}
    },
    "natural_language_inference": {
      "name": "Natural Language Inference",
      "category": "language",
      "x": 0.35,
      "y": 0.6,
      "description": "Determine logical relationships between text passages",
      "benchmarks": [
        "adversarial_nli"
      ],
      "heights": {},
      "top_models": {}
    },
    "agent_reasoning": {
      "name": "Agent Reasoning",
      "category": "agents",
      "x": 0.5,
      "y": 0.8,
      "description": "Plan and execute multi-step tasks autonomously",
      "benchmarks": [
        "the_agent_company"
      ],
      "heights": {},
      "top_models": {}
    },
    "boolean_reasoning": {
      "name": "Boolean Reasoning",
      "category": "reasoning",
      "x": 0.4,
      "y": 0.5,
      "description": "Answer yes/no questions requiring logical deduction",
      "benchmarks": [
        "bool_q"
      ],
      "heights": {
        "2021": 0.654,
        "2022": 0.704,
        "2023": 0.85,
        "2019": 0.59,
        "2020": 0.621,
        "2024": 0.875,
        "2025": 0.902
      },
      "top_models": {
        "2021": [
          {
            "model": "gpt-j-6b",
            "org": "EleutherAI,LAION",
            "benchmark": "bool_q",
            "score": 0.654,
            "normalized_score": 0.654,
            "date": "2021-08-05"
          }
        ],
        "2022": [
          {
            "model": "bloom",
            "org": "Hugging Face,BigScience",
            "benchmark": "bool_q",
            "score": 0.704,
            "normalized_score": 0.704,
            "date": "2022-07-06"
          }
        ],
        "2023": [
          {
            "model": "mpt-30b-instruct",
            "org": "MosaicML",
            "benchmark": "bool_q",
            "score": 0.85,
            "normalized_score": 0.85,
            "date": "2023-06-22"
          }
        ]
      }
    },
    "language_modeling": {
      "name": "Language Modeling",
      "category": "language",
      "x": 0.3,
      "y": 0.7,
      "description": "Predict and generate coherent natural language sequences",
      "benchmarks": [
        "lambada"
      ],
      "heights": {
        "2023": 0.7,
        "2019": 0.57,
        "2020": 0.6,
        "2021": 0.632,
        "2022": 0.665,
        "2024": 0.721,
        "2025": 0.743
      },
      "top_models": {
        "2023": [
          {
            "model": "mpt-7b",
            "org": "MosaicML",
            "benchmark": "lambada",
            "score": 0.7,
            "normalized_score": 0.7,
            "date": "2023-05-05"
          }
        ]
      }
    },
    "terminal_usage": {
      "name": "Terminal Usage",
      "category": "agents",
      "x": 0.45,
      "y": 0.85,
      "description": "Execute commands and navigate command-line interfaces",
      "benchmarks": [
        "terminalbench"
      ],
      "heights": {},
      "top_models": {}
    }
  }
}